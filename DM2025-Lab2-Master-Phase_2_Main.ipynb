{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Data Mining Lab 2 - Phase 2](#toc1_)    \n",
    "  - [Before Starting](#toc1_1_)    \n",
    "  - [Introduction](#toc1_2_)    \n",
    "  - [**1. Data Preparation**](#toc1_3_)    \n",
    "  - [**1.1 Load data**](#toc1_4_)    \n",
    "    - [**1.2 Save data**](#toc1_4_1_)    \n",
    "  - [**2. Large Language Models (LLMs)**](#toc1_5_)    \n",
    "    - [Open-Source vs. Proprietary LLMs](#toc1_5_1_)    \n",
    "    - [Why Use Code (API) for Data Mining?](#toc1_5_2_)    \n",
    "    - [The Gemini API](#toc1_5_3_)    \n",
    "    - [Interacting with the Gemini API](#toc1_5_4_)    \n",
    "    - [**2.1 Text Prompting**](#toc1_5_5_)    \n",
    "        - [**>>> Exercise 1 (Take home):**](#toc1_5_5_1_1_)    \n",
    "    - [**2.2 Structured Output**](#toc1_5_6_)    \n",
    "        - [**>>> Exercise 2 (Take home):**](#toc1_5_6_1_1_)    \n",
    "    - [**2.3 Information Extraction and Grounding:**](#toc1_5_7_)    \n",
    "      - [**`langextract`: A Library for Grounded Extraction**](#toc1_5_7_1_)    \n",
    "        - [**2.3.1 Using PDF Documents:**](#toc1_5_7_1_1_)    \n",
    "        - [**>>> Bonus Exercise 3 (Take home):**](#toc1_5_7_1_2_)    \n",
    "    - [**2.4 Generating LLM Embeddings:**](#toc1_5_8_)    \n",
    "        - [**>>> Exercise 4 (Take home):**](#toc1_5_8_1_1_)    \n",
    "    - [**2.5 Retrieval-Augmented Generation (RAG)**](#toc1_5_9_)    \n",
    "        - [**Actual answer in the URL:**](#toc1_5_9_1_1_)    \n",
    "        - [**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc1_5_9_1_2_)    \n",
    "        - [**>>> Bonus Exercise 5 (Take home):**](#toc1_5_9_1_3_)    \n",
    "    - [**2.6 Few-Shot Prompting Classification:**](#toc1_5_10_)    \n",
    "        - [**>>> Exercise 6 (Take home):**](#toc1_5_10_1_1_)    \n",
    "        - [**>>> Exercise 7 (Take home):**](#toc1_5_10_1_2_)    \n",
    "    - [**2.7 Extra LLM Related Materials:**](#toc1_5_11_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uuutyCx4YTpX"
   },
   "source": [
    "# <a id='toc1_'></a>[Data Mining Lab 2 - Phase 2](#toc0_)\n",
    "In this lab's phase 2 session we will focus on exploring some basic LLMs' applications with data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Before Starting](#toc0_)\n",
    "\n",
    "**Make sure you have installed all the required libraries and you have the environment ready to run this lab.**\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LIpAqCvMYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_2_'></a>[Introduction](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n2paPeNbYTpX"
   },
   "source": [
    "**Dataset:** [SemEval 2017 Task](https://competitions.codalab.org/competitions/16380)\n",
    "\n",
    "**Task:** Classify text data into 4 different emotions using word embeddings and other deep information retrieval approaches.\n",
    "\n",
    "![pic0.png](./pics/pic0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op_X7pR-YTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_3_'></a>[**1. Data Preparation**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgoEbZzSYTpX"
   },
   "source": [
    "---\n",
    "## <a id='toc1_4_'></a>[**1.1 Load data**](#toc0_)\n",
    "\n",
    "We start by loading the csv files into a single pandas dataframe for training and one for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "anfjcPSSYTpX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "### training data\n",
    "anger_train = pd.read_csv(\"data/semeval/train/anger-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None,names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_train = pd.read_csv(\"data/semeval/train/sadness-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_train = pd.read_csv(\"data/semeval/train/fear-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_train = pd.read_csv(\"data/semeval/train/joy-ratings-0to1.train.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "yVc2T5MIYTpX"
   },
   "outputs": [],
   "source": [
    "# combine 4 sub-dataset\n",
    "train_df = pd.concat([anger_train, fear_train, joy_train, sadness_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Kw8bGMv7YTpX",
    "outputId": "9f6f7052-302e-4794-ef69-b84450b61b36"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000</td>\n",
       "      <td>How the fu*k! Who the heck! moved my fridge!.....</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>So my Indian Uber driver just called someone t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10002</td>\n",
       "      <td>@DPD_UK I asked for my parcel to be delivered ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10003</td>\n",
       "      <td>so ef whichever butt wipe pulled the fire alar...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10004</td>\n",
       "      <td>Don't join @BTCare they put the phone down on ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text emotion  intensity\n",
       "0  10000  How the fu*k! Who the heck! moved my fridge!.....   anger      0.938\n",
       "1  10001  So my Indian Uber driver just called someone t...   anger      0.896\n",
       "2  10002  @DPD_UK I asked for my parcel to be delivered ...   anger      0.896\n",
       "3  10003  so ef whichever butt wipe pulled the fire alar...   anger      0.896\n",
       "4  10004  Don't join @BTCare they put the phone down on ...   anger      0.896"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### testing data\n",
    "anger_test = pd.read_csv(\"data/semeval/dev/anger-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "sadness_test = pd.read_csv(\"data/semeval/dev/sadness-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "fear_test = pd.read_csv(\"data/semeval/dev/fear-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "joy_test = pd.read_csv(\"data/semeval/dev/joy-ratings-0to1.dev.gold.txt\",\n",
    "                         sep=\"\\t\", header=None, names=[\"id\", \"text\", \"emotion\", \"intensity\"])\n",
    "\n",
    "# combine 4 sub-dataset\n",
    "test_df = pd.concat([anger_test, fear_test, joy_test, sadness_test], ignore_index=True)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "HBHwcL8sYTpX"
   },
   "outputs": [],
   "source": [
    "# shuffle dataset\n",
    "train_df = train_df.sample(frac=1)\n",
    "test_df = test_df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9w_cDUwCYTpX",
    "outputId": "3582ac44-1f5f-4cb2-b833-d477f152461a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training df:  (3613, 4)\n",
      "Shape of Testing df:  (347, 4)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of Training df: \", train_df.shape)\n",
    "print(\"Shape of Testing df: \", test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_hr8aKhlYTpo"
   },
   "source": [
    "---\n",
    "### <a id='toc1_4_1_'></a>[**1.2 Save data**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dZzepBdpYTpo"
   },
   "outputs": [],
   "source": [
    "# save to pickle file\n",
    "train_df.to_pickle(\"./data/train_df.pkl\") \n",
    "test_df.to_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "H5uO-kOUYTpo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load a pickle file\n",
    "train_df = pd.read_pickle(\"./data/train_df.pkl\")\n",
    "test_df = pd.read_pickle(\"./data/test_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_sLDcQzeYTpo"
   },
   "source": [
    "For more information: https://reurl.cc/0Dzqx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## <a id='toc1_5_'></a>[**2. Large Language Models (LLMs)**](#toc0_)\n",
    "\n",
    "Before we start we strongly suggest that you watch the following video explanations so you can understand the concepts that we are gonna discuss about LLMs: \n",
    "\n",
    "1. [How Large Language Models Work](https://www.youtube.com/watch?v=5sLYAQS9sWQ)\n",
    "2. [Large Language Models explained briefly](https://www.youtube.com/watch?v=LPZh9BOjkQs)\n",
    "3. [What is Prompt Tuning?](https://www.youtube.com/watch?v=yu27PWzJI_Y)\n",
    "4. [Why Large Language Models Hallucinate](https://www.youtube.com/watch?v=cfqtFvWOfg0)\n",
    "5. [What are LLM Embeddings?](https://www.youtube.com/watch?v=UShw_1NbpCw&t=182s)\n",
    "6. [What is Retrieval-Augmented Generation (RAG)?](https://www.youtube.com/watch?v=T-D1OfcDW1M)\n",
    "7. [RAG vs Fine-Tuning vs Prompt Engineering: Optimizing AI Models](https://www.youtube.com/watch?v=zYGDpG-pTho)\n",
    "8. [Discover Few-Shot Prompting | Google AI Essentials](https://www.youtube.com/watch?v=9qdgEBVkWR4)\n",
    "9. [What is Zero-Shot Learning?](https://www.youtube.com/watch?v=pVpr4GYLzAo)\n",
    "10. [Zero-shot, One-shot and Few-shot Prompting Explained | Prompt Engineering 101](https://www.youtube.com/watch?v=sW5xoicq5TY)\n",
    "\n",
    "`These videos can help you get a better grasp on the core concepts of LLMs if you were not familiar before.`\n",
    "\n",
    "**So now let's start with the main content of Lab 2 Phase 2.**\n",
    "\n",
    "Large Language Models (LLMs) are AI systems trained on vast amounts of text to understand and generate human language for tasks like summarization and translation.\n",
    "\n",
    "### <a id='toc1_5_1_'></a>[Open-Source vs. Proprietary LLMs](#toc0_)\n",
    "*   **Open-Source Models** (e.g., Llama, Gemma) are customizable and cost-effective but require technical skill to manage and may be less powerful.\n",
    "*   **Proprietary Models** (e.g., Gemini, ChatGPT) offer top performance and ease of use but are more costly and less flexible.\n",
    "\n",
    "For students interested in running models locally, the optional notebook `DM2025-Lab2-Optional-Ollama.ipynb` explores using Ollama ([Ollama GitHub Link](https://github.com/ollama/ollama)). It needs a capable GPU to run models (**at least 4GB VRAM**).\n",
    "\n",
    "You can explore the variety of models available through Ollama here:\n",
    "\n",
    "![pic10.png](./pics/pic10.png)\n",
    "\n",
    "### <a id='toc1_5_2_'></a>[Why Use Code (API) for Data Mining?](#toc0_)\n",
    "\n",
    "For data analysis, accessing LLMs programmatically is superior to using web chatbots because it allows for:\n",
    "*   **Automation:** Easily process entire datasets with loops.\n",
    "*   **Structured Output:** Receive data in usable formats like **JSON**, ready for analysis in tools like pandas.\n",
    "*   **Reproducibility:** Ensure consistent results by setting fixed parameters.\n",
    "*   **Privacy:** Maintain data security, especially when running models locally.\n",
    "\n",
    "For the main exercises in this lab, we will use **the Gemini API**. This approach offers several advantages over running local open-source models, such as access to state-of-the-art model performance without needing specialized hardware. While the API has usage limits (rate limits and token quotas), it provides a generous **free tier** that is more than sufficient for our exercises.\n",
    "\n",
    "![pic13.png](./pics/pic13.png)\n",
    "\n",
    "![pic14.png](./pics/pic14.png)\n",
    "\n",
    "### <a id='toc1_5_3_'></a>[The Gemini API](#toc0_)\n",
    "\n",
    "We will primarily use the **Gemini 2.5 Flash-Lite** (`gemini-2.5-flash-lite`) model. As shown in the rate limit table, this model is optimized for high-frequency tasks and offers a high request-per-day limit of 1,000, making it ideal for completing the lab exercises without interruption.\n",
    "\n",
    "Students are encouraged to explore other models available through the API but should remain mindful of their respective usage limits. For instance:\n",
    "*   **Gemini 2.5 Pro** is a more powerful model but has a lower daily request limit of 100.\n",
    "*   The **Gemma 3** model available via the API offers an impressive 14,400 requests per day, providing another excellent alternative for experimentation.\n",
    "\n",
    "Please be aware of your usage limits as you work through the exercises to ensure you do not get rate-limited.\n",
    "\n",
    "[Gemini Documentation](https://ai.google.dev/gemini-api/docs)\n",
    "\n",
    "[Gemini Rate Limits](https://ai.google.dev/gemini-api/docs/rate-limits)\n",
    "\n",
    "[Description of Gemini Models](https://ai.google.dev/gemini-api/docs/models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <a id='toc1_5_4_'></a>[Interacting with the Gemini API](#toc0_)\n",
    "\n",
    "The code cell below contains the primary function, `prompt_gemini`, that we will use throughout this lab to communicate with the Gemini API. It's designed to be a flexible wrapper that handles the details of sending a request and receiving a response.\n",
    "\n",
    "Before you run the exercises, here are the key things you need to understand in this setup:\n",
    "\n",
    "*   **API Key Configuration**: The script loads your API key from a `.env` file located in the `./config/` directory. **You must create this file and add your API key** like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`. This is a security best practice to keep your credentials out of the code.\n",
    "\n",
    "*   **Global Settings**: At the top of the script, you can find and modify several important defaults:\n",
    "    *   `MODEL_NAME`: We've set this to `\"gemini-2.5-flash-lite\"`, but you can easily switch to other models like `\"gemini-2.5-pro\"` to experiment.\n",
    "    *   `SYSTEM_INSTRUCTION`: This sets the model's default behavior or persona (e.g., \"You are a helpful assistant\"). You can customize this for different tasks.\n",
    "    *   `SAFETY_SETTINGS`: For our academic exercises, these are turned off to prevent interference. In real-world applications, you would configure these carefully.\n",
    "\n",
    "*   **The `prompt_gemini` function**: This is the main tool you will use. Here are its most important parameters:\n",
    "    *   `input_prompt`: The list of contents (text, images, etc.) you want to send to the model.\n",
    "    *   `temperature`: Controls the randomness of the output. `0.0` makes the output deterministic and less creative, while a higher value (e.g., `0.7`) makes it more varied.\n",
    "    *   `schema`: A powerful feature that allows you to specify a JSON format for the model's output. This is extremely useful for structured data extraction.\n",
    "    *   `with_tokens_info`: If set to `True`, the function will also return the number of input and output tokens used, which is helpful for monitoring your usage against the free tier limits.\n",
    "\n",
    "In the following exercises, you will call this function with different prompts and configurations to solve various tasks.\n",
    "\n",
    "If needed, you can also check some tutorials on how a python function works: [Python Functions Tutorial](https://realpython.com/defining-your-own-python-function/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "\n",
    "env_path = \"./config/.env\"\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "\n",
    "# System instruction that can dictate how the model behaves in the output, can be customized as needed\n",
    "SYSTEM_INSTRUCTION = (\n",
    "        \"You are a helpful assistant\"\n",
    "    )\n",
    "\n",
    "# Max amount of tokens that the model can output, the Gemini 2.5 Models have this maximum amount\n",
    "# For other models need to check their documentation \n",
    "MAX_OUTPUT_TOKENS = 65535\n",
    "MODEL_NAME = \"gemini-2.5-flash-lite\" # Other models: \"gemini-2.5-pro\", \"gemini-2.5-flash\"; Check different max output tokens: \"gemini-2.0-flash\" , \"gemini-2.0-flash-lite\" \n",
    "\n",
    "# We disable the safety settings, as no moderation is needed in our tasks\n",
    "SAFETY_SETTINGS = [\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
    "    types.SafetySetting(\n",
    "        category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
    "]\n",
    "\n",
    "#IMPORTANT: The script loads your API key from a `.env` file located in the `./config/` directory. \n",
    "# You must create this file and add your API key like this: `GOOGLE_API_KEY='YOUR_API_KEY_HERE'`\n",
    "\n",
    "# We input the API Key to be able to use the Gemini models\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "# We also set LangExtract to use the API key as well:\n",
    "if 'GEMINI_API_KEY' not in os.environ:\n",
    "    os.environ['GEMINI_API_KEY'] = api_key\n",
    "\n",
    "def prompt_gemini(\n",
    "        input_prompt: list,\n",
    "        schema = None,\n",
    "        temperature: float = 0.0,\n",
    "        system_instruction: str = SYSTEM_INSTRUCTION,\n",
    "        max_output_tokens: int = MAX_OUTPUT_TOKENS,\n",
    "        client: genai.Client = client,\n",
    "        model_name: str = MODEL_NAME,\n",
    "        new_config: types.GenerateContentConfig = None,\n",
    "        with_tools: bool = False,\n",
    "        with_parts: bool = False,\n",
    "        with_tokens_info: bool = False\n",
    "    ):\n",
    "        try:\n",
    "            # If we need a JSON schema we set up the following\n",
    "            if schema:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    response_mime_type=\"application/json\",\n",
    "                    response_schema=schema,\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            # If there is no need we leave it unstructured\n",
    "            else:\n",
    "                generate_content_config = types.GenerateContentConfig(\n",
    "                    temperature=temperature,\n",
    "                    system_instruction=system_instruction,\n",
    "                    max_output_tokens=max_output_tokens,\n",
    "                    response_modalities=[\"TEXT\"],\n",
    "                    safety_settings=SAFETY_SETTINGS\n",
    "                )\n",
    "            \n",
    "            # We add a different custom configuration if we need it\n",
    "            if new_config:\n",
    "                generate_content_config = new_config\n",
    "            \n",
    "            # For some tasks we need a more specific way to add the contents when prompting the model\n",
    "            # So we need custom parts for it sometimes from the \"types\" objects\n",
    "            if with_parts:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=types.Content(parts=input_prompt),\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "            # In the simplest form the contents can be expressed as a list [] of simple objects like str and Pillow images\n",
    "            else:\n",
    "                response = client.models.generate_content(\n",
    "                    model=model_name,\n",
    "                    contents=input_prompt,\n",
    "                    config=generate_content_config,\n",
    "                )\n",
    "\n",
    "            if with_tools:\n",
    "                # print(response)\n",
    "                # Include raw response when function calling\n",
    "                completion = response\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    return completion, log\n",
    "                return completion\n",
    "            else:\n",
    "                completion = response.text\n",
    "                if with_tokens_info:\n",
    "                    log = {\n",
    "                        \"model\": model_name,\n",
    "                        \"input_tokens\": response.usage_metadata.prompt_token_count,\n",
    "                        \"output_tokens\": response.usage_metadata.candidates_token_count,\n",
    "                    }\n",
    "                    # Return the text response and logs (if selected)\n",
    "                    return completion, log\n",
    "                return completion\n",
    "        except Exception as e:\n",
    "             print(f\"Error occurred when generating response, error: {e}\")\n",
    "             return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_5_'></a>[**2.1 Text Prompting**](#toc0_)\n",
    "\n",
    "In the same way as with ChatGPT we can use the Gemini models to ask about anything. Here we are going to ask a question requesting the response to be in markdown format, this is to make it have a better display afterwards.\n",
    "\n",
    "For more information visit:\n",
    "[Gemini's Text Generation Documentation](https://ai.google.dev/gemini-api/docs/text-generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
      "\n",
      "Here's a breakdown of what that means:\n",
      "\n",
      "**Key Concepts:**\n",
      "\n",
      "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
      "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
      "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
      "\n",
      "**How it Works (The Process):**\n",
      "\n",
      "Data mining is usually an iterative process that involves several stages:\n",
      "\n",
      "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
      "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
      "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
      "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
      "    *   **Integration:** Combining data from multiple sources.\n",
      "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
      "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
      "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
      "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
      "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
      "\n",
      "**Common Data Mining Techniques:**\n",
      "\n",
      "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
      "\n",
      "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
      "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
      "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
      "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
      "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
      "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
      "\n",
      "**Why is Data Mining Important?**\n",
      "\n",
      "Data mining is crucial for businesses and organizations because it enables them to:\n",
      "\n",
      "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
      "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
      "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
      "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
      "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
      "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
      "\n",
      "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields.\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"What is Data Mining?\"]\n",
    "text_response, logs = prompt_gemini(input_prompt = input_prompt, with_tokens_info = True)\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the logs of the usage with our model that we defined in our previous function. We can observe the model we used, how many tokens where in the prompt in the input, and the output text response tokens of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 12, 'output_tokens': 911}\n"
     ]
    }
   ],
   "source": [
    "print(logs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can use the IPython library to make the response look better:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Data mining is the process of **discovering patterns, insights, and knowledge from large datasets**. It's essentially about extracting valuable information that isn't immediately obvious from raw data. Think of it as sifting through a mountain of information to find hidden gems.\n",
       "\n",
       "Here's a breakdown of what that means:\n",
       "\n",
       "**Key Concepts:**\n",
       "\n",
       "*   **Large Datasets:** Data mining is typically applied to datasets that are too large and complex for manual analysis. This can include customer transaction records, website logs, sensor data, social media feeds, scientific experiment results, and much more.\n",
       "*   **Patterns and Insights:** The goal is to identify recurring trends, correlations, anomalies, and relationships within the data. These patterns can reveal underlying structures, predict future behavior, or explain observed phenomena.\n",
       "*   **Knowledge Discovery:** The ultimate aim is to transform raw data into actionable knowledge that can be used for decision-making, problem-solving, and strategic planning.\n",
       "\n",
       "**How it Works (The Process):**\n",
       "\n",
       "Data mining is usually an iterative process that involves several stages:\n",
       "\n",
       "1.  **Business Understanding:** Defining the problem or objective you want to achieve with data mining. What questions are you trying to answer? What business goals are you trying to meet?\n",
       "2.  **Data Understanding:** Exploring and getting familiar with the data. This involves collecting, cleaning, and understanding the data's structure, quality, and meaning.\n",
       "3.  **Data Preparation (Preprocessing):** This is often the most time-consuming stage. It involves:\n",
       "    *   **Cleaning:** Handling missing values, noisy data, and inconsistencies.\n",
       "    *   **Integration:** Combining data from multiple sources.\n",
       "    *   **Transformation:** Normalizing or aggregating data to make it suitable for mining.\n",
       "    *   **Reduction:** Reducing the size of the dataset while preserving important information.\n",
       "4.  **Modeling:** Selecting and applying appropriate data mining techniques (algorithms) to discover patterns. This is where the \"mining\" happens.\n",
       "5.  **Evaluation:** Assessing the quality and usefulness of the discovered patterns. Do they make sense? Are they statistically significant? Do they meet the business objectives?\n",
       "6.  **Deployment:** Putting the discovered knowledge into practice. This could involve integrating it into business processes, creating reports, or building predictive models.\n",
       "\n",
       "**Common Data Mining Techniques:**\n",
       "\n",
       "Data mining employs a variety of techniques, often drawing from statistics, machine learning, and database systems. Some of the most common include:\n",
       "\n",
       "*   **Classification:** Categorizing data into predefined classes (e.g., predicting whether a customer will churn or not).\n",
       "*   **Clustering:** Grouping similar data points together without predefined classes (e.g., segmenting customers into different groups based on their purchasing behavior).\n",
       "*   **Association Rule Mining:** Discovering relationships between items in a dataset (e.g., \"customers who buy bread also tend to buy milk\"). This is often used in market basket analysis.\n",
       "*   **Regression:** Predicting a continuous numerical value (e.g., predicting the price of a house based on its features).\n",
       "*   **Anomaly Detection (Outlier Detection):** Identifying data points that deviate significantly from the norm (e.g., detecting fraudulent transactions).\n",
       "*   **Sequential Pattern Mining:** Discovering patterns that occur in a sequence over time (e.g., identifying common user navigation paths on a website).\n",
       "\n",
       "**Why is Data Mining Important?**\n",
       "\n",
       "Data mining is crucial for businesses and organizations because it enables them to:\n",
       "\n",
       "*   **Make Better Decisions:** By understanding customer behavior, market trends, and operational efficiencies, organizations can make more informed and strategic decisions.\n",
       "*   **Improve Customer Relationships:** Identifying customer preferences and predicting their needs allows for personalized marketing, better customer service, and increased loyalty.\n",
       "*   **Detect Fraud and Risk:** Anomaly detection can help identify fraudulent activities, security breaches, and potential risks.\n",
       "*   **Optimize Operations:** Understanding patterns in operational data can lead to improved efficiency, reduced costs, and better resource allocation.\n",
       "*   **Drive Innovation:** Discovering new insights can spark new product development, service offerings, and business models.\n",
       "*   **Gain a Competitive Advantage:** Organizations that effectively leverage data mining can outperform their competitors by understanding their market and customers better.\n",
       "\n",
       "In essence, data mining is a powerful tool for transforming raw data into valuable intelligence, driving progress and innovation across various fields."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "display(Markdown(text_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_5_1_1_'></a>[**>>> Exercise 1 (Take home):**](#toc0_)\n",
    "\n",
    "`With your own prompt`, run the previous example in the following way:\n",
    "\n",
    "1. Run it with the same model as the example (gemini-2.5-flash-lite). \n",
    "2. Run it with a different gemini model from the available options for the API.\n",
    "3. Discuss the differences on the results with different models.\n",
    "4. Discuss what would happen if you change the system prompt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 答案\n",
    "\n",
    "Exercise 1 討論:\n",
    "\n",
    "1. 同一個 prompt, 使用 gemini-2.5-flash-lite 與 gemini-2.5-flash 的輸出差異:\n",
    "- flash-lite: 回覆較長, 內容更完整, 例子解釋較細, output tokens 較高(約 1104)。\n",
    "- flash: 回覆較短, 結構更精簡, 仍有定義與例子, 但細節較少, output tokens 較低(約 998)。\n",
    "\n",
    "2. 不同模型的差異原因(直覺解讀):\n",
    "- 模型大小與預設行為不同, 會影響回答長度, 條理, 舉例方式, 以及細節程度。\n",
    "- tokens 使用量也會跟回答長短直接相關。\n",
    "\n",
    "3. 變更 system prompt 會發生什麼事:\n",
    "- system prompt 會改變模型的角色與輸出規則, 例如要求只能用條列, 要求更嚴格或更簡短。\n",
    "- 同一個 user prompt 在不同 system prompt 下, 可能會改變回答的格式, 長度, 用詞, 甚至是否補充額外提醒。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.5-pro\\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.5-pro\\nPlease retry in 38.755345039s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerDay-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-pro', 'location': 'global'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}}, {'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-pro'}}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}\n",
      "=== flash-lite ===\n",
      "A confusion matrix is a table that summarizes the performance of a classification model on a set of test data for which the true values are known. It allows you to visualize the performance of your classification model by breaking down the predictions into four categories:\n",
      "\n",
      "*   **True Positives (TP):** The number of instances that were correctly predicted as belonging to a particular class.\n",
      "*   **True Negatives (TN):** The number of instances that were correctly predicted as *not* belonging to a particular class.\n",
      "*   **False Positives (FP):** The number of instances that were incorrectly predicted as belonging to a particular class (Type I error).\n",
      "*   **False Negatives (FN):** The number of instances that were incorrectly predicted as *not* belonging to a particular class (Type II error).\n",
      "\n",
      "The matrix is typically structured with the actual (true) classes on the rows and the predicted classes on the columns.\n",
      "\n",
      "### Structure of a Confusion Matrix\n",
      "\n",
      "For a binary classification problem (two classes, e.g., \"Positive\" and \"Negative\"), the confusion matrix looks like this:\n",
      "\n",
      "|               | Predicted Positive | Predicted Negative |\n",
      "| :------------ | :----------------- | :----------------- |\n",
      "| **Actual Positive** | TP                 | FN                 |\n",
      "| **Actual Negative** | FP                 | TN                 |\n",
      "\n",
      "### Importance of a Confusion Matrix\n",
      "\n",
      "Confusion matrices are valuable because they provide a more detailed insight into the model's performance than simple accuracy. They help identify:\n",
      "\n",
      "*   **Which classes are being confused:** Are certain classes frequently misclassified as others?\n",
      "*   **Types of errors:** Is the model more prone to false positives or false negatives?\n",
      "*   **Model strengths and weaknesses:** Where does the model perform well, and where does it struggle?\n",
      "\n",
      "This information is crucial for understanding how to improve the model, such as by collecting more data for specific classes, adjusting class weights, or trying different algorithms.\n",
      "\n",
      "### Example for 4-Class Classification\n",
      "\n",
      "Let's consider a scenario where we are classifying images into four categories: **Cat**, **Dog**, **Bird**, and **Fish**. We have a test set of 100 images, and after running our classification model, we obtain the following confusion matrix:\n",
      "\n",
      "|               | Predicted Cat | Predicted Dog | Predicted Bird | Predicted Fish |\n",
      "| :------------ | :------------ | :------------ | :------------- | :------------- |\n",
      "| **Actual Cat** | 20            | 3             | 1              | 0              |\n",
      "| **Actual Dog** | 2             | 25            | 2              | 1              |\n",
      "| **Actual Bird**| 0             | 1             | 18             | 1              |\n",
      "| **Actual Fish**| 1             | 0             | 2              | 19             |\n",
      "\n",
      "**Explanation of the Example:**\n",
      "\n",
      "*   **Actual Cat (Row 1):**\n",
      "    *   **20** images were actually cats and were correctly predicted as cats (TP for Cat).\n",
      "    *   **3** images were actually cats but were misclassified as dogs (FN for Cat, FP for Dog).\n",
      "    *   **1** image was actually a cat but was misclassified as a bird (FN for Cat, FP for Bird).\n",
      "    *   **0** images were actually cats but were misclassified as fish.\n",
      "\n",
      "*   **Actual Dog (Row 2):**\n",
      "    *   **2** images were actually dogs but were misclassified as cats.\n",
      "    *   **25** images were actually dogs and were correctly predicted as dogs (TP for Dog).\n",
      "    *   **2** images were actually dogs but were misclassified as birds.\n",
      "    *   **1** image was actually a dog but was misclassified as a fish.\n",
      "\n",
      "*   **Actual Bird (Row 3):**\n",
      "    *   **0** images were actually birds but were misclassified as cats.\n",
      "    *   **1** image was actually a bird but was misclassified as a dog.\n",
      "    *   **18** images were actually birds and were correctly predicted as birds (TP for Bird).\n",
      "    *   **1** image was actually a bird but was misclassified as a fish.\n",
      "\n",
      "*   **Actual Fish (Row 4):**\n",
      "    *   **1** image was actually a fish but was misclassified as a cat.\n",
      "    *   **0** images were actually fish but were misclassified as dogs.\n",
      "    *   **2** images were actually fish but were misclassified as birds.\n",
      "    *   **19** images were actually fish and were correctly predicted as fish (TP for Fish).\n",
      "\n",
      "**Observations from this example:**\n",
      "\n",
      "*   The model performs reasonably well for **Cat** and **Dog** classes, with high true positives.\n",
      "*   There's some confusion between **Cat** and **Dog**, and between **Bird** and **Fish**.\n",
      "*   The model seems to struggle slightly with distinguishing **Fish** from **Birds** and **Cats**, as indicated by the non-zero values in those cells.\n",
      "\n",
      "From this matrix, you can calculate various performance metrics like precision, recall, F1-score, and overall accuracy for each class and for the entire model.\n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 31, 'output_tokens': 1104}\n",
      "\n",
      "resp_pro_result: None\n",
      "\n",
      "2.5-pro 失敗, 改用 gemini-2.5-flash\n",
      "\n",
      "=== second model ===\n",
      "A **confusion matrix** is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. It allows visualization of the performance of an algorithm.\n",
      "\n",
      "## What is a Confusion Matrix?\n",
      "\n",
      "Here's a breakdown of its key characteristics:\n",
      "\n",
      "*   **Table Structure:** It's a square matrix where both rows and columns represent the classes involved in the classification problem.\n",
      "*   **Rows: Actual Classes:** Each row of the matrix represents the instances in an **actual class** (what the true label of the data point was).\n",
      "*   **Columns: Predicted Classes:** Each column represents the instances in a **predicted class** (what the model predicted the label to be).\n",
      "*   **Diagonal Elements:** The values along the main diagonal (from top-left to bottom-right) represent the number of instances that were **correctly classified**. That is, the predicted label matches the actual label.\n",
      "*   **Off-Diagonal Elements:** The values outside the main diagonal represent the number of instances that were **misclassified**. These show where the model \"confused\" one class for another.\n",
      "\n",
      "### Why is it Useful?\n",
      "\n",
      "While simple **accuracy** tells you the overall correctness of your model, a confusion matrix provides a more detailed breakdown, showing:\n",
      "\n",
      "*   **Types of Errors:** It reveals *what kind* of mistakes the model is making. For example, is it confusing class A with class B, or class A with class C?\n",
      "*   **Class-Specific Performance:** It helps identify which classes are being predicted well and which ones are problematic.\n",
      "*   **Basis for Other Metrics:** It's the foundation for calculating more advanced performance metrics like Precision, Recall (Sensitivity), Specificity, and F1-Score, which offer deeper insights than accuracy alone, especially in imbalanced datasets.\n",
      "\n",
      "---\n",
      "\n",
      "## Short Example for 4-Class Classification\n",
      "\n",
      "Let's imagine we have a model designed to classify images of animals into one of four categories: **Cat**, **Dog**, **Bird**, or **Fish**. We test our model on 100 images (25 of each animal type).\n",
      "\n",
      "Here's a hypothetical confusion matrix:\n",
      "\n",
      "```\n",
      "|             | Predicted Cat | Predicted Dog | Predicted Bird | Predicted Fish |\n",
      "| :---------- | :------------ | :------------ | :------------- | :------------- |\n",
      "| **Actual Cat**    | 20            | 3             | 1              | 1              |\n",
      "| **Actual Dog**    | 2             | 22            | 0              | 1              |\n",
      "| **Actual Bird**   | 1             | 1             | 23             | 0              |\n",
      "| **Actual Fish**   | 0             | 0             | 2              | 23             |\n",
      "```\n",
      "\n",
      "### Interpretation of the Example:\n",
      "\n",
      "*   **Actual Cat (Row 1):**\n",
      "    *   Out of 25 actual cat images, the model correctly predicted **20** as Cat.\n",
      "    *   It misclassified **3** cats as Dogs, **1** as a Bird, and **1** as a Fish.\n",
      "*   **Actual Dog (Row 2):**\n",
      "    *   Out of 25 actual dog images, the model correctly predicted **22** as Dog.\n",
      "    *   It misclassified **2** dogs as Cats and **1** as a Fish.\n",
      "*   **Actual Bird (Row 3):**\n",
      "    *   Out of 25 actual bird images, the model correctly predicted **23** as Bird.\n",
      "    *   It misclassified **1** bird as a Cat and **1** as a Dog.\n",
      "*   **Actual Fish (Row 4):**\n",
      "    *   Out of 25 actual fish images, the model correctly predicted **23** as Fish.\n",
      "    *   It misclassified **2** fish as Birds.\n",
      "\n",
      "### Insights from this Matrix:\n",
      "\n",
      "*   **Good Performance:** The model generally performs well, with high numbers on the diagonal (20, 22, 23, 23 correct predictions for each class).\n",
      "*   **Common Confusion:** The most common misclassification seems to be confusing **Cats with Dogs** (3 actual cats predicted as dogs, 2 actual dogs predicted as cats). This is plausible as they are both mammals and can share similar features.\n",
      "*   **Specific Errors:** The model also occasionally confuses **Fish with Birds** (2 actual fish predicted as birds), which might indicate issues with distinguishing aquatic vs. aerial features or background noise.\n",
      "*   **Strongest Performance:** The model seems to be best at identifying Birds and Fish, with 23 correct predictions each and relatively few misclassifications.\n",
      "\n",
      "This example clearly shows how a confusion matrix provides a much richer understanding of model performance than just a single accuracy score (which would be (20+22+23+23)/100 = 88% in this case).\n",
      "{'model': 'gemini-2.5-flash', 'input_tokens': 31, 'output_tokens': 1063}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## flash-lite output\n",
       "A confusion matrix is a table that summarizes the performance of a classification model on a set of test data for which the true values are known. It allows you to visualize the performance of your classification model by breaking down the predictions into four categories:\n",
       "\n",
       "*   **True Positives (TP):** The number of instances that were correctly predicted as belonging to a particular class.\n",
       "*   **True Negatives (TN):** The number of instances that were correctly predicted as *not* belonging to a particular class.\n",
       "*   **False Positives (FP):** The number of instances that were incorrectly predicted as belonging to a particular class (Type I error).\n",
       "*   **False Negatives (FN):** The number of instances that were incorrectly predicted as *not* belonging to a particular class (Type II error).\n",
       "\n",
       "The matrix is typically structured with the actual (true) classes on the rows and the predicted classes on the columns.\n",
       "\n",
       "### Structure of a Confusion Matrix\n",
       "\n",
       "For a binary classification problem (two classes, e.g., \"Positive\" and \"Negative\"), the confusion matrix looks like this:\n",
       "\n",
       "|               | Predicted Positive | Predicted Negative |\n",
       "| :------------ | :----------------- | :----------------- |\n",
       "| **Actual Positive** | TP                 | FN                 |\n",
       "| **Actual Negative** | FP                 | TN                 |\n",
       "\n",
       "### Importance of a Confusion Matrix\n",
       "\n",
       "Confusion matrices are valuable because they provide a more detailed insight into the model's performance than simple accuracy. They help identify:\n",
       "\n",
       "*   **Which classes are being confused:** Are certain classes frequently misclassified as others?\n",
       "*   **Types of errors:** Is the model more prone to false positives or false negatives?\n",
       "*   **Model strengths and weaknesses:** Where does the model perform well, and where does it struggle?\n",
       "\n",
       "This information is crucial for understanding how to improve the model, such as by collecting more data for specific classes, adjusting class weights, or trying different algorithms.\n",
       "\n",
       "### Example for 4-Class Classification\n",
       "\n",
       "Let's consider a scenario where we are classifying images into four categories: **Cat**, **Dog**, **Bird**, and **Fish**. We have a test set of 100 images, and after running our classification model, we obtain the following confusion matrix:\n",
       "\n",
       "|               | Predicted Cat | Predicted Dog | Predicted Bird | Predicted Fish |\n",
       "| :------------ | :------------ | :------------ | :------------- | :------------- |\n",
       "| **Actual Cat** | 20            | 3             | 1              | 0              |\n",
       "| **Actual Dog** | 2             | 25            | 2              | 1              |\n",
       "| **Actual Bird**| 0             | 1             | 18             | 1              |\n",
       "| **Actual Fish**| 1             | 0             | 2              | 19             |\n",
       "\n",
       "**Explanation of the Example:**\n",
       "\n",
       "*   **Actual Cat (Row 1):**\n",
       "    *   **20** images were actually cats and were correctly predicted as cats (TP for Cat).\n",
       "    *   **3** images were actually cats but were misclassified as dogs (FN for Cat, FP for Dog).\n",
       "    *   **1** image was actually a cat but was misclassified as a bird (FN for Cat, FP for Bird).\n",
       "    *   **0** images were actually cats but were misclassified as fish.\n",
       "\n",
       "*   **Actual Dog (Row 2):**\n",
       "    *   **2** images were actually dogs but were misclassified as cats.\n",
       "    *   **25** images were actually dogs and were correctly predicted as dogs (TP for Dog).\n",
       "    *   **2** images were actually dogs but were misclassified as birds.\n",
       "    *   **1** image was actually a dog but was misclassified as a fish.\n",
       "\n",
       "*   **Actual Bird (Row 3):**\n",
       "    *   **0** images were actually birds but were misclassified as cats.\n",
       "    *   **1** image was actually a bird but was misclassified as a dog.\n",
       "    *   **18** images were actually birds and were correctly predicted as birds (TP for Bird).\n",
       "    *   **1** image was actually a bird but was misclassified as a fish.\n",
       "\n",
       "*   **Actual Fish (Row 4):**\n",
       "    *   **1** image was actually a fish but was misclassified as a cat.\n",
       "    *   **0** images were actually fish but were misclassified as dogs.\n",
       "    *   **2** images were actually fish but were misclassified as birds.\n",
       "    *   **19** images were actually fish and were correctly predicted as fish (TP for Fish).\n",
       "\n",
       "**Observations from this example:**\n",
       "\n",
       "*   The model performs reasonably well for **Cat** and **Dog** classes, with high true positives.\n",
       "*   There's some confusion between **Cat** and **Dog**, and between **Bird** and **Fish**.\n",
       "*   The model seems to struggle slightly with distinguishing **Fish** from **Birds** and **Cats**, as indicated by the non-zero values in those cells.\n",
       "\n",
       "From this matrix, you can calculate various performance metrics like precision, recall, F1-score, and overall accuracy for each class and for the entire model."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## second model output\n",
       "A **confusion matrix** is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known. It allows visualization of the performance of an algorithm.\n",
       "\n",
       "## What is a Confusion Matrix?\n",
       "\n",
       "Here's a breakdown of its key characteristics:\n",
       "\n",
       "*   **Table Structure:** It's a square matrix where both rows and columns represent the classes involved in the classification problem.\n",
       "*   **Rows: Actual Classes:** Each row of the matrix represents the instances in an **actual class** (what the true label of the data point was).\n",
       "*   **Columns: Predicted Classes:** Each column represents the instances in a **predicted class** (what the model predicted the label to be).\n",
       "*   **Diagonal Elements:** The values along the main diagonal (from top-left to bottom-right) represent the number of instances that were **correctly classified**. That is, the predicted label matches the actual label.\n",
       "*   **Off-Diagonal Elements:** The values outside the main diagonal represent the number of instances that were **misclassified**. These show where the model \"confused\" one class for another.\n",
       "\n",
       "### Why is it Useful?\n",
       "\n",
       "While simple **accuracy** tells you the overall correctness of your model, a confusion matrix provides a more detailed breakdown, showing:\n",
       "\n",
       "*   **Types of Errors:** It reveals *what kind* of mistakes the model is making. For example, is it confusing class A with class B, or class A with class C?\n",
       "*   **Class-Specific Performance:** It helps identify which classes are being predicted well and which ones are problematic.\n",
       "*   **Basis for Other Metrics:** It's the foundation for calculating more advanced performance metrics like Precision, Recall (Sensitivity), Specificity, and F1-Score, which offer deeper insights than accuracy alone, especially in imbalanced datasets.\n",
       "\n",
       "---\n",
       "\n",
       "## Short Example for 4-Class Classification\n",
       "\n",
       "Let's imagine we have a model designed to classify images of animals into one of four categories: **Cat**, **Dog**, **Bird**, or **Fish**. We test our model on 100 images (25 of each animal type).\n",
       "\n",
       "Here's a hypothetical confusion matrix:\n",
       "\n",
       "```\n",
       "|             | Predicted Cat | Predicted Dog | Predicted Bird | Predicted Fish |\n",
       "| :---------- | :------------ | :------------ | :------------- | :------------- |\n",
       "| **Actual Cat**    | 20            | 3             | 1              | 1              |\n",
       "| **Actual Dog**    | 2             | 22            | 0              | 1              |\n",
       "| **Actual Bird**   | 1             | 1             | 23             | 0              |\n",
       "| **Actual Fish**   | 0             | 0             | 2              | 23             |\n",
       "```\n",
       "\n",
       "### Interpretation of the Example:\n",
       "\n",
       "*   **Actual Cat (Row 1):**\n",
       "    *   Out of 25 actual cat images, the model correctly predicted **20** as Cat.\n",
       "    *   It misclassified **3** cats as Dogs, **1** as a Bird, and **1** as a Fish.\n",
       "*   **Actual Dog (Row 2):**\n",
       "    *   Out of 25 actual dog images, the model correctly predicted **22** as Dog.\n",
       "    *   It misclassified **2** dogs as Cats and **1** as a Fish.\n",
       "*   **Actual Bird (Row 3):**\n",
       "    *   Out of 25 actual bird images, the model correctly predicted **23** as Bird.\n",
       "    *   It misclassified **1** bird as a Cat and **1** as a Dog.\n",
       "*   **Actual Fish (Row 4):**\n",
       "    *   Out of 25 actual fish images, the model correctly predicted **23** as Fish.\n",
       "    *   It misclassified **2** fish as Birds.\n",
       "\n",
       "### Insights from this Matrix:\n",
       "\n",
       "*   **Good Performance:** The model generally performs well, with high numbers on the diagonal (20, 22, 23, 23 correct predictions for each class).\n",
       "*   **Common Confusion:** The most common misclassification seems to be confusing **Cats with Dogs** (3 actual cats predicted as dogs, 2 actual dogs predicted as cats). This is plausible as they are both mammals and can share similar features.\n",
       "*   **Specific Errors:** The model also occasionally confuses **Fish with Birds** (2 actual fish predicted as birds), which might indicate issues with distinguishing aquatic vs. aerial features or background noise.\n",
       "*   **Strongest Performance:** The model seems to be best at identifying Birds and Fish, with 23 correct predictions each and relatively few misclassifications.\n",
       "\n",
       "This example clearly shows how a confusion matrix provides a much richer understanding of model performance than just a single accuracy score (which would be (20+22+23+23)/100 = 88% in this case)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "my_prompt = [\n",
    "    \"Please answer in markdown. Explain what a confusion matrix is, and give a short example for 4-class classification.\"\n",
    "]\n",
    "\n",
    "resp_lite, log_lite = prompt_gemini(\n",
    "    input_prompt=my_prompt,\n",
    "    model_name=\"gemini-2.5-flash-lite\",\n",
    "    with_tokens_info=True\n",
    ")\n",
    "\n",
    "resp_pro_result = prompt_gemini(\n",
    "    input_prompt=my_prompt,\n",
    "    model_name=\"gemini-2.5-pro\",\n",
    "    with_tokens_info=True\n",
    ")\n",
    "\n",
    "print(\"=== flash-lite ===\")\n",
    "print(resp_lite)\n",
    "print(log_lite)\n",
    "\n",
    "print(\"\\nresp_pro_result:\", resp_pro_result)\n",
    "\n",
    "if resp_pro_result is None:\n",
    "    print(\"\\n2.5-pro 失敗, 改用 gemini-2.5-flash\")\n",
    "    resp_pro, log_pro = prompt_gemini(\n",
    "        input_prompt=my_prompt,\n",
    "        model_name=\"gemini-2.5-flash\",\n",
    "        with_tokens_info=True\n",
    "    )\n",
    "else:\n",
    "    resp_pro, log_pro = resp_pro_result\n",
    "\n",
    "print(\"\\n=== second model ===\")\n",
    "print(resp_pro)\n",
    "print(log_pro)\n",
    "\n",
    "display(Markdown(\"## flash-lite output\\n\" + resp_lite))\n",
    "display(Markdown(\"## second model output\\n\" + resp_pro))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_6_'></a>[**2.2 Structured Output**](#toc0_)\n",
    "\n",
    "By default, an LLM responds with unstructured, free-form text. For data mining, this is often impractical, as we need data in a predictable format to load into tools like a pandas DataFrame for analysis. **Structured output** is a powerful feature that forces the model to return its response in a specific, machine-readable format, such as JSON.\n",
    "\n",
    "The key to enabling this is to provide the model with a **response schema**. This schema acts as a strict template or blueprint that the model's output must conform to. Instead of generating a paragraph, the model will fill in the fields defined in your schema with the relevant information it extracts from the prompt.\n",
    "\n",
    "In the following code, we define this schema using Python classes. Think of each class as defining a JSON object:\n",
    "*   The **attributes** of the class (e.g., `topic_name`, `sub_title`) become the keys in the final JSON object.\n",
    "*   The **type hints** for those attributes (e.g., `str`, `list`) tell the model what kind of data is expected for each key's value.\n",
    "\n",
    "We can even nest these classes inside one another to create complex, hierarchical JSON structures. This allows us to precisely control the format of the output, transforming the LLM from a simple text generator into a reliable tool for automated and structured data extraction.\n",
    "\n",
    "[Gemini's Structured Output Documentation](https://ai.google.dev/gemini-api/docs/structured-output)\n",
    "\n",
    "For data validation of schemas Gemini API uses the Pydantic library, for more documentation on it you can check: [Pydantic](https://docs.pydantic.dev/latest/) \n",
    "\n",
    "[JSON Format Documentation](https://docs.python.org/3/library/json.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "# We define our structure schema that Gemini should follow for the output response\n",
    "\n",
    "# Subsections on the topics we query\n",
    "class Subsection(BaseModel):\n",
    "    sub_title: str\n",
    "    sub_explanation: str\n",
    "\n",
    "# The top-level structure for the entire topic analysis\n",
    "class Topic(BaseModel):\n",
    "    topic_name: str\n",
    "    subsections: list[Subsection]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"topic_name\": \"Machine Learning\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Types of Machine Learning\",\n",
      "        \"sub_explanation\": \"Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Applications\",\n",
      "        \"sub_explanation\": \"ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Data Centers\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Key Components\",\n",
      "        \"sub_explanation\": \"Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Purpose\",\n",
      "        \"sub_explanation\": \"Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Large Language Models (LLMs)\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"Definition\",\n",
      "        \"sub_explanation\": \"Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Capabilities\",\n",
      "        \"sub_explanation\": \"LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Underlying Technology\",\n",
      "        \"sub_explanation\": \"LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.\"\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"topic_name\": \"Relationship Between Machine Learning, Data Centers, and LLMs\",\n",
      "    \"subsections\": [\n",
      "      {\n",
      "        \"sub_title\": \"LLMs as a Product of Machine Learning\",\n",
      "        \"sub_explanation\": \"LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Data Centers as the Foundation for LLMs and ML\",\n",
      "        \"sub_explanation\": \"Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure – high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power – to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.\"\n",
      "      },\n",
      "      {\n",
      "        \"sub_title\": \"Interdependence\",\n",
      "        \"sub_explanation\": \"In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "input_prompt = [\"Explain what are machine learning, data centers, llms and how do they relate to each other.\"]\n",
    "text_response = prompt_gemini(input_prompt = input_prompt, schema = list[Topic])\n",
    "print(text_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'topic_name': 'Machine Learning', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': \"Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention.\"}, {'sub_title': 'Types of Machine Learning', 'sub_explanation': 'Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties).'}, {'sub_title': 'Applications', 'sub_explanation': 'ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis.'}]}, {'topic_name': 'Data Centers', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations.'}, {'sub_title': 'Key Components', 'sub_explanation': 'Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures.'}, {'sub_title': 'Purpose', 'sub_explanation': 'Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations.'}]}, {'topic_name': 'Large Language Models (LLMs)', 'subsections': [{'sub_title': 'Definition', 'sub_explanation': 'Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks.'}, {'sub_title': 'Capabilities', 'sub_explanation': 'LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data.'}, {'sub_title': 'Underlying Technology', 'sub_explanation': 'LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively.'}]}, {'topic_name': 'Relationship Between Machine Learning, Data Centers, and LLMs', 'subsections': [{'sub_title': 'LLMs as a Product of Machine Learning', 'sub_explanation': 'LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model.'}, {'sub_title': 'Data Centers as the Foundation for LLMs and ML', 'sub_explanation': 'Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure – high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power – to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale.'}, {'sub_title': 'Interdependence', 'sub_explanation': 'In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers.'}]}]\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Now the response can be parsed to a python object using the JSON dictionary structure loading\n",
    "structured_resp = json.loads(text_response)\n",
    "print(structured_resp)\n",
    "print(type(structured_resp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Machine Learning \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Machine learning (ML) is a subset of artificial intelligence (AI) that focuses on building systems that can learn from and make decisions based on data. Instead of being explicitly programmed, ML algorithms use statistical techniques to enable systems to 'learn' from data, identify patterns, and make predictions or decisions without human intervention. \n",
      "\n",
      "\t Types of Machine Learning \n",
      "\n",
      "\t\t Common types include supervised learning (learning from labeled data), unsupervised learning (finding patterns in unlabeled data), and reinforcement learning (learning through trial and error with rewards and penalties). \n",
      "\n",
      "\t Applications \n",
      "\n",
      "\t\t ML is used in a wide range of applications, such as image recognition, natural language processing, recommendation systems, fraud detection, and medical diagnosis. \n",
      "\n",
      "Data Centers \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t A data center is a dedicated physical facility that an organization uses to house its critical IT infrastructure, including servers, storage systems, networking equipment, and related components. These facilities are designed to provide a secure, reliable, and controlled environment for computing operations. \n",
      "\n",
      "\t Key Components \n",
      "\n",
      "\t\t Essential components include servers, storage devices, network switches and routers, power supplies (including UPS and generators), cooling systems (HVAC), and physical security measures. \n",
      "\n",
      "\t Purpose \n",
      "\n",
      "\t\t Data centers serve as the central hub for data storage, processing, and management, enabling businesses to run applications, host websites, and manage their digital operations. \n",
      "\n",
      "Large Language Models (LLMs) \n",
      "\n",
      "\t Definition \n",
      "\n",
      "\t\t Large Language Models (LLMs) are a type of artificial intelligence model that are trained on massive amounts of text data. They are designed to understand, generate, and manipulate human language. LLMs are characterized by their enormous size (billions or trillions of parameters) and their ability to perform a wide variety of natural language processing tasks. \n",
      "\n",
      "\t Capabilities \n",
      "\n",
      "\t\t LLMs can perform tasks such as text generation, translation, summarization, question answering, code generation, and creative writing. They learn complex linguistic patterns, grammar, facts, and reasoning abilities from their training data. \n",
      "\n",
      "\t Underlying Technology \n",
      "\n",
      "\t\t LLMs are typically built using deep learning architectures, most notably the Transformer architecture, which allows them to process sequential data like text very effectively. \n",
      "\n",
      "Relationship Between Machine Learning, Data Centers, and LLMs \n",
      "\n",
      "\t LLMs as a Product of Machine Learning \n",
      "\n",
      "\t\t LLMs are a sophisticated application and outcome of machine learning research and development. The techniques used to train LLMs, such as deep learning and neural networks, are core machine learning concepts. Therefore, LLMs are a specific, advanced type of machine learning model. \n",
      "\n",
      "\t Data Centers as the Foundation for LLMs and ML \n",
      "\n",
      "\t\t Training and running LLMs, as well as many other complex machine learning models, requires immense computational power and vast amounts of data storage. Data centers provide the necessary infrastructure – high-performance servers, specialized hardware (like GPUs and TPUs), robust networking, and reliable power – to handle these computationally intensive tasks. Without data centers, it would be practically impossible to develop, train, and deploy LLMs at scale. \n",
      "\n",
      "\t Interdependence \n",
      "\n",
      "\t\t In essence, machine learning is the field of study and the set of techniques. LLMs are a powerful manifestation of these techniques. Data centers are the physical environments and infrastructure that enable the training, deployment, and operation of both general machine learning models and highly demanding LLMs. LLMs rely on ML principles, and both ML and LLMs rely heavily on the resources provided by data centers. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# So now we have an object that we can explore/use in a pythonic way for our purposes\n",
    "for topic in structured_resp:\n",
    "    print(topic[\"topic_name\"], \"\\n\")\n",
    "    # We can access each subsection as well\n",
    "    for subsection in topic[\"subsections\"]:\n",
    "        print(\"\\t\", subsection[\"sub_title\"], \"\\n\")\n",
    "        print(\"\\t\\t\", subsection[\"sub_explanation\"], \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### <a id='toc1_5_6_1_1_'></a>[**>>> Exercise 2 (Take home):**](#toc0_)\n",
    "\n",
    "Try a prompt with your own schema structure, it needs to be completely different to the example. It should show an intuitive way to represent the text output of the model based on the prompt you chose. See the documentation for reference: https://ai.google.dev/gemini-api/docs/structured-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"city\": \"Taipei\",\n",
      "  \"days\": 2,\n",
      "  \"budget_twd\": 3000,\n",
      "  \"transport\": [\"MRT\", \"Bus\", \"Walking\"],\n",
      "  \"daily_plans\": [\n",
      "    {\n",
      "      \"day\": 1,\n",
      "      \"area\": \"Zhongzheng District & Wanhua District\",\n",
      "      \"places\": [\n",
      "        {\n",
      "          \"name\": \"Chiang Kai-shek Memorial Hall\",\n",
      "          \"reason\": \"Iconic landmark with historical significance and beautiful gardens.\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"Longshan Temple\",\n",
      "          \"reason\": \"A vibrant and historically rich temple, offering a glimpse into local religious practices.\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"Ximending\",\n",
      "          \"reason\": \"A bustling youth-oriented shopping and entertainment district.\"\n",
      "        }\n",
      "      ],\n",
      "      \"activities\": [\n",
      "        {\n",
      "          \"time\": \"09:00\",\n",
      "          \"title\": \"Explore CKS Memorial Hall\",\n",
      "          \"notes\": \"Watch the changing of the guard ceremony if possible.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"11:30\",\n",
      "          \"title\": \"Travel to Longshan Temple\",\n",
      "          \"notes\": \"Take the MRT to Longshan Temple Station.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"12:00\",\n",
      "          \"title\": \"Visit Longshan Temple\",\n",
      "          \"notes\": \"Observe the architecture and local worshippers.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"13:30\",\n",
      "          \"title\": \"Lunch near Longshan Temple\",\n",
      "          \"notes\": \"Try some local snacks or a simple meal.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"14:30\",\n",
      "          \"title\": \"Explore Ximending\",\n",
      "          \"notes\": \"Walk around, browse shops, and soak in the atmosphere.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"18:00\",\n",
      "          \"title\": \"Dinner in Ximending\",\n",
      "          \"notes\": \"Plenty of affordable options available.\"\n",
      "        }\n",
      "      ],\n",
      "      \"food_suggestions\": [\n",
      "        \"Xiao Long Bao\",\n",
      "        \"Beef Noodle Soup\",\n",
      "        \"Bubble Tea\",\n",
      "        \"Stinky Tofu (for the adventurous!)\"\n",
      "      ]\n",
      "    },\n",
      "    {\n",
      "      \"day\": 2,\n",
      "      \"area\": \"Da'an District & Xinyi District\",\n",
      "      \"places\": [\n",
      "        {\n",
      "          \"name\": \"National Taiwan University (NTU)\",\n",
      "          \"reason\": \"Explore Taiwan's premier university campus, known for its beautiful greenery and architecture.\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"Daan Forest Park\",\n",
      "          \"reason\": \"A large urban park offering a peaceful escape.\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"Taipei 101 (Observatory optional)\",\n",
      "          \"reason\": \"Iconic skyscraper offering panoramic city views. Observatory visit is optional due to budget.\"\n",
      "        },\n",
      "        {\n",
      "          \"name\": \"Sun Yat-sen Memorial Hall\",\n",
      "          \"reason\": \"Another significant memorial hall with views of Taipei 101.\"\n",
      "        }\n",
      "      ],\n",
      "      \"activities\": [\n",
      "        {\n",
      "          \"time\": \"09:30\",\n",
      "          \"title\": \"Visit National Taiwan University\",\n",
      "          \"notes\": \"Stroll through the campus and visit the Azalea Garden (seasonal).\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"11:30\",\n",
      "          \"title\": \"Walk to Daan Forest Park\",\n",
      "          \"notes\": \"Enjoy a relaxing walk or sit by the lake.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"13:00\",\n",
      "          \"title\": \"Lunch near Daan Forest Park\",\n",
      "          \"notes\": \"Find a local eatery or a student-friendly cafe.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"14:30\",\n",
      "          \"title\": \"Travel to Xinyi District\",\n",
      "          \"notes\": \"Take the MRT to Taipei 101/World Trade Center Station.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"15:00\",\n",
      "          \"title\": \"View Taipei 101 from outside\",\n",
      "          \"notes\": \"Admire the architecture. Consider visiting the Sun Yat-sen Memorial Hall for a free view of Taipei 101.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"17:00\",\n",
      "          \"title\": \"Explore Xinyi District\",\n",
      "          \"notes\": \"Window shop at the high-end malls or visit the department store food courts.\"\n",
      "        },\n",
      "        {\n",
      "          \"time\": \"18:30\",\n",
      "          \"title\": \"Dinner in Xinyi District\",\n",
      "          \"notes\": \"Look for more affordable food court options or street food.\"\n",
      "        }\n",
      "      ],\n",
      "      \"food_suggestions\": [\n",
      "        \"Lu Rou Fan (Braised Pork Rice)\",\n",
      "        \"Gua Bao (Taiwanese Hamburger)\",\n",
      "        \"Mango Shaved Ice (seasonal)\",\n",
      "        \"Various night market snacks if time permits\"\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"warnings\": [\n",
      "    \"Taipei can be hot and humid, especially in summer. Stay hydrated.\",\n",
      "    \"Wear comfortable shoes as you will be doing a lot of walking.\",\n",
      "    \"Be mindful of your belongings in crowded areas.\",\n",
      "    \"Check MRT and bus schedules for efficient travel.\",\n",
      "    \"The budget is tight, prioritize free activities and affordable food options.\"\n",
      "  ]\n",
      "}\n",
      "<class 'dict'>\n",
      "Taipei 2 3000\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "from pydantic import BaseModel\n",
    "import json\n",
    "\n",
    "class Place(BaseModel):\n",
    "    name: str\n",
    "    reason: str\n",
    "\n",
    "class Activity(BaseModel):\n",
    "    time: str\n",
    "    title: str\n",
    "    notes: str\n",
    "\n",
    "class DayPlan(BaseModel):\n",
    "    day: int\n",
    "    area: str\n",
    "    places: list[Place]\n",
    "    activities: list[Activity]\n",
    "    food_suggestions: list[str]\n",
    "\n",
    "class TripPlan(BaseModel):\n",
    "    city: str\n",
    "    days: int\n",
    "    budget_twd: int\n",
    "    transport: list[str]\n",
    "    daily_plans: list[DayPlan]\n",
    "    warnings: list[str]\n",
    "\n",
    "input_prompt = [\n",
    "    \"Please output JSON only. Plan a 2-day trip in Taipei for a student. Budget is 3000 TWD. Include places, timetable, and food suggestions.\"\n",
    "]\n",
    "\n",
    "text_response = prompt_gemini(\n",
    "    input_prompt=input_prompt,\n",
    "    schema=TripPlan,\n",
    "    model_name=\"gemini-2.5-flash-lite\"\n",
    ")\n",
    "\n",
    "print(text_response)\n",
    "\n",
    "parsed = json.loads(text_response)\n",
    "print(type(parsed))\n",
    "print(parsed[\"city\"], parsed[\"days\"], parsed[\"budget_twd\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2 說明:\n",
    "- 我用自訂 schema (TripPlan) 強制模型輸出 JSON, 內容包含 city, days, budget_twd, transport, daily_plans, warnings。\n",
    "- daily_plans 內再分 places 與 activities, 讓行程可以直接用程式轉成表格或做後續分析。\n",
    "- 這種結構化輸出比純文字更適合資料探勘, 因為欄位固定, 可直接丟進 pandas。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_7_'></a>[**2.3 Information Extraction and Grounding:**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "When using LLMs to extract structured data from text, two main challenges arise:\n",
    "\n",
    "1.  **Trust:** LLMs can \"hallucinate\" or invent information. We need to ensure the extracted data is accurate and comes directly from the source text.\n",
    "2.  **Scalability:** We need a reliable way to extract complex information consistently from thousands of large, messy documents.\n",
    "\n",
    "The solution to these challenges is **grounding**—the process of linking every piece of extracted data back to its specific origin in the source document. This creates a verifiable audit trail, building trust in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### <a id='toc1_5_7_1_'></a>[**`langextract`: A Library for Grounded Extraction**](#toc0_)\n",
    "\n",
    "**`langextract`** is an open-source Python library from Google designed to create trustworthy data extraction pipelines. It uses LLMs to convert unstructured text into structured data with a focus on reliability and traceability.\n",
    "\n",
    "**Key Features:**\n",
    "\n",
    "*   **Precise Grounding:** Its core feature. It maps every extracted item to its exact character position in the original text, allowing for easy verification.\n",
    "*   **Reliable Structured Output:** Uses examples (few-shot prompting) to ensure the LLM's output consistently follows a predefined format.\n",
    "*   **Adaptable & No Fine-Tuning:** Can be adapted to any domain (e.g., legal, medical) simply by changing the examples and instructions, without needing to retrain a model.\n",
    "*   **Handles Long Documents:** Built to process lengthy texts that might exceed an LLM's standard context window.\n",
    "*   **Flexible LLM Support:** It is model-agnostic and works with various LLMs like Gemini, OpenAI models, and even local open-source models through Ollama.\n",
    "\n",
    "**`Github repository:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### <a id='toc1_5_7_1_1_'></a>[**2.3.1 Using PDF Documents:**](#toc0_)\n",
    "\n",
    "For PDF Document information extraction we are going to use the `pymupdf` library. Documentation: [pymupdf](https://pymupdf.readthedocs.io/en/latest/)\n",
    "\n",
    "And then we are going to pass it on to langextract to get insights on the document's content.\n",
    "\n",
    "We can also process documents using Gemini, for more information you can check their documentation: [Document Understanding](https://ai.google.dev/gemini-api/docs/document-processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted text from './data/documents/doc_example_review_interstellar.pdf'\n"
     ]
    }
   ],
   "source": [
    "import pymupdf\n",
    "# Extract text from the PDF and format it for the prompt\n",
    "# This is a review from the movie interstellar\n",
    "pdf_path = \"./data/documents/doc_example_review_interstellar.pdf\"\n",
    "formatted_text = \"\"\n",
    "try:\n",
    "    doc = pymupdf.open(pdf_path)\n",
    "    # In case the PDF documents have more than one page, in this example it only has one\n",
    "    for i, page in enumerate(doc):\n",
    "        text = page.get_text(\"text\")\n",
    "        # Format follows the prompt's requirement: **Page X** \"\"\"document's text\"\"\"\n",
    "        formatted_text += f'**Page {i + 1}**\\n'\n",
    "        formatted_text += f'\"\"\"\\n{text.strip()}\\n\"\"\"\\n\\n'\n",
    "    doc.close()\n",
    "    print(f\"✓ Extracted text from '{pdf_path}'\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not read PDF: {e}\")\n",
    "    formatted_text = \"Error: Could not process PDF file.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Page 1**\n",
      "\"\"\"\n",
      "Dan Baldwin\n",
      "Group 4\n",
      "Auteur Review - Interstellar \n",
      "I believe Christopher Nolan: the director behind the 2014 sci-ﬁ/adventure cinematic ‘Interstellar,’ \n",
      "to be a very intellectual and imaginative inventive talent.  \n",
      "His style in his previous ﬁlms sets characters in epic unique locations, with gargantuan issues to \n",
      "face, and artistically impresses the audience with how the characters solve their problems. For \n",
      "example, in Nolan’s 2010 ﬁlm ‘Inception,’ he tackles the idea of dreams, and sets his characters \n",
      "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
      "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
      "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
      "themselves and corridors spinning, without seeming unrealistic. \n",
      "This brain-racking epic theme is once again evident in ‘Interstellar,’ as Nolan sets his characters \n",
      "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
      "uninhabitable. So, ex-NASA pilot ‘Cooper’ (Matthew McConaughey) is summoned back to space \n",
      "travel in a bid to ﬁnd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
      "black hole orbiting Saturn can transport them further into space to land on these potential \n",
      "planets. \n",
      "Throughout the ﬂick, the crew explore multiple worlds - again feeding Nolan’s mind more \n",
      "opportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \n",
      "‘Brand,’ (Anne Hathaway) and ‘Romilly,’ (David Gyasi) visit initially seems like an inﬁnite sea of two \n",
      "feet deep water. Not threatening at all right? Well think again, because the crew suddenly ﬁnd out \n",
      "that a giant 100ft tidal wave is about to hit them, and they have minutes to ﬂy away. Nolan further \n",
      "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
      "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
      "At the climax of the ﬁlm, the crew end up sending themselves through a black hole into a \n",
      "tesseract (a 3D representation of a larger dimension) to ﬁnd the ‘secret to harnessing gravity’ \n",
      "which will let the human race bend space-time in order to survive oﬀ earth. I know. Mental. \n",
      "The imagination that Nolan possesses and implicates into ‘Interstellar’ is farfetched and \n",
      "wonderful, not only impressing his audience with the appealing visuals he creates, but induces \n",
      "them to think and discuss what is going on due its scientiﬁc depth. Personally, as someone who is \n",
      "bamboozled by the idea of how big the universe is, I ﬁnd it unendingly entertaining to repeatedly \n",
      "watch this ﬁlm and understanding it more each time, and can only hope the technology portrayed \n",
      "will one day come true. \n",
      "Overall, ‘Interstellar’ is a clear example of Nolan’s auteur talent, as he once again ﬁgments yet \n",
      "another cluster of conditions for us to marvel at. With a fantastic score from world famous \n",
      "composer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \n",
      "we stress over how we are all going to be saved once again.\n",
      "\"\"\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(formatted_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our prompt and examples based on our required type of data, in this case we are going to do it having `movie reviews` in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langextract as lx\n",
    "import textwrap\n",
    "\n",
    "# Defining the extraction prompt for \"movie review\" type of data\n",
    "prompt = textwrap.dedent(\"\"\"\\\n",
    "    Extract specific opinions and their impact on the audience from this movie review.\n",
    "    Important: Use exact text verbatim from the input for extraction_text. Do not paraphrase.\n",
    "    Extract entities in order of appearance with no overlapping text spans.\n",
    "\n",
    "    Use the 'opinion_statement' class for direct judgments about film elements (like plot, score, or acting).\n",
    "    - 'subject' should be the element being reviewed.\n",
    "    - 'sentiment' should be Positive, Negative, or Neutral.\n",
    "    - 'key_phrase' should be the core descriptive words.\n",
    "\n",
    "    Use the 'audience_impact' class for phrases describing the effect on the viewer.\n",
    "    - 'emotion_evoked' should be the feeling or reaction (e.g., stress, joy, confusion).\n",
    "    - 'causal_element' is what part of the film caused the reaction.\n",
    "    - 'target_audience' is who was affected (e.g., 'the audience', 'the reviewer').\n",
    "    \"\"\")\n",
    "\n",
    "# Providing high-quality examples to guide the model\n",
    "# These examples show the model exactly how to differentiate between the two classes\n",
    "examples = [\n",
    "    # Example 1: Demonstrates a positive opinion on the plot and its direct impact on the reviewer\n",
    "    lx.data.ExampleData(\n",
    "        text=\"The film boasts a truly clever plot that kept me guessing until the very end.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"a truly clever plot\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The plot\",\n",
    "                    \"sentiment\": \"Positive\",\n",
    "                    \"key_phrase\": \"truly clever\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"kept me guessing until the very end\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"engaged\", \"curious\"],\n",
    "                    \"causal_element\": \"The plot\",\n",
    "                    \"target_audience\": \"the reviewer\"\n",
    "                }\n",
    "            ),\n",
    "        ]\n",
    "    ),\n",
    "    # Example 2: Shows a negative opinion and a separate audience impact caused by the soundtrack\n",
    "    lx.data.ExampleData(\n",
    "        text=\"Unfortunately, the dialogue felt clunky and unnatural, and the jarring soundtrack made the audience jump.\",\n",
    "        extractions=[\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"opinion_statement\",\n",
    "                extraction_text=\"the dialogue felt clunky and unnatural\",\n",
    "                attributes={\n",
    "                    \"subject\": \"The dialogue\",\n",
    "                    \"sentiment\": \"Negative\",\n",
    "                    \"key_phrase\": \"clunky and unnatural\"\n",
    "                }\n",
    "            ),\n",
    "            lx.data.Extraction(\n",
    "                extraction_class=\"audience_impact\",\n",
    "                extraction_text=\"made the audience jump\",\n",
    "                attributes={\n",
    "                    \"emotion_evoked\": [\"startled\", \"on edge\"],\n",
    "                    \"causal_element\": \"The soundtrack\",\n",
    "                    \"target_audience\": \"the audience\"\n",
    "                }\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define our main function to call for langextract information extraction, note that there are some constants in the functions that we are not going to change for the example but it would be required to explore and understand in the exercise. In this function we obtain the resulting raw extracted information into a .jsonl file and the visualization into a .html file. Check the documentation for more information.\n",
    "\n",
    "The files will be saved in the following directory: `results/info_extractions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import langextract as lx\n",
    "\n",
    "# We define our main langextract function \n",
    "def grounded_info_extraction(input_documents, prompt, examples, file_name, model_id =\"gemini-2.5-flash-lite\", extraction_passes = 1, max_workers = 5, max_char_buffer = 2000):\n",
    "    result = lx.extract(\n",
    "        text_or_documents=input_documents,\n",
    "        prompt_description=prompt,\n",
    "        examples=examples,\n",
    "        model_id=model_id,\n",
    "        extraction_passes=extraction_passes,    # Improves recall through multiple passes over the same text, needs temperature above 0.0\n",
    "        max_workers=max_workers,         # Parallel processing for speed, remember there are API call rate limits, so do not abuse\n",
    "        max_char_buffer=max_char_buffer    # Smaller contexts for better accuracy, currently: 1000 characters per batch\n",
    "    )\n",
    "\n",
    "    # Display results\n",
    "    print(f\"Extracted {len(result.extractions)} entities:\\n\")\n",
    "    for extraction in result.extractions:\n",
    "        print(f\"• {extraction.extraction_class}: '{extraction.extraction_text}'\")\n",
    "        if extraction.attributes:\n",
    "            for key, value in extraction.attributes.items():\n",
    "                print(f\"  - {key}: {value}\")\n",
    "    \n",
    "    output_dir = \"./results/info_extractions\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save results to JSONL\n",
    "    lx.io.save_annotated_documents([result], output_name=f\"{file_name}.jsonl\", output_dir=output_dir)\n",
    "\n",
    "    # Generate interactive visualization\n",
    "    html_content = lx.visualize(f\"{output_dir}/{file_name}.jsonl\")\n",
    "    with open(f\"{output_dir}/{file_name}_vis.html\", \"w\") as f:\n",
    "        if hasattr(html_content, 'data'):\n",
    "            f.write(html_content.data)\n",
    "        else:\n",
    "            f.write(html_content)\n",
    "\n",
    "    print(f\"✓ Visualization saved to {output_dir}/{file_name}_vis.html\")\n",
    "    \n",
    "    # returning html content for display\n",
    "    return html_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:google_genai._api_client:Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 13 entities:\n",
      "\n",
      "• opinion_statement: 'a very intellectual and imaginative inventive talent'\n",
      "  - subject: Christopher Nolan\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: very intellectual and imaginative inventive talent\n",
      "• opinion_statement: 'artistically impresses the audience'\n",
      "  - subject: Nolan's style\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: artistically impresses\n",
      "• opinion_statement: 'This brain-racking epic theme is once again evident in ‘Interstellar,’'\n",
      "  - subject: The theme\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: brain-racking epic theme\n",
      "• opinion_statement: 'crazy scenarios'\n",
      "  - subject: Nolan's mind\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: crazy\n",
      "• opinion_statement: 'Not threatening at all right?'\n",
      "  - subject: The planet\n",
      "  - sentiment: Neutral\n",
      "  - key_phrase: Not threatening at all\n",
      "• opinion_statement: 'a giant 100ft tidal wave is about to hit them'\n",
      "  - subject: The tidal wave\n",
      "  - sentiment: Negative\n",
      "  - key_phrase: giant 100ft tidal wave\n",
      "• audience_impact: 'minutes to ﬂy away'\n",
      "  - emotion_evoked: ['stress', 'urgency']\n",
      "  - causal_element: The tidal wave\n",
      "  - target_audience: the crew\n",
      "• opinion_statement: 'farfetched and wonderful'\n",
      "  - subject: The imagination that Nolan possesses and implicates into ‘Interstellar’\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: farfetched and wonderful\n",
      "• audience_impact: 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientiﬁc depth'\n",
      "  - emotion_evoked: ['impressed', 'thoughtful', 'engaged']\n",
      "  - causal_element: The appealing visuals and scientific depth\n",
      "  - target_audience: his audience\n",
      "• audience_impact: 'I ﬁnd it unendingly entertaining to repeatedly watch this ﬁlm and understanding it more each time'\n",
      "  - emotion_evoked: ['entertained', 'intellectually stimulated']\n",
      "  - causal_element: The film's complexity and depth\n",
      "  - target_audience: the reviewer\n",
      "• opinion_statement: 'a clear example of Nolan’s auteur talent'\n",
      "  - subject: ‘Interstellar’\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: clear example of Nolan’s auteur talent\n",
      "• opinion_statement: 'fantastic score'\n",
      "  - subject: The score\n",
      "  - sentiment: Positive\n",
      "  - key_phrase: fantastic\n",
      "• audience_impact: 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again'\n",
      "  - emotion_evoked: ['captivated', 'stressed']\n",
      "  - causal_element: His epic, orchestral theme\n",
      "  - target_audience: the audience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Saving to \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m: 1 docs [00:00, 141.73 docs/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m✓\u001b[0m Saved \u001b[1m1\u001b[0m documents to \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[94m\u001b[1mLangExtract\u001b[0m: Loading \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m: 100%|█████████▉| 8.58k/8.58k [00:00<00:00, 241kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m✓\u001b[0m Loaded \u001b[1m1\u001b[0m documents from \u001b[92mresults\\info_extractions\\review_extraction_example.jsonl\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'cp950' codec can't encode character '\\ufb01' in position 3642: illegal multibyte sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeEncodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m html_content = \u001b[43mgrounded_info_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatted_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreview_extraction_example\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mgrounded_info_extraction\u001b[39m\u001b[34m(input_documents, prompt, examples, file_name, model_id, extraction_passes, max_workers, max_char_buffer)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_vis.html\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(html_content, \u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         f.write(html_content.data)\n\u001b[32m     34\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     35\u001b[39m         f.write(html_content)\n",
      "\u001b[31mUnicodeEncodeError\u001b[39m: 'cp950' codec can't encode character '\\ufb01' in position 3642: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "html_content = grounded_info_extraction(formatted_text, prompt, examples, \"review_extraction_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'extractions': [{'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a very intellectual and imaginative inventive talent',\n",
       "   'char_interval': {'start_pos': 172, 'end_pos': 224},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'Christopher Nolan',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'very intellectual and imaginative inventive talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'artistically impresses the audience',\n",
       "   'char_interval': {'start_pos': 338, 'end_pos': 373},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's style\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'artistically impresses'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'This brain-racking epic theme is once again evident in ‘Interstellar,’',\n",
       "   'char_interval': {'start_pos': 878, 'end_pos': 948},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The theme',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'brain-racking epic theme'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'crazy scenarios',\n",
       "   'char_interval': {'start_pos': 1484, 'end_pos': 1499},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': \"Nolan's mind\",\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'crazy'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'Not threatening at all right?',\n",
       "   'char_interval': {'start_pos': 1676, 'end_pos': 1705},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The planet',\n",
       "    'sentiment': 'Neutral',\n",
       "    'key_phrase': 'Not threatening at all'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a giant 100ft tidal wave is about to hit them',\n",
       "   'char_interval': {'start_pos': 1764, 'end_pos': 1809},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The tidal wave',\n",
       "    'sentiment': 'Negative',\n",
       "    'key_phrase': 'giant 100ft tidal wave'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'minutes to ﬂy away',\n",
       "   'char_interval': {'start_pos': 1825, 'end_pos': 1843},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 7,\n",
       "   'group_index': 6,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['stress', 'urgency'],\n",
       "    'causal_element': 'The tidal wave',\n",
       "    'target_audience': 'the crew'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'farfetched and wonderful',\n",
       "   'char_interval': {'start_pos': 2418, 'end_pos': 2443},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 1,\n",
       "   'group_index': 0,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The imagination that Nolan possesses and implicates into ‘Interstellar’',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'farfetched and wonderful'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scientiﬁc depth',\n",
       "   'char_interval': {'start_pos': 2445, 'end_pos': 2596},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 2,\n",
       "   'group_index': 1,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['impressed', 'thoughtful', 'engaged'],\n",
       "    'causal_element': 'The appealing visuals and scientific depth',\n",
       "    'target_audience': 'his audience'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'I ﬁnd it unendingly entertaining to repeatedly watch this ﬁlm and understanding it more each time',\n",
       "   'char_interval': {'start_pos': 2680, 'end_pos': 2778},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 3,\n",
       "   'group_index': 2,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['entertained',\n",
       "     'intellectually stimulated'],\n",
       "    'causal_element': \"The film's complexity and depth\",\n",
       "    'target_audience': 'the reviewer'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'a clear example of Nolan’s auteur talent',\n",
       "   'char_interval': {'start_pos': 2876, 'end_pos': 2916},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 4,\n",
       "   'group_index': 3,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': '‘Interstellar’',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'clear example of Nolan’s auteur talent'}},\n",
       "  {'extraction_class': 'opinion_statement',\n",
       "   'extraction_text': 'fantastic score',\n",
       "   'char_interval': {'start_pos': 3006, 'end_pos': 3021},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 5,\n",
       "   'group_index': 4,\n",
       "   'description': None,\n",
       "   'attributes': {'subject': 'The score',\n",
       "    'sentiment': 'Positive',\n",
       "    'key_phrase': 'fantastic'}},\n",
       "  {'extraction_class': 'audience_impact',\n",
       "   'extraction_text': 'sets the audience in the palm of his hands as we stress over how we are all going to be saved once again',\n",
       "   'char_interval': {'start_pos': 3090, 'end_pos': 3195},\n",
       "   'alignment_status': 'match_exact',\n",
       "   'extraction_index': 6,\n",
       "   'group_index': 5,\n",
       "   'description': None,\n",
       "   'attributes': {'emotion_evoked': ['captivated', 'stressed'],\n",
       "    'causal_element': 'His epic, orchestral theme',\n",
       "    'target_audience': 'the audience'}}],\n",
       " 'text': '**Page 1**\\n\"\"\"\\nDan Baldwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-ﬁ/adventure cinematic ‘Interstellar,’ \\nto be a very intellectual and imaginative inventive talent.  \\nHis style in his previous ﬁlms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience with how the characters solve their problems. For \\nexample, in Nolan’s 2010 ﬁlm ‘Inception,’ he tackles the idea of dreams, and sets his characters \\ndiving through dreams within dreams within even more dreams to complete their goals. Because \\nthis idea is so farfetched, and dreams are a subject in which science has made little factual \\ndiscovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\nThis brain-racking epic theme is once again evident in ‘Interstellar,’ as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex-NASA pilot ‘Cooper’ (Matthew McConaughey) is summoned back to space \\ntravel in a bid to ﬁnd a new planet for the species to inhabit. Luckily for Cooper and his team, a \\nblack hole orbiting Saturn can transport them further into space to land on these potential \\nplanets. \\nThroughout the ﬂick, the crew explore multiple worlds - again feeding Nolan’s mind more \\nopportunities to create crazy scenarios. For example, one planet that Cooper and his friends, \\n‘Brand,’ (Anne Hathaway) and ‘Romilly,’ (David Gyasi) visit initially seems like an inﬁnite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly ﬁnd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to ﬂy away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \\nAt the climax of the ﬁlm, the crew end up sending themselves through a black hole into a \\ntesseract (a 3D representation of a larger dimension) to ﬁnd the ‘secret to harnessing gravity’ \\nwhich will let the human race bend space-time in order to survive oﬀ earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into ‘Interstellar’ is farfetched and \\nwonderful, not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scientiﬁc depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I ﬁnd it unendingly entertaining to repeatedly \\nwatch this ﬁlm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, ‘Interstellar’ is a clear example of Nolan’s auteur talent, as he once again ﬁgments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again.\\n\"\"\"\\n\\n',\n",
       " 'document_id': 'doc_30bc5f79'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# We can also observe the structure of the raw extracted data\n",
    "with open(\"./results/info_extractions/review_extraction_example.jsonl\", \"r\") as f:\n",
    "    content_extracted_raw = json.load(f)\n",
    "content_extracted_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".lx-highlight { position: relative; border-radius:3px; padding:1px 2px;}\n",
       ".lx-highlight .lx-tooltip {\n",
       "  visibility: hidden;\n",
       "  opacity: 0;\n",
       "  transition: opacity 0.2s ease-in-out;\n",
       "  background: #333;\n",
       "  color: #fff;\n",
       "  text-align: left;\n",
       "  border-radius: 4px;\n",
       "  padding: 6px 8px;\n",
       "  position: absolute;\n",
       "  z-index: 1000;\n",
       "  bottom: 125%;\n",
       "  left: 50%;\n",
       "  transform: translateX(-50%);\n",
       "  font-size: 12px;\n",
       "  max-width: 240px;\n",
       "  white-space: normal;\n",
       "  box-shadow: 0 2px 6px rgba(0,0,0,0.3);\n",
       "}\n",
       ".lx-highlight:hover .lx-tooltip { visibility: visible; opacity:1; }\n",
       ".lx-animated-wrapper { max-width: 100%; font-family: Arial, sans-serif; }\n",
       ".lx-controls {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 8px;\n",
       "  padding: 12px; margin-bottom: 16px;\n",
       "}\n",
       ".lx-button-row {\n",
       "  display: flex; justify-content: center; gap: 8px; margin-bottom: 12px;\n",
       "}\n",
       ".lx-control-btn {\n",
       "  background: #4285f4; color: white; border: none; border-radius: 4px;\n",
       "  padding: 8px 16px; cursor: pointer; font-size: 13px; font-weight: 500;\n",
       "  transition: background-color 0.2s;\n",
       "}\n",
       ".lx-control-btn:hover { background: #3367d6; }\n",
       ".lx-progress-container {\n",
       "  margin-bottom: 8px;\n",
       "}\n",
       ".lx-progress-slider {\n",
       "  width: 100%; margin: 0; appearance: none; height: 6px;\n",
       "  background: #ddd; border-radius: 3px; outline: none;\n",
       "}\n",
       ".lx-progress-slider::-webkit-slider-thumb {\n",
       "  appearance: none; width: 18px; height: 18px; background: #4285f4;\n",
       "  border-radius: 50%; cursor: pointer;\n",
       "}\n",
       ".lx-progress-slider::-moz-range-thumb {\n",
       "  width: 18px; height: 18px; background: #4285f4; border-radius: 50%;\n",
       "  cursor: pointer; border: none;\n",
       "}\n",
       ".lx-status-text {\n",
       "  text-align: center; font-size: 12px; color: #666; margin-top: 4px;\n",
       "}\n",
       ".lx-text-window {\n",
       "  font-family: monospace; white-space: pre-wrap; border: 1px solid #90caf9;\n",
       "  padding: 12px; max-height: 260px; overflow-y: auto; margin-bottom: 12px;\n",
       "  line-height: 1.6;\n",
       "}\n",
       ".lx-attributes-panel {\n",
       "  background: #fafafa; border: 1px solid #90caf9; border-radius: 6px;\n",
       "  padding: 8px 10px; margin-top: 8px; font-size: 13px;\n",
       "}\n",
       ".lx-current-highlight {\n",
       "  border-bottom: 4px solid #ff4444;\n",
       "  font-weight: bold;\n",
       "  animation: lx-pulse 1s ease-in-out;\n",
       "}\n",
       "@keyframes lx-pulse {\n",
       "  0% { text-decoration-color: #ff4444; }\n",
       "  50% { text-decoration-color: #ff0000; }\n",
       "  100% { text-decoration-color: #ff4444; }\n",
       "}\n",
       ".lx-legend {\n",
       "  font-size: 12px; margin-bottom: 8px;\n",
       "  padding-bottom: 8px; border-bottom: 1px solid #e0e0e0;\n",
       "}\n",
       ".lx-label {\n",
       "  display: inline-block;\n",
       "  padding: 2px 4px;\n",
       "  border-radius: 3px;\n",
       "  margin-right: 4px;\n",
       "  color: #000;\n",
       "}\n",
       ".lx-attr-key {\n",
       "  font-weight: 600;\n",
       "  color: #1565c0;\n",
       "  letter-spacing: 0.3px;\n",
       "}\n",
       ".lx-attr-value {\n",
       "  font-weight: 400;\n",
       "  opacity: 0.85;\n",
       "  letter-spacing: 0.2px;\n",
       "}\n",
       "\n",
       "/* Add optimizations with larger fonts and better readability for GIFs */\n",
       ".lx-gif-optimized .lx-text-window { font-size: 16px; line-height: 1.8; }\n",
       ".lx-gif-optimized .lx-attributes-panel { font-size: 15px; }\n",
       ".lx-gif-optimized .lx-current-highlight { text-decoration-thickness: 4px; }\n",
       "</style>\n",
       "    <div class=\"lx-animated-wrapper lx-gif-optimized\">\n",
       "      <div class=\"lx-attributes-panel\">\n",
       "        <div class=\"lx-legend\">Highlights Legend: <span class=\"lx-label\" style=\"background-color:#D2E3FC;\">audience_impact</span> <span class=\"lx-label\" style=\"background-color:#C8E6C9;\">opinion_statement</span></div>\n",
       "        <div id=\"attributesContainer\"></div>\n",
       "      </div>\n",
       "      <div class=\"lx-text-window\" id=\"textWindow\">\n",
       "        **Page 1**\n",
       "&quot;&quot;&quot;\n",
       "Dan Baldwin\n",
       "Group 4\n",
       "Auteur Review - Interstellar \n",
       "I believe Christopher Nolan: the director behind the 2014 sci-ﬁ/adventure cinematic ‘Interstellar,’ \n",
       "to be <span class=\"lx-highlight lx-current-highlight\" data-idx=\"0\" style=\"background-color:#C8E6C9;\">a very intellectual and imaginative inventive talent</span>.  \n",
       "His style in his previous ﬁlms sets characters in epic unique locations, with gargantuan issues to \n",
       "face, and <span class=\"lx-highlight\" data-idx=\"1\" style=\"background-color:#C8E6C9;\">artistically impresses the audience</span> with how the characters solve their problems. For \n",
       "example, in Nolan’s 2010 ﬁlm ‘Inception,’ he tackles the idea of dreams, and sets his characters \n",
       "diving through dreams within dreams within even more dreams to complete their goals. Because \n",
       "this idea is so farfetched, and dreams are a subject in which science has made little factual \n",
       "discovery in, Nolan is free to use his creativity to present ideas such as landscapes folding in on \n",
       "themselves and corridors spinning, without seeming unrealistic. \n",
       "<span class=\"lx-highlight\" data-idx=\"2\" style=\"background-color:#C8E6C9;\">This brain-racking epic theme is once again evident in ‘Interstellar,’</span> as Nolan sets his characters \n",
       "during a second American dust bowl on future Earth. The world is short of food, and will soon be \n",
       "uninhabitable. So, ex-NASA pilot ‘Cooper’ (Matthew McConaughey) is summoned back to space \n",
       "travel in a bid to ﬁnd a new planet for the species to inhabit. Luckily for Cooper and his team, a \n",
       "black hole orbiting Saturn can transport them further into space to land on these potential \n",
       "planets. \n",
       "Throughout the ﬂick, the crew explore multiple worlds - again feeding Nolan’s mind more \n",
       "opportunities to create <span class=\"lx-highlight\" data-idx=\"3\" style=\"background-color:#C8E6C9;\">crazy scenarios</span>. For example, one planet that Cooper and his friends, \n",
       "‘Brand,’ (Anne Hathaway) and ‘Romilly,’ (David Gyasi) visit initially seems like an inﬁnite sea of two \n",
       "feet deep water. <span class=\"lx-highlight\" data-idx=\"4\" style=\"background-color:#C8E6C9;\">Not threatening at all right?</span> Well think again, because the crew suddenly ﬁnd out \n",
       "that <span class=\"lx-highlight\" data-idx=\"5\" style=\"background-color:#C8E6C9;\">a giant 100ft tidal wave is about to hit them</span>, and they have <span class=\"lx-highlight\" data-idx=\"6\" style=\"background-color:#D2E3FC;\">minutes to ﬂy away</span>. Nolan further \n",
       "increases the stakes in this scene as it is explained that every hour spent on this planet counts for \n",
       "seven years on earth, meaning the planet will be destroyed before they return if their ship sinks. \n",
       "At the climax of the ﬁlm, the crew end up sending themselves through a black hole into a \n",
       "tesseract (a 3D representation of a larger dimension) to ﬁnd the ‘secret to harnessing gravity’ \n",
       "which will let the human race bend space-time in order to survive oﬀ earth. I know. Mental. \n",
       "The imagination that Nolan possesses and implicates into ‘Interstellar’ is <span class=\"lx-highlight\" data-idx=\"7\" style=\"background-color:#C8E6C9;\">farfetched and \n",
       "wonderful</span>, <span class=\"lx-highlight\" data-idx=\"8\" style=\"background-color:#D2E3FC;\">not only impressing his audience with the appealing visuals he creates, but induces \n",
       "them to think and discuss what is going on due its scientiﬁc depth</span>. Personally, as someone who is \n",
       "bamboozled by the idea of how big the universe is, <span class=\"lx-highlight\" data-idx=\"9\" style=\"background-color:#D2E3FC;\">I ﬁnd it unendingly entertaining to repeatedly \n",
       "watch this ﬁlm and understanding it more each time</span>, and can only hope the technology portrayed \n",
       "will one day come true. \n",
       "Overall, ‘Interstellar’ is <span class=\"lx-highlight\" data-idx=\"10\" style=\"background-color:#C8E6C9;\">a clear example of Nolan’s auteur talent</span>, as he once again ﬁgments yet \n",
       "another cluster of conditions for us to marvel at. With a <span class=\"lx-highlight\" data-idx=\"11\" style=\"background-color:#C8E6C9;\">fantastic score</span> from world famous \n",
       "composer Hanz Zimmer, his epic, orchestral theme <span class=\"lx-highlight\" data-idx=\"12\" style=\"background-color:#D2E3FC;\">sets the audience in the palm of his hands as \n",
       "we stress over how we are all going to be saved once again</span>.\n",
       "&quot;&quot;&quot;\n",
       "\n",
       "\n",
       "      </div>\n",
       "      <div class=\"lx-controls\">\n",
       "        <div class=\"lx-button-row\">\n",
       "          <button class=\"lx-control-btn\" onclick=\"playPause()\">▶️ Play</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"prevExtraction()\">⏮ Previous</button>\n",
       "          <button class=\"lx-control-btn\" onclick=\"nextExtraction()\">⏭ Next</button>\n",
       "        </div>\n",
       "        <div class=\"lx-progress-container\">\n",
       "          <input type=\"range\" id=\"progressSlider\" class=\"lx-progress-slider\"\n",
       "                 min=\"0\" max=\"12\" value=\"0\"\n",
       "                 onchange=\"jumpToExtraction(this.value)\">\n",
       "        </div>\n",
       "        <div class=\"lx-status-text\">\n",
       "          Entity <span id=\"entityInfo\">1/13</span> |\n",
       "          Pos <span id=\"posInfo\">[172-224]</span>\n",
       "        </div>\n",
       "      </div>\n",
       "    </div>\n",
       "\n",
       "    <script>\n",
       "      (function() {\n",
       "        const extractions = [{\"index\": 0, \"class\": \"opinion_statement\", \"text\": \"a very intellectual and imaginative inventive talent\", \"color\": \"#C8E6C9\", \"startPos\": 172, \"endPos\": 224, \"beforeText\": \"dwin\\nGroup 4\\nAuteur Review - Interstellar \\nI believe Christopher Nolan: the director behind the 2014 sci-\\ufb01/adventure cinematic \\u2018Interstellar,\\u2019 \\nto be \", \"extractionText\": \"a very intellectual and imaginative inventive talent\", \"afterText\": \".  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and artistically impresses the audience \", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Christopher Nolan</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">very intellectual and imaginative inventive talent</span>}</div>\"}, {\"index\": 1, \"class\": \"opinion_statement\", \"text\": \"artistically impresses the audience\", \"color\": \"#C8E6C9\", \"startPos\": 338, \"endPos\": 373, \"beforeText\": \"ual and imaginative inventive talent.  \\nHis style in his previous \\ufb01lms sets characters in epic unique locations, with gargantuan issues to \\nface, and \", \"extractionText\": \"artistically impresses the audience\", \"afterText\": \" with how the characters solve their problems. For \\nexample, in Nolan\\u2019s 2010 \\ufb01lm \\u2018Inception,\\u2019 he tackles the idea of dreams, and sets his characters \\n\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s style</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">artistically impresses</span>}</div>\"}, {\"index\": 2, \"class\": \"opinion_statement\", \"text\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"color\": \"#C8E6C9\", \"startPos\": 878, \"endPos\": 948, \"beforeText\": \"lan is free to use his creativity to present ideas such as landscapes folding in on \\nthemselves and corridors spinning, without seeming unrealistic. \\n\", \"extractionText\": \"This brain-racking epic theme is once again evident in \\u2018Interstellar,\\u2019\", \"afterText\": \" as Nolan sets his characters \\nduring a second American dust bowl on future Earth. The world is short of food, and will soon be \\nuninhabitable. So, ex\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The theme</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">brain-racking epic theme</span>}</div>\"}, {\"index\": 3, \"class\": \"opinion_statement\", \"text\": \"crazy scenarios\", \"color\": \"#C8E6C9\", \"startPos\": 1484, \"endPos\": 1499, \"beforeText\": \"o land on these potential \\nplanets. \\nThroughout the \\ufb02ick, the crew explore multiple worlds - again feeding Nolan\\u2019s mind more \\nopportunities to create \", \"extractionText\": \"crazy scenarios\", \"afterText\": \". For example, one planet that Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite se\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">Nolan&#x27;s mind</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">crazy</span>}</div>\"}, {\"index\": 4, \"class\": \"opinion_statement\", \"text\": \"Not threatening at all right?\", \"color\": \"#C8E6C9\", \"startPos\": 1676, \"endPos\": 1705, \"beforeText\": \"hat Cooper and his friends, \\n\\u2018Brand,\\u2019 (Anne Hathaway) and \\u2018Romilly,\\u2019 (David Gyasi) visit initially seems like an in\\ufb01nite sea of two \\nfeet deep water. \", \"extractionText\": \"Not threatening at all right?\", \"afterText\": \" Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have minutes to \\ufb02y away. Nolan furt\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The planet</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Neutral</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">Not threatening at all</span>}</div>\"}, {\"index\": 5, \"class\": \"opinion_statement\", \"text\": \"a giant 100ft tidal wave is about to hit them\", \"color\": \"#C8E6C9\", \"startPos\": 1764, \"endPos\": 1809, \"beforeText\": \" initially seems like an in\\ufb01nite sea of two \\nfeet deep water. Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat \", \"extractionText\": \"a giant 100ft tidal wave is about to hit them\", \"afterText\": \", and they have minutes to \\ufb02y away. Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts f\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Negative</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">giant 100ft tidal wave</span>}</div>\"}, {\"index\": 6, \"class\": \"audience_impact\", \"text\": \"minutes to \\ufb02y away\", \"color\": \"#D2E3FC\", \"startPos\": 1825, \"endPos\": 1843, \"beforeText\": \" Not threatening at all right? Well think again, because the crew suddenly \\ufb01nd out \\nthat a giant 100ft tidal wave is about to hit them, and they have \", \"extractionText\": \"minutes to \\ufb02y away\", \"afterText\": \". Nolan further \\nincreases the stakes in this scene as it is explained that every hour spent on this planet counts for \\nseven years on earth, meaning \", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">stress, urgency</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The tidal wave</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the crew</span>}</div>\"}, {\"index\": 7, \"class\": \"opinion_statement\", \"text\": \"farfetched and wonderful\", \"color\": \"#C8E6C9\", \"startPos\": 2418, \"endPos\": 2443, \"beforeText\": \" human race bend space-time in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is \", \"extractionText\": \"farfetched and \\nwonderful\", \"afterText\": \", not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c de\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">farfetched and wonderful</span>}</div>\"}, {\"index\": 8, \"class\": \"audience_impact\", \"text\": \"not only impressing his audience with the appealing visuals he creates, but induces them to think and discuss what is going on due its scienti\\ufb01c depth\", \"color\": \"#D2E3FC\", \"startPos\": 2445, \"endPos\": 2596, \"beforeText\": \" in order to survive o\\ufb00 earth. I know. Mental. \\nThe imagination that Nolan possesses and implicates into \\u2018Interstellar\\u2019 is farfetched and \\nwonderful, \", \"extractionText\": \"not only impressing his audience with the appealing visuals he creates, but induces \\nthem to think and discuss what is going on due its scienti\\ufb01c depth\", \"afterText\": \". Personally, as someone who is \\nbamboozled by the idea of how big the universe is, I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">impressed, thoughtful, engaged</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The appealing visuals and scientific depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">his audience</span>}</div>\"}, {\"index\": 9, \"class\": \"audience_impact\", \"text\": \"I \\ufb01nd it unendingly entertaining to repeatedly watch this \\ufb01lm and understanding it more each time\", \"color\": \"#D2E3FC\", \"startPos\": 2680, \"endPos\": 2778, \"beforeText\": \"them to think and discuss what is going on due its scienti\\ufb01c depth. Personally, as someone who is \\nbamboozled by the idea of how big the universe is, \", \"extractionText\": \"I \\ufb01nd it unendingly entertaining to repeatedly \\nwatch this \\ufb01lm and understanding it more each time\", \"afterText\": \", and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">entertained, intellectually stimulated</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">The film&#x27;s complexity and depth</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the reviewer</span>}</div>\"}, {\"index\": 10, \"class\": \"opinion_statement\", \"text\": \"a clear example of Nolan\\u2019s auteur talent\", \"color\": \"#C8E6C9\", \"startPos\": 2876, \"endPos\": 2916, \"beforeText\": \" \\nwatch this \\ufb01lm and understanding it more each time, and can only hope the technology portrayed \\nwill one day come true. \\nOverall, \\u2018Interstellar\\u2019 is \", \"extractionText\": \"a clear example of Nolan\\u2019s auteur talent\", \"afterText\": \", as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">\\u2018Interstellar\\u2019</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">clear example of Nolan\\u2019s auteur talent</span>}</div>\"}, {\"index\": 11, \"class\": \"opinion_statement\", \"text\": \"fantastic score\", \"color\": \"#C8E6C9\", \"startPos\": 3006, \"endPos\": 3021, \"beforeText\": \", \\u2018Interstellar\\u2019 is a clear example of Nolan\\u2019s auteur talent, as he once again \\ufb01gments yet \\nanother cluster of conditions for us to marvel at. With a \", \"extractionText\": \"fantastic score\", \"afterText\": \" from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme sets the audience in the palm of his hands as \\nwe stress over how we are all goin\", \"attributesHtml\": \"<div><strong>class:</strong> opinion_statement</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">subject</span>: <span class=\\\"lx-attr-value\\\">The score</span>, <span class=\\\"lx-attr-key\\\">sentiment</span>: <span class=\\\"lx-attr-value\\\">Positive</span>, <span class=\\\"lx-attr-key\\\">key_phrase</span>: <span class=\\\"lx-attr-value\\\">fantastic</span>}</div>\"}, {\"index\": 12, \"class\": \"audience_impact\", \"text\": \"sets the audience in the palm of his hands as we stress over how we are all going to be saved once again\", \"color\": \"#D2E3FC\", \"startPos\": 3090, \"endPos\": 3195, \"beforeText\": \"ts yet \\nanother cluster of conditions for us to marvel at. With a fantastic score from world famous \\ncomposer Hanz Zimmer, his epic, orchestral theme \", \"extractionText\": \"sets the audience in the palm of his hands as \\nwe stress over how we are all going to be saved once again\", \"afterText\": \".\\n&quot;&quot;&quot;\\n\\n\", \"attributesHtml\": \"<div><strong>class:</strong> audience_impact</div><div><strong>attributes:</strong> {<span class=\\\"lx-attr-key\\\">emotion_evoked</span>: <span class=\\\"lx-attr-value\\\">captivated, stressed</span>, <span class=\\\"lx-attr-key\\\">causal_element</span>: <span class=\\\"lx-attr-value\\\">His epic, orchestral theme</span>, <span class=\\\"lx-attr-key\\\">target_audience</span>: <span class=\\\"lx-attr-value\\\">the audience</span>}</div>\"}];\n",
       "        let currentIndex = 0;\n",
       "        let isPlaying = false;\n",
       "        let animationInterval = null;\n",
       "        let animationSpeed = 1.0;\n",
       "\n",
       "        function updateDisplay() {\n",
       "          const extraction = extractions[currentIndex];\n",
       "          if (!extraction) return;\n",
       "\n",
       "          document.getElementById('attributesContainer').innerHTML = extraction.attributesHtml;\n",
       "          document.getElementById('entityInfo').textContent = (currentIndex + 1) + '/' + extractions.length;\n",
       "          document.getElementById('posInfo').textContent = '[' + extraction.startPos + '-' + extraction.endPos + ']';\n",
       "          document.getElementById('progressSlider').value = currentIndex;\n",
       "\n",
       "          const playBtn = document.querySelector('.lx-control-btn');\n",
       "          if (playBtn) playBtn.textContent = isPlaying ? '⏸ Pause' : '▶️ Play';\n",
       "\n",
       "          const prevHighlight = document.querySelector('.lx-text-window .lx-current-highlight');\n",
       "          if (prevHighlight) prevHighlight.classList.remove('lx-current-highlight');\n",
       "          const currentSpan = document.querySelector('.lx-text-window span[data-idx=\"' + currentIndex + '\"]');\n",
       "          if (currentSpan) {\n",
       "            currentSpan.classList.add('lx-current-highlight');\n",
       "            currentSpan.scrollIntoView({block: 'center', behavior: 'smooth'});\n",
       "          }\n",
       "        }\n",
       "\n",
       "        function nextExtraction() {\n",
       "          currentIndex = (currentIndex + 1) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function prevExtraction() {\n",
       "          currentIndex = (currentIndex - 1 + extractions.length) % extractions.length;\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function jumpToExtraction(index) {\n",
       "          currentIndex = parseInt(index);\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        function playPause() {\n",
       "          if (isPlaying) {\n",
       "            clearInterval(animationInterval);\n",
       "            isPlaying = false;\n",
       "          } else {\n",
       "            animationInterval = setInterval(nextExtraction, animationSpeed * 1000);\n",
       "            isPlaying = true;\n",
       "          }\n",
       "          updateDisplay();\n",
       "        }\n",
       "\n",
       "        window.playPause = playPause;\n",
       "        window.nextExtraction = nextExtraction;\n",
       "        window.prevExtraction = prevExtraction;\n",
       "        window.jumpToExtraction = jumpToExtraction;\n",
       "\n",
       "        updateDisplay();\n",
       "      })();\n",
       "    </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_7_1_2_'></a>[**>>> Bonus Exercise 3 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Repeat the steps for information extraction using a different movie reviews.\n",
    "1. Search for movie reviews online and save them in a PDF, we suggest **at least 1 page worth of reviews** like in the example.\n",
    "2. Load the PDF and pass them to langextract to extract information from it.\n",
    "3. Display html with the grounded extracted attributes.\n",
    "4. Discuss about the quality of the extracted information with langextract, how could it be improved based on the options the documentation gives that we didn't try?\n",
    "\n",
    "**`Github repository for reference:`** [langextract](https://github.com/google/langextract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_8_'></a>[**2.4 Generating LLM Embeddings:**](#toc0_)\n",
    "\n",
    "LLM embeddings are dense numerical vectors that represent the semantic meaning of text. Generated by Large Language Models, they map words, phrases, or documents into a high-dimensional space where similar concepts are positioned closely together.\n",
    "\n",
    "Their key advantages are:\n",
    "\n",
    "*   **Contextual Understanding:** Unlike older methods, LLM embeddings are contextual. The vector for a word like **\"bank\"** will be different depending on whether it's used in the context of a \"river bank\" or a \"money bank,\" providing a more nuanced representation of language.\n",
    "\n",
    "*   **Versatility from Pre-training:** They are pre-trained on vast amounts of text data. This allows them to generalize effectively across various tasks, such as classification, clustering, and similarity detection. They do not require extensive retraining.\n",
    "\n",
    "<span style=\"color:green\">For the exercise in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>\n",
    "\n",
    "**Now let's generate some embeddings with Gemini for a sample of our dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "import pandas as pd\n",
    "import time\n",
    "from google.api_core import exceptions\n",
    "\n",
    "# Let's define our function to get the embeddings with Gemini\n",
    "def get_gemini_embedding(text: str, model: str=\"gemini-embedding-001\"):\n",
    "    try:\n",
    "        result = client.models.embed_content(model=model, contents=[text])\n",
    "        # 100 requests per minute limit -> 60s / 100 = 0.6s per request\n",
    "        # buffer time to avoid rate limits\n",
    "        time.sleep(0.6)\n",
    "        return result.embeddings\n",
    "    except exceptions.ResourceExhausted as e:\n",
    "        print(f\"Rate limit exceeded. Waiting to retry... Error: {e}\")\n",
    "        time.sleep(5) # Wait for 5 seconds before the next attempt\n",
    "        return get_gemini_embedding(text, model) # Retry the request\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampling 160 rows from the training set...\n",
      "Sampling 40 rows from the test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\didif\\AppData\\Local\\Temp\\ipykernel_92972\\837381810.py:13: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
      "C:\\Users\\didif\\AppData\\Local\\Temp\\ipykernel_92972\\837381810.py:13: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n"
     ]
    }
   ],
   "source": [
    "total_extractions = 200\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.2\n",
    "\n",
    "n_train_to_sample = int(total_extractions * train_ratio)\n",
    "n_test_to_sample = int(total_extractions * test_ratio)\n",
    "# We use the text column\n",
    "column_name = 'text'\n",
    "\n",
    "# This function is to get a stratified sample from our data, meaning to have the same distribution of labels as in the full dataset\n",
    "def stratified_sample(df: pd.DataFrame, n_samples: int, stratify_col: str = 'emotion') -> pd.DataFrame:\n",
    "    if n_samples >= len(df):\n",
    "        return df.copy() # Return a copy if requested sample is larger or equal\n",
    "    sampled_df = df.groupby(stratify_col, group_keys=False).apply(\n",
    "        lambda x: x.sample(n=max(0, int(round(len(x) / len(df) * n_samples))))\n",
    "    )\n",
    "\n",
    "    # Adjust for rounding errors to get the exact number of samples\n",
    "    current_samples = len(sampled_df)\n",
    "    if current_samples < n_samples:\n",
    "        remaining_indices = df.index.difference(sampled_df.index)\n",
    "        additional_samples = df.loc[remaining_indices].sample(n=n_samples - current_samples, random_state=42)\n",
    "        sampled_df = pd.concat([sampled_df, additional_samples])\n",
    "    elif current_samples > n_samples:\n",
    "        sampled_df = sampled_df.sample(n=n_samples, random_state=42)\n",
    "    return sampled_df\n",
    "\n",
    "print(f\"Sampling {n_train_to_sample} rows from the training set...\")\n",
    "train_df_new = stratified_sample(train_df, n_train_to_sample, 'emotion')\n",
    "\n",
    "print(f\"Sampling {n_test_to_sample} rows from the test set...\")\n",
    "test_df_new = stratified_sample(test_df, n_test_to_sample, 'emotion')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       51\n",
       "anger      38\n",
       "joy        36\n",
       "sadness    35\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emotion\n",
       "fear       13\n",
       "anger      10\n",
       "joy         9\n",
       "sadness     8\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df_new[\"emotion\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new training set...\n"
     ]
    }
   ],
   "source": [
    "# Apply the function to the specified column and store the result in a new column 'embeddings'\n",
    "print(\"\\nGenerating embeddings for the new training set...\")\n",
    "train_df_new['embeddings'] = train_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating embeddings for the new test set...\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerating embeddings for the new test set...\")\n",
    "test_df_new['embeddings'] = test_df_new[column_name].apply(get_gemini_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.genai import types\n",
    "\n",
    "# After getting the embeddings we need to convert the Gemini type ContentDict of the embeddings into a simple list with them\n",
    "train_df_new['embeddings_values'] = train_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n",
    "test_df_new['embeddings_values'] = test_df_new[\"embeddings\"].apply(lambda row: list(types.ContentDict(row[0]).values())[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>10259</td>\n",
       "      <td>@saclivin @MrsCagg specific &amp;amp; intentional ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.583</td>\n",
       "      <td>[values=[0.0074897306, 0.010551137, 0.01268477...</td>\n",
       "      <td>[0.0074897306, 0.010551137, 0.012684776, -0.06...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>10625</td>\n",
       "      <td>Now they fret about scuffs. I’ll take scuffs (...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.396</td>\n",
       "      <td>[values=[0.007862637, -0.018608198, -0.0045249...</td>\n",
       "      <td>[0.007862637, -0.018608198, -0.0045249686, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>10436</td>\n",
       "      <td>@Freepenalties @TMortimerFtbl Doll is a vile c...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.479</td>\n",
       "      <td>[values=[0.0034193734, -0.011207058, 0.0153249...</td>\n",
       "      <td>[0.0034193734, -0.011207058, 0.015324958, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>10116</td>\n",
       "      <td>Police Officers....should NOT have the right t...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.688</td>\n",
       "      <td>[values=[0.003105581, -0.015246949, 0.00538699...</td>\n",
       "      <td>[0.003105581, -0.015246949, 0.005386993, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>714</th>\n",
       "      <td>10714</td>\n",
       "      <td>@BarackObama I love Lizzy Warren's latest rage...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.177</td>\n",
       "      <td>[values=[-0.004500443, 0.013404208, 0.02262224...</td>\n",
       "      <td>[-0.004500443, 0.013404208, 0.02262224, -0.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3610</th>\n",
       "      <td>40783</td>\n",
       "      <td>@SilkInSide @TommyJoeRatliff that's so pretty!...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.088</td>\n",
       "      <td>[values=[-0.0061398125, 0.010634093, -0.012183...</td>\n",
       "      <td>[-0.0061398125, 0.010634093, -0.012183881, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2891</th>\n",
       "      <td>40064</td>\n",
       "      <td>We have left #Maine. #sadness</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.771</td>\n",
       "      <td>[values=[-0.040753946, -0.016005157, -0.013711...</td>\n",
       "      <td>[-0.040753946, -0.016005157, -0.013711573, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2840</th>\n",
       "      <td>40013</td>\n",
       "      <td>I sulk too much for my own good.</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.896</td>\n",
       "      <td>[values=[-0.0026435328, 0.006199665, -0.009658...</td>\n",
       "      <td>[-0.0026435328, 0.006199665, -0.00965845, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3346</th>\n",
       "      <td>40519</td>\n",
       "      <td>That's me for the evening, though! Way too lit...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.396</td>\n",
       "      <td>[values=[-0.0026682366, 0.00042450507, -0.0232...</td>\n",
       "      <td>[-0.0026682366, 0.00042450507, -0.02326137, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2934</th>\n",
       "      <td>40107</td>\n",
       "      <td>Don't wanna go to work but I want the money #sad</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.729</td>\n",
       "      <td>[values=[-0.010172246, 0.010840196, 0.00058211...</td>\n",
       "      <td>[-0.010172246, 0.010840196, 0.0005821167, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  emotion  \\\n",
       "259   10259  @saclivin @MrsCagg specific &amp; intentional ...    anger   \n",
       "625   10625  Now they fret about scuffs. I’ll take scuffs (...    anger   \n",
       "436   10436  @Freepenalties @TMortimerFtbl Doll is a vile c...    anger   \n",
       "116   10116  Police Officers....should NOT have the right t...    anger   \n",
       "714   10714  @BarackObama I love Lizzy Warren's latest rage...    anger   \n",
       "...     ...                                                ...      ...   \n",
       "3610  40783  @SilkInSide @TommyJoeRatliff that's so pretty!...  sadness   \n",
       "2891  40064                      We have left #Maine. #sadness  sadness   \n",
       "2840  40013                   I sulk too much for my own good.  sadness   \n",
       "3346  40519  That's me for the evening, though! Way too lit...  sadness   \n",
       "2934  40107   Don't wanna go to work but I want the money #sad  sadness   \n",
       "\n",
       "      intensity                                         embeddings  \\\n",
       "259       0.583  [values=[0.0074897306, 0.010551137, 0.01268477...   \n",
       "625       0.396  [values=[0.007862637, -0.018608198, -0.0045249...   \n",
       "436       0.479  [values=[0.0034193734, -0.011207058, 0.0153249...   \n",
       "116       0.688  [values=[0.003105581, -0.015246949, 0.00538699...   \n",
       "714       0.177  [values=[-0.004500443, 0.013404208, 0.02262224...   \n",
       "...         ...                                                ...   \n",
       "3610      0.088  [values=[-0.0061398125, 0.010634093, -0.012183...   \n",
       "2891      0.771  [values=[-0.040753946, -0.016005157, -0.013711...   \n",
       "2840      0.896  [values=[-0.0026435328, 0.006199665, -0.009658...   \n",
       "3346      0.396  [values=[-0.0026682366, 0.00042450507, -0.0232...   \n",
       "2934      0.729  [values=[-0.010172246, 0.010840196, 0.00058211...   \n",
       "\n",
       "                                      embeddings_values  \n",
       "259   [0.0074897306, 0.010551137, 0.012684776, -0.06...  \n",
       "625   [0.007862637, -0.018608198, -0.0045249686, -0....  \n",
       "436   [0.0034193734, -0.011207058, 0.015324958, -0.0...  \n",
       "116   [0.003105581, -0.015246949, 0.005386993, -0.05...  \n",
       "714   [-0.004500443, 0.013404208, 0.02262224, -0.085...  \n",
       "...                                                 ...  \n",
       "3610  [-0.0061398125, 0.010634093, -0.012183881, -0....  \n",
       "2891  [-0.040753946, -0.016005157, -0.013711573, -0....  \n",
       "2840  [-0.0026435328, 0.006199665, -0.00965845, -0.0...  \n",
       "3346  [-0.0026682366, 0.00042450507, -0.02326137, -0...  \n",
       "2934  [-0.010172246, 0.010840196, 0.0005821167, -0.0...  \n",
       "\n",
       "[160 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "      <th>intensity</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings_values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>30898</td>\n",
       "      <td>@r0Ils ppl get triggered over u smiling they'r...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.170</td>\n",
       "      <td>[values=[-0.0058842055, 0.012170943, -0.017462...</td>\n",
       "      <td>[-0.0058842055, 0.012170943, -0.017462442, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>21204</td>\n",
       "      <td>I have been seeing terrible terrible prescript...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.438</td>\n",
       "      <td>[values=[-0.0063169575, -0.0028110475, -0.0048...</td>\n",
       "      <td>[-0.0063169575, -0.0028110475, -0.0048835087, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>10902</td>\n",
       "      <td>S/O to the girl that just hit my car...not onl...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.542</td>\n",
       "      <td>[values=[-0.021190451, -0.0024552303, -0.02645...</td>\n",
       "      <td>[-0.021190451, -0.0024552303, -0.026451988, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>30831</td>\n",
       "      <td>Google caffeine-an sprightly lengthening into ...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.200</td>\n",
       "      <td>[values=[-0.014093162, 0.0063211513, -0.007975...</td>\n",
       "      <td>[-0.014093162, 0.0063211513, -0.007975788, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10875</td>\n",
       "      <td>@TrussElise Obama must be fuming.. lol</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.500</td>\n",
       "      <td>[values=[-0.0028347652, 0.04002049, -0.0105925...</td>\n",
       "      <td>[-0.0028347652, 0.04002049, -0.010592525, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>40826</td>\n",
       "      <td>@LeePorter94 @DomMcGovern_ hi Dom I saw u at N...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[0.00033614397, -0.03252327, 0.0025710...</td>\n",
       "      <td>[0.00033614397, -0.03252327, 0.0025710862, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>21234</td>\n",
       "      <td>Trying to book holiday flights on @britishairw...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[-0.04059941, -0.018868277, -0.0080992...</td>\n",
       "      <td>[-0.04059941, -0.018868277, -0.008099283, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>40824</td>\n",
       "      <td>On bedrest since I got out of the hospital. U ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.440</td>\n",
       "      <td>[values=[0.0041351523, -0.0051084706, -0.02860...</td>\n",
       "      <td>[0.0041351523, -0.0051084706, -0.028601801, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>30865</td>\n",
       "      <td>When we give cheerfully and accept gratefully,...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.712</td>\n",
       "      <td>[values=[-0.029224416, -0.011000588, -0.027645...</td>\n",
       "      <td>[-0.029224416, -0.011000588, -0.02764561, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10887</td>\n",
       "      <td>Everybody talking about 'the first day of fall...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[-0.016532253, -0.018671215, 0.0024112...</td>\n",
       "      <td>[-0.016532253, -0.018671215, 0.0024112132, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>30890</td>\n",
       "      <td>A lifetime of laughter at the expense of the d...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[values=[0.0102727655, 0.031475015, 0.00417681...</td>\n",
       "      <td>[0.0102727655, 0.031475015, 0.0041768197, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>21212</td>\n",
       "      <td>I don't want speak front to him #afraid #intim...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[values=[0.007820222, -0.034854155, 0.01393725...</td>\n",
       "      <td>[0.007820222, -0.034854155, 0.013937257, -0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>21162</td>\n",
       "      <td>@madhav_pastey moral of the story, never check...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.354</td>\n",
       "      <td>[values=[0.012194014, 0.011370001, -0.01486749...</td>\n",
       "      <td>[0.012194014, 0.011370001, -0.014867495, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>10893</td>\n",
       "      <td>@pbhushan1 @IndianExpress so in your opinion i...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.526</td>\n",
       "      <td>[values=[-0.015313634, -0.009707481, -0.004503...</td>\n",
       "      <td>[-0.015313634, -0.009707481, -0.0045037856, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>21171</td>\n",
       "      <td>You want  bad service use #frontier they have ...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[values=[-0.014948463, -0.0071810996, -0.01019...</td>\n",
       "      <td>[-0.014948463, -0.0071810996, -0.0101971235, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>40813</td>\n",
       "      <td>This shit hurting my heart 😪 that's how seriou...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.875</td>\n",
       "      <td>[values=[-0.0069135656, -0.0037595944, -0.0228...</td>\n",
       "      <td>[-0.0069135656, -0.0037595944, -0.022816306, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>21231</td>\n",
       "      <td>@lukeshawtime terrible</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.521</td>\n",
       "      <td>[values=[-4.4061668e-05, -0.008561462, -0.0062...</td>\n",
       "      <td>[-4.4061668e-05, -0.008561462, -0.0062373965, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>40805</td>\n",
       "      <td>Might go on @RadioX tomorrow to hopefully win ...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.458</td>\n",
       "      <td>[values=[0.002165168, -0.022245526, 0.01743654...</td>\n",
       "      <td>[0.002165168, -0.022245526, 0.017436543, -0.07...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>40790</td>\n",
       "      <td>All I want to do is watch some netflix but I a...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.667</td>\n",
       "      <td>[values=[-0.0058988086, 0.013784122, -0.015859...</td>\n",
       "      <td>[-0.0058988086, 0.013784122, -0.015859485, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>10890</td>\n",
       "      <td>All Brian does is sleep and aggravate me</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.833</td>\n",
       "      <td>[values=[-0.016705524, -0.008376931, -0.018700...</td>\n",
       "      <td>[-0.016705524, -0.008376931, -0.01870026, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>30855</td>\n",
       "      <td>Each day is what you make of it! #goals #chall...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[-0.01992363, 0.021712968, 0.013815594...</td>\n",
       "      <td>[-0.01992363, 0.021712968, 0.013815594, -0.062...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10880</td>\n",
       "      <td>@TrueAggieFan oh so that's where Brian was! Wh...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.417</td>\n",
       "      <td>[values=[-0.037104376, -0.016576506, -0.019182...</td>\n",
       "      <td>[-0.037104376, -0.016576506, -0.019182565, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>21207</td>\n",
       "      <td>@LethalWeaponFOX This show SUCKS! #lame #awful...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.396</td>\n",
       "      <td>[values=[-0.04764038, 0.010794757, 0.004717541...</td>\n",
       "      <td>[-0.04764038, 0.010794757, 0.0047175414, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>10935</td>\n",
       "      <td>@TrevorHMoore @paget_old In Scotland, the righ...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.604</td>\n",
       "      <td>[values=[0.009859718, -0.009872029, 0.02174849...</td>\n",
       "      <td>[0.009859718, -0.009872029, 0.02174849, -0.054...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>30844</td>\n",
       "      <td>@NateBLoL no it was that clear American natura...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.312</td>\n",
       "      <td>[values=[0.0005466202, 0.0077015567, 0.0056142...</td>\n",
       "      <td>[0.0005466202, 0.0077015567, 0.005614247, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>21210</td>\n",
       "      <td>Another fun fact: i am afraid</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.667</td>\n",
       "      <td>[values=[-0.01226142, -0.00048677987, -0.01031...</td>\n",
       "      <td>[-0.01226142, -0.00048677987, -0.010317536, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10917</td>\n",
       "      <td>I think our defense here at USC is playing wel...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[values=[-0.011085541, -0.015644377, 0.0231633...</td>\n",
       "      <td>[-0.011085541, -0.015644377, 0.02316334, -0.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>30830</td>\n",
       "      <td>If any trump supporters and Hillary haters wan...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.100</td>\n",
       "      <td>[values=[-0.0061332616, -0.0058089164, 0.00725...</td>\n",
       "      <td>[-0.0061332616, -0.0058089164, 0.0072566825, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>40845</td>\n",
       "      <td>We are about a little over an hour away! We wi...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[values=[-0.003842375, 0.015801212, -0.0173058...</td>\n",
       "      <td>[-0.003842375, 0.015801212, -0.017305838, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>10898</td>\n",
       "      <td>Realest ever, relentless ever, inevitable that...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.415</td>\n",
       "      <td>[values=[-0.014525433, 0.01642175, 0.010939563...</td>\n",
       "      <td>[-0.014525433, 0.01642175, 0.010939563, -0.071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>40800</td>\n",
       "      <td>“Dyslexia is the affliction of a frozen genius...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.333</td>\n",
       "      <td>[values=[0.018854156, 0.0033274922, -0.0072523...</td>\n",
       "      <td>[0.018854156, 0.0033274922, -0.0072523863, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>30829</td>\n",
       "      <td>@Casper10666 I assure you there is no laughter...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.167</td>\n",
       "      <td>[values=[-0.008917223, -0.013621849, 0.0017390...</td>\n",
       "      <td>[-0.008917223, -0.013621849, 0.0017390692, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>40823</td>\n",
       "      <td>you are on an endless journey of figuring your...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>0.375</td>\n",
       "      <td>[values=[-0.036277726, 0.011091107, -0.0132130...</td>\n",
       "      <td>[-0.036277726, 0.011091107, -0.013213003, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>21184</td>\n",
       "      <td>Nothing worse than an uber driver that can't d...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.562</td>\n",
       "      <td>[values=[0.010763933, -0.003074528, -0.0115314...</td>\n",
       "      <td>[0.010763933, -0.003074528, -0.011531402, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>21205</td>\n",
       "      <td>@stephenfhayes Mustard gas = hostile work envi...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[0.0034173268, 0.014688194, 0.00708017...</td>\n",
       "      <td>[0.0034173268, 0.014688194, 0.0070801787, -0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>21181</td>\n",
       "      <td>@AlaskaGurus @adventuretweets agreed! 😍 an awe...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.208</td>\n",
       "      <td>[values=[-0.03000513, -0.024266208, 0.01600963...</td>\n",
       "      <td>[-0.03000513, -0.024266208, 0.01600963, -0.072...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>21182</td>\n",
       "      <td>@BuzzFeed so this houses will get into my inst...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.700</td>\n",
       "      <td>[values=[0.009150241, -0.017897055, 0.00885419...</td>\n",
       "      <td>[0.009150241, -0.017897055, 0.008854199, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10882</td>\n",
       "      <td>It's the most magical time of the year......Xm...</td>\n",
       "      <td>anger</td>\n",
       "      <td>0.429</td>\n",
       "      <td>[values=[-0.032807905, 0.002414791, -0.0038823...</td>\n",
       "      <td>[-0.032807905, 0.002414791, -0.0038823327, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>21240</td>\n",
       "      <td>Tweeting from the sporadic wifi on the tube #p...</td>\n",
       "      <td>fear</td>\n",
       "      <td>0.434</td>\n",
       "      <td>[values=[-0.007219498, 0.00479843, -0.01259315...</td>\n",
       "      <td>[-0.007219498, 0.00479843, -0.012593151, -0.10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>30858</td>\n",
       "      <td>It's #HobbitDay! \\nHobbit's give gifts on thei...</td>\n",
       "      <td>joy</td>\n",
       "      <td>0.708</td>\n",
       "      <td>[values=[-0.016419495, 0.024953509, -0.0105649...</td>\n",
       "      <td>[-0.016419495, 0.024953509, -0.010564933, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  emotion  \\\n",
       "269  30898  @r0Ils ppl get triggered over u smiling they'r...      joy   \n",
       "141  21204  I have been seeing terrible terrible prescript...     fear   \n",
       "45   10902  S/O to the girl that just hit my car...not onl...    anger   \n",
       "202  30831  Google caffeine-an sprightly lengthening into ...      joy   \n",
       "18   10875             @TrussElise Obama must be fuming.. lol    anger   \n",
       "313  40826  @LeePorter94 @DomMcGovern_ hi Dom I saw u at N...  sadness   \n",
       "171  21234  Trying to book holiday flights on @britishairw...     fear   \n",
       "311  40824  On bedrest since I got out of the hospital. U ...  sadness   \n",
       "236  30865  When we give cheerfully and accept gratefully,...      joy   \n",
       "30   10887  Everybody talking about 'the first day of fall...    anger   \n",
       "261  30890  A lifetime of laughter at the expense of the d...      joy   \n",
       "149  21212  I don't want speak front to him #afraid #intim...     fear   \n",
       "99   21162  @madhav_pastey moral of the story, never check...     fear   \n",
       "36   10893  @pbhushan1 @IndianExpress so in your opinion i...    anger   \n",
       "108  21171  You want  bad service use #frontier they have ...     fear   \n",
       "300  40813  This shit hurting my heart 😪 that's how seriou...  sadness   \n",
       "168  21231                             @lukeshawtime terrible     fear   \n",
       "292  40805  Might go on @RadioX tomorrow to hopefully win ...  sadness   \n",
       "277  40790  All I want to do is watch some netflix but I a...  sadness   \n",
       "33   10890           All Brian does is sleep and aggravate me    anger   \n",
       "226  30855  Each day is what you make of it! #goals #chall...      joy   \n",
       "23   10880  @TrueAggieFan oh so that's where Brian was! Wh...    anger   \n",
       "144  21207  @LethalWeaponFOX This show SUCKS! #lame #awful...     fear   \n",
       "78   10935  @TrevorHMoore @paget_old In Scotland, the righ...    anger   \n",
       "215  30844  @NateBLoL no it was that clear American natura...      joy   \n",
       "147  21210                      Another fun fact: i am afraid     fear   \n",
       "60   10917  I think our defense here at USC is playing wel...    anger   \n",
       "201  30830  If any trump supporters and Hillary haters wan...      joy   \n",
       "332  40845  We are about a little over an hour away! We wi...  sadness   \n",
       "41   10898  Realest ever, relentless ever, inevitable that...    anger   \n",
       "287  40800  “Dyslexia is the affliction of a frozen genius...  sadness   \n",
       "200  30829  @Casper10666 I assure you there is no laughter...      joy   \n",
       "310  40823  you are on an endless journey of figuring your...  sadness   \n",
       "121  21184  Nothing worse than an uber driver that can't d...     fear   \n",
       "142  21205  @stephenfhayes Mustard gas = hostile work envi...     fear   \n",
       "118  21181  @AlaskaGurus @adventuretweets agreed! 😍 an awe...     fear   \n",
       "119  21182  @BuzzFeed so this houses will get into my inst...     fear   \n",
       "25   10882  It's the most magical time of the year......Xm...    anger   \n",
       "177  21240  Tweeting from the sporadic wifi on the tube #p...     fear   \n",
       "229  30858  It's #HobbitDay! \\nHobbit's give gifts on thei...      joy   \n",
       "\n",
       "     intensity                                         embeddings  \\\n",
       "269      0.170  [values=[-0.0058842055, 0.012170943, -0.017462...   \n",
       "141      0.438  [values=[-0.0063169575, -0.0028110475, -0.0048...   \n",
       "45       0.542  [values=[-0.021190451, -0.0024552303, -0.02645...   \n",
       "202      0.200  [values=[-0.014093162, 0.0063211513, -0.007975...   \n",
       "18       0.500  [values=[-0.0028347652, 0.04002049, -0.0105925...   \n",
       "313      0.312  [values=[0.00033614397, -0.03252327, 0.0025710...   \n",
       "171      0.458  [values=[-0.04059941, -0.018868277, -0.0080992...   \n",
       "311      0.440  [values=[0.0041351523, -0.0051084706, -0.02860...   \n",
       "236      0.712  [values=[-0.029224416, -0.011000588, -0.027645...   \n",
       "30       0.417  [values=[-0.016532253, -0.018671215, 0.0024112...   \n",
       "261      0.354  [values=[0.0102727655, 0.031475015, 0.00417681...   \n",
       "149      0.875  [values=[0.007820222, -0.034854155, 0.01393725...   \n",
       "99       0.354  [values=[0.012194014, 0.011370001, -0.01486749...   \n",
       "36       0.526  [values=[-0.015313634, -0.009707481, -0.004503...   \n",
       "108      0.333  [values=[-0.014948463, -0.0071810996, -0.01019...   \n",
       "300      0.875  [values=[-0.0069135656, -0.0037595944, -0.0228...   \n",
       "168      0.521  [values=[-4.4061668e-05, -0.008561462, -0.0062...   \n",
       "292      0.458  [values=[0.002165168, -0.022245526, 0.01743654...   \n",
       "277      0.667  [values=[-0.0058988086, 0.013784122, -0.015859...   \n",
       "33       0.833  [values=[-0.016705524, -0.008376931, -0.018700...   \n",
       "226      0.604  [values=[-0.01992363, 0.021712968, 0.013815594...   \n",
       "23       0.417  [values=[-0.037104376, -0.016576506, -0.019182...   \n",
       "144      0.396  [values=[-0.04764038, 0.010794757, 0.004717541...   \n",
       "78       0.604  [values=[0.009859718, -0.009872029, 0.02174849...   \n",
       "215      0.312  [values=[0.0005466202, 0.0077015567, 0.0056142...   \n",
       "147      0.667  [values=[-0.01226142, -0.00048677987, -0.01031...   \n",
       "60       0.250  [values=[-0.011085541, -0.015644377, 0.0231633...   \n",
       "201      0.100  [values=[-0.0061332616, -0.0058089164, 0.00725...   \n",
       "332      0.125  [values=[-0.003842375, 0.015801212, -0.0173058...   \n",
       "41       0.415  [values=[-0.014525433, 0.01642175, 0.010939563...   \n",
       "287      0.333  [values=[0.018854156, 0.0033274922, -0.0072523...   \n",
       "200      0.167  [values=[-0.008917223, -0.013621849, 0.0017390...   \n",
       "310      0.375  [values=[-0.036277726, 0.011091107, -0.0132130...   \n",
       "121      0.562  [values=[0.010763933, -0.003074528, -0.0115314...   \n",
       "142      0.708  [values=[0.0034173268, 0.014688194, 0.00708017...   \n",
       "118      0.208  [values=[-0.03000513, -0.024266208, 0.01600963...   \n",
       "119      0.700  [values=[0.009150241, -0.017897055, 0.00885419...   \n",
       "25       0.429  [values=[-0.032807905, 0.002414791, -0.0038823...   \n",
       "177      0.434  [values=[-0.007219498, 0.00479843, -0.01259315...   \n",
       "229      0.708  [values=[-0.016419495, 0.024953509, -0.0105649...   \n",
       "\n",
       "                                     embeddings_values  \n",
       "269  [-0.0058842055, 0.012170943, -0.017462442, -0....  \n",
       "141  [-0.0063169575, -0.0028110475, -0.0048835087, ...  \n",
       "45   [-0.021190451, -0.0024552303, -0.026451988, -0...  \n",
       "202  [-0.014093162, 0.0063211513, -0.007975788, -0....  \n",
       "18   [-0.0028347652, 0.04002049, -0.010592525, -0.0...  \n",
       "313  [0.00033614397, -0.03252327, 0.0025710862, -0....  \n",
       "171  [-0.04059941, -0.018868277, -0.008099283, -0.0...  \n",
       "311  [0.0041351523, -0.0051084706, -0.028601801, -0...  \n",
       "236  [-0.029224416, -0.011000588, -0.02764561, -0.0...  \n",
       "30   [-0.016532253, -0.018671215, 0.0024112132, -0....  \n",
       "261  [0.0102727655, 0.031475015, 0.0041768197, -0.0...  \n",
       "149  [0.007820222, -0.034854155, 0.013937257, -0.08...  \n",
       "99   [0.012194014, 0.011370001, -0.014867495, -0.04...  \n",
       "36   [-0.015313634, -0.009707481, -0.0045037856, -0...  \n",
       "108  [-0.014948463, -0.0071810996, -0.0101971235, -...  \n",
       "300  [-0.0069135656, -0.0037595944, -0.022816306, -...  \n",
       "168  [-4.4061668e-05, -0.008561462, -0.0062373965, ...  \n",
       "292  [0.002165168, -0.022245526, 0.017436543, -0.07...  \n",
       "277  [-0.0058988086, 0.013784122, -0.015859485, -0....  \n",
       "33   [-0.016705524, -0.008376931, -0.01870026, -0.0...  \n",
       "226  [-0.01992363, 0.021712968, 0.013815594, -0.062...  \n",
       "23   [-0.037104376, -0.016576506, -0.019182565, -0....  \n",
       "144  [-0.04764038, 0.010794757, 0.0047175414, -0.05...  \n",
       "78   [0.009859718, -0.009872029, 0.02174849, -0.054...  \n",
       "215  [0.0005466202, 0.0077015567, 0.005614247, -0.1...  \n",
       "147  [-0.01226142, -0.00048677987, -0.010317536, -0...  \n",
       "60   [-0.011085541, -0.015644377, 0.02316334, -0.09...  \n",
       "201  [-0.0061332616, -0.0058089164, 0.0072566825, -...  \n",
       "332  [-0.003842375, 0.015801212, -0.017305838, -0.0...  \n",
       "41   [-0.014525433, 0.01642175, 0.010939563, -0.071...  \n",
       "287  [0.018854156, 0.0033274922, -0.0072523863, -0....  \n",
       "200  [-0.008917223, -0.013621849, 0.0017390692, -0....  \n",
       "310  [-0.036277726, 0.011091107, -0.013213003, -0.0...  \n",
       "121  [0.010763933, -0.003074528, -0.011531402, -0.0...  \n",
       "142  [0.0034173268, 0.014688194, 0.0070801787, -0.0...  \n",
       "118  [-0.03000513, -0.024266208, 0.01600963, -0.072...  \n",
       "119  [0.009150241, -0.017897055, 0.008854199, -0.05...  \n",
       "25   [-0.032807905, 0.002414791, -0.0038823327, -0....  \n",
       "177  [-0.007219498, 0.00479843, -0.012593151, -0.10...  \n",
       "229  [-0.016419495, 0.024953509, -0.010564933, -0.0...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_df_new #We can see the new column with the embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save them to pickle files\n",
    "train_df_new.to_pickle(\"./data/train_df_sample_embeddings.pkl\") \n",
    "test_df_new.to_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load the pickle files\n",
    "train_df_new = pd.read_pickle(\"./data/train_df_sample_embeddings.pkl\")\n",
    "test_df_new = pd.read_pickle(\"./data/test_df_sample_embeddings.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3072"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df_new.iloc[0][\"embeddings_values\"]) # Gemini embedding dimension is 3072 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\didif\\Documents\\TA Jobs\\Data Mining TA - 2025\\Homework 2\\Master\\DM2025-Lab2-Master\\.venv\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning:\n",
      "\n",
      "n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "@saclivin @MrsCagg specific &amp; intentional way. And part of that intention is to provoke conversation around systemic racism towards blacks.",
           0.583
          ],
          [
           "Now they fret about scuffs. I’ll take scuffs (which…come in) for a phone I can use wet handed or drop in a toilet any day.",
           0.396
          ],
          [
           "@Freepenalties @TMortimerFtbl Doll is a vile creature on the touchline. Every game he has tantrums &amp; shouts at the ref. Would love to see",
           0.479
          ],
          [
           "Police Officers....should NOT have the right to just 'shoot' human beings without provocation. It's wrong.\\n\\n@ORConservative @MichaelaAngelaD",
           0.688
          ],
          [
           "@BarackObama I love Lizzy Warren's latest rage against Wall Street.",
           0.177
          ],
          [
           "I need to stop second guess myself and just go with the first thought and go with it. ",
           0.208
          ],
          [
           "Recommended reading: Prisoners of Hate by Aaron Beck ",
           0.292
          ],
          [
           "#Taurus will react angrily when she can't take being provoked any longer.",
           0.438
          ],
          [
           "This provocation sets off a curiosity. An entity is feeding fuel to the fire. speaking quatrains. Hmmm America needs to be vigilant now",
           0.5
          ],
          [
           "@savageimiike one of my favorite songs brother, real talk. #rage",
           0.417
          ],
          [
           "Colors of the leaves are- changing.  Heatwaves in LA still- raging.  Lattes made in batches. Visit pumpkin patches. #FallSongs",
           0.271
          ],
          [
           "@Thebeast_ufc what happened to the suicide tweet it was a joke obviously how could that offend anyone?🤔",
           0.542
          ],
          [
           "If i could just get my line to block! #germantownbroncos #lilleague #popwarner #Broncos #usafootball  #lineman",
           0.417
          ],
          [
           "@jwolfie_ why you gotta use the dark skin emoji ",
           0.479
          ],
          [
           "@CBSBigBrother never bring back Meech and Bridgette. Crying because someone looks at you? Ugh, and Bridgette. ",
           0.479
          ],
          [
           "Ellie just gave me loads of gifts with notes on em for uni n I burst out in tears, I LOVE HER😩",
           0.146
          ],
          [
           "@Ms_HeartAttack peanut butter takes away the sting",
           0.188
          ],
          [
           "That way ur so angry you can literally feel ur blood boiling",
           0.75
          ],
          [
           "People irritate me 🙄",
           0.646
          ],
          [
           "I believe I'm gonna start singing in my snap stories on the tractor. Switch it up a little bit.",
           0.375
          ],
          [
           "@savageimiike one of my favorite songs brother, real talk. ",
           0.157
          ],
          [
           "How is it suppose to work if you do that? Wtf dude? Thanks for pissing me off. ",
           0.875
          ],
          [
           "Puzzle investing opening portland feodal population is correlative straight a snorting infuriate: XLzjYhG",
           0.458
          ],
          [
           "I hate my lawn mower. If it had a soul, I'd condemn it to the fiery pits of Hell.",
           0.833
          ],
          [
           "@LisaAsquithtobe @craig8710 @WayneHaselden @june65wigan everyone is against wigan because we are the biggest club #bitter",
           0.562
          ],
          [
           "Ok but I just got called a 'White Devil' on the train and I didnt know whether to laugh or be offended",
           0.484
          ],
          [
           "im also definitely still bitter about the yellow ranger not being asian, but asian representation in hollywood is essentially a shrug anyway",
           0.417
          ],
          [
           "I don't get what point is made when reporting on Charlotte looting @CNNAshleigh. Why not explore what looting businesses symbolizes ",
           0.438
          ],
          [
           "@ashleighjessica @zacflint1 I'd give that pout the firm D",
           0.5
          ],
          [
           "I think I must scare my coworkers when I'm eating like a rabid animal on my breaks #srry",
           0.5
          ],
          [
           "You ever just find that the people around you really irritate you sometimes? That's me right now 😒",
           0.792
          ],
          [
           "Hell hath not fury like a hamstring cramp. #ouch",
           0.542
          ],
          [
           "could never be a angry drunk lol yall weirdos just enjoy your time",
           0.521
          ],
          [
           "@mdivincenzo9 he's stupid, I hate him lol #bitter",
           0.646
          ],
          [
           "@Disneyland #nothappy and still #charging the #fullprice 😡😡 #fuming some your #bestrides 😳😳",
           0.646
          ],
          [
           "So Rangers v Celtic ll #revenge",
           0.333
          ],
          [
           "I wonder what would happen if I were to tell some people the truth #savage #uhoh ",
           0.458
          ],
          [
           "Bitches aggravate like what inspires you to be the biggest cunt known to man kind?",
           0.854
          ],
          [
           "S/O to the girl that just hit my car...not only did she get lucky w/ no scratch but also from being spared the wrath of sleep deprived Kait🙃",
           0.542
          ],
          [
           "@TrussElise Obama must be fuming.. lol",
           0.5
          ],
          [
           "Everybody talking about 'the first day of fall' but summer '16 is never gonna die #revenge @Drake",
           0.417
          ],
          [
           "@pbhushan1 @IndianExpress so in your opinion is this the worst delhi govt? #acrid  #hypocrisy",
           0.526
          ],
          [
           "All Brian does is sleep and aggravate me",
           0.833
          ],
          [
           "@TrueAggieFan oh so that's where Brian was! Where was my invite? #offended",
           0.417
          ],
          [
           "@TrevorHMoore @paget_old In Scotland, the right-wingers are the most rabid anti-nationalists. Socialists are mostly in favour.",
           0.604
          ],
          [
           "I think our defense here at USC is playing well, we just need to fix a few things on offense and we can win the PAC 12 this year'",
           0.25
          ],
          [
           "Realest ever, relentless ever, inevitable that I win.",
           0.415
          ],
          [
           "It's the most magical time of the year......Xmas party announced and the #outrage commences. Gotta love Silicon Valley millennials.",
           0.429
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "hDrDQBmA/0AkRvpAbKm/QNuEs0DpMwVBLUv3QGd+A0FHLLxADC/oQP3Y0EAdB9hA+rfwQHdH0EBsF+FAO+65QIxV0kDWzQRBDU0IQeb240B3uuhAjCoAQUATwEDsggNBcX/0QJagmEBOIgNB+ze6QIZNqUDT1gVBRtcHQcxACkEMTv1AbSX6QGKv2kDxuK1A1vgAQRTxAEHXecVAOSGZQCcNykBccLFADdgIQU+J00DKyKNAs5XzQCWn50D/q8pA",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "rD20QI404UBBfotAFwWjQD5FrkDRPP9AQZK/QAqFwUAd8LhA02wIQTLxEEFLF7dAGdLwQCKhvEDpAKFAZEYEQZxb7UD9Y8NANG/BQJHf8ECF7wlBtsm3QETYyEAEVrVASsKhQODw20Bs49VAlQioQCcr70AIJABBRsvGQPcn0ED9l8lANCmxQH+Li0BYkMRAIn/1QGU0tUBlkvVAuZXGQMiiFEEhgZ5AiaC7QC1Mv0CE/rtAFH3zQHvMCEFOQcNA",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "you come running back to me saying how much you miss me then cower away when we acc try a friendship 👍🏼",
           0.521
          ],
          [
           "#Terrorism can be destroyed easily if #wholeworld came together great strength..they could destroy this #fear from #humanity..",
           0.5
          ],
          [
           "While we focus on issue of #IPCA @IHFOKids Indulges in #intimidation @BringRoshniHome @ChildrensIssues @MEAIndia @MinistryWCD #StopCruelty",
           0.562
          ],
          [
           "Recently changed to @firstdirect and its the worst service I've ever encountered nearly require DNA to access anything. #awful 😩😩😩",
           0.5
          ],
          [
           "i might have #hysteria ,i don't kno if it's just #anxiety or both,..need a diagnosis cuz somethin' is messed up,need ert bu i nvr come out",
           0.86
          ],
          [
           "Most Americans think the media is nothing but Government propaganda BS. #lies #control #BS #RiggedSystem  #garbage #oreillyfactor",
           0.521
          ],
          [
           "Obama admin rejects Texas plan to have refugees vetted for terrorism so Texas pulls of of fed refugee resettlement program. Aiding .",
           0.458
          ],
          [
           "Thoroughly enjoying AHS tonight. #ahs  #americanhorrorstory",
           0.146
          ],
          [
           "@BrumSciComm in a danish.  What horror, what depths. #gbbo",
           0.542
          ],
          [
           "@JasonBHampton it's Bowers. I went and drove it for a while this evening #horrible",
           0.447
          ],
          [
           "It's 5:55am. I'm hungry but there is no food. ",
           0.417
          ],
          [
           "And I would advise that everyone wait to watch @KevinCanWaitCBS ,or actually don't wait, just don't even watch it because it is #awful",
           0.229
          ],
          [
           "@JaySekulow what can we do 2 get @realDonaldTrump 2 reveal his taxes? That is the immediate danger. But u will not answer me. ",
           0.646
          ],
          [
           "#Aleppo city is burning. The head of #terrorism #Assad regime &amp; #Russia are bombarding the city right now with #whitephosphrus #bombs !",
           0.729
          ],
          [
           "I feel horrible. I have accounting today but physically and mentally am not okay 😪",
           0.833
          ],
          [
           "She was so posh it frightened me. I'm still scared.",
           0.81
          ],
          [
           "@thebully10 does being a #bully make u feel like a #bigman? Cos it makes u a #twat",
           0.396
          ],
          [
           "@alicemazzy he was more partisan on social issues a few years back; now he just concern trolls the center left as Chait does the far left",
           0.354
          ],
          [
           "@ManUtd it was a terrible Freekick...",
           0.347
          ],
          [
           "Sir, my concern is not whether God is on our side; my greatest concern is to be on God's side, for God is always right.' - Abraham Lincoln",
           0.333
          ],
          [
           "I seem to alternate between 'sleep-full' and sleepless nights. Tonight is a sleepless one. 😕 #insomnia  #notfair",
           0.583
          ],
          [
           "@jessespector @nasboat old rich white religious guy supports republicans. Not shocking at all.",
           0.271
          ],
          [
           "@CBSThisMorning @newsgirl123456 again, profiling DOESN'T discourage (September 20, 2016; 18:41 EDT) #terror #TRUMP #FAIL",
           0.667
          ],
          [
           "@Miami4Trump Yeah, but bad part is the #terrorism #terror Muslims won't be the ones leaving #ObamaLegacy #nationalsecurity #disaster #Obama",
           0.63
          ],
          [
           "We, #Indians, can hold our heads up high and stay unafraid. The #UNGA is well-informed about #Pakistan's #terrorism business and deception.",
           0.438
          ],
          [
           "@mcdermo11 @rogerc32 u gave Laura so much constructive criticism she blocked u 'Lazy Give Up Now No Hope Retire' same with Heather #bully",
           0.521
          ],
          [
           "Romero, Rojo, Blind, Memphis, Rooney. This is nearly a starting line up I’d wanna punch in the face rather than shake their hand.",
           0.438
          ],
          [
           "@carlybigelow13 first you take the room now you wanna beat me up ",
           0.412
          ],
          [
           "#Muslims are the principle victims of #terrorism. More Muslims are dying at the hands of these #terrorists than anyone else. #YounusAlGohar",
           0.583
          ],
          [
           "procrasting is fun until im an hour away from the time its due and i still havent finished so i have a panic attack",
           0.92
          ],
          [
           "@1NatalieMaines Can you imagine being the person who has to spray tan him? ",
           0.28
          ],
          [
           "@bdp514am We are a tired and restless community. We are human and tired of asking for change only to be ignored.",
           0.458
          ],
          [
           "Still waiting to see if my @london2012track will make an appearance next week - two months today it was ordered #shocking #badservice",
           0.583
          ],
          [
           "My study skills are terrible 😒",
           0.562
          ],
          [
           "Swear all of my guy friends are scaredy cats. You don't do horror movies. You don't do haunted houses. Wtf do you do then?",
           0.271
          ],
          [
           "Fosu Mensah is having a complete nightmare! It's the reason all Northamptons attacks come from the left.",
           0.604
          ],
          [
           "I have no #alarm preset #life will #wakemeup",
           0.396
          ],
          [
           "It's 5:55am. I'm hungry but there is no food. #panic",
           0.723
          ],
          [
           "How can you blame the manager watching these players play? It's abysmal. Our team are dreadful. If Jose can't save us. No-one can.  #mufc",
           0.458
          ],
          [
           "$100 says Teufel is 'reassigned' within the organization before next year, but I wish it was sooner... #Mets #thirdbasecoach #terrible #lgm",
           0.417
          ],
          [
           "@Avanquest i have unsubscribed 3 times from your spam emails still coming? STOP THE EMAILS #avanquest #software #terrible",
           0.438
          ],
          [
           "Ronaldo has been shocking. He's tried to do skill twice and he's nearly fallen over both times",
           0.5
          ],
          [
           "It's never the end / When the moment is dire. / A small spark of hope / Can relight a new fire.",
           0.396
          ],
          [
           "im what a 90s tv bully would call 'a nerd' but i would rather shove one thousand nickels into my right earhole than go to new york comic con",
           0.25
          ],
          [
           ".@Tolumanda love it! so true. As @Deedeey_ taught me, fear can be an illusion. #coaching  #courage",
           0.375
          ],
          [
           "a #monster is only a #monster if you view him through ",
           0.438
          ],
          [
           "@gdimelow @TheDailyShow @NivenJ1 @jordanklepper These interviews scare the crap out of me. I never imagined so many dumb, dumb Americans.",
           0.812
          ],
          [
           "Idk if it's hella hot in here or I'm nervous",
           0.68
          ],
          [
           "We can't stop racism overnight. Nor gun violence. Nor terrorism. But we CAN literally stop Trump overnight. So, like, let's? #ImWithHer",
           0.521
          ],
          [
           "@jody_paterson So I worry about emphasis on 'keeping family together' as a guiding principle, due to my own experiences",
           0.396
          ],
          [
           "@RobdotThom @sulphurhoops in fact they need to start making all holidays! Maybe even e dry month pick a theme so we can have them all year",
           0.229
          ],
          [
           "I have been seeing terrible terrible prescriptions this week. What's going on?",
           0.438
          ],
          [
           "Trying to book holiday flights on @britishairways website is becoming a #nightmare",
           0.458
          ],
          [
           "I don't want speak front to him #afraid #intimidate #nopanicattack",
           0.875
          ],
          [
           "@madhav_pastey moral of the story, never check mails in the night. PS. Most notices have nothing much to worry about. @ashwinikn",
           0.354
          ],
          [
           "You want  bad service use #frontier they have #terrible service. Go to #AT&amp;T anybody is better. I am going to complain to better business",
           0.333
          ],
          [
           "@lukeshawtime terrible",
           0.521
          ],
          [
           "@LethalWeaponFOX This show SUCKS! #lame #awful you even used the same names?? lol SO SO bad! #Failed #notworth2minutes. Off air SOON",
           0.396
          ],
          [
           "Another fun fact: i am afraid",
           0.667
          ],
          [
           "Nothing worse than an uber driver that can't drive. ",
           0.562
          ],
          [
           "@stephenfhayes Mustard gas = hostile work environment, not #terrorism; call #OSHA not #military",
           0.708
          ],
          [
           "@AlaskaGurus @adventuretweets agreed! 😍 an awe to meet such beautiful, powerful animals.",
           0.208
          ],
          [
           "@BuzzFeed so this houses will get into my instestines and scare my poop and I'll shit my pants?",
           0.7
          ],
          [
           "Tweeting from the sporadic wifi on the tube #perilous",
           0.434
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "tVwUQT1Jo0BhNKNAIkDpQDB7B0FAtsdA9QycQHkIw0BPdehAj2b7QFnWC0FAIulAFgCyQEXDn0A5xBVBkboEQUgw60AGz6xAfKH7QFc3rEDLRQtBcJmpQBt0pUD+9qJAI/6aQAeQ4kAXTv9AlNbnQHklnEBd/whBCc+lQKfF2kCwIeJAeb8OQalSAEGj1AFBkBwGQamOCEEG1/pAlVbsQPGd6kB/5wBBPSrfQOHBA0HHlfpAHCTuQCaV1UBXewdBeBipQLeurUCNXtVAUHEFQVgz50DgVgNBS3SwQPAm5kDFmv9AQkrkQLJRBkFYkvpAyRWhQF8WyEDy1/1AlXzfQA==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "8H3aQDHOm0D6+7FAhdyHQGI1C0GnOp1AfD2XQAtEBUFa5tZA6kifQC/I+UDIbJRA1KehQF7PmUBdAuZAbLIKQVV2sEAnpa9A4MKKQKODCEGYdelAJ8evQLSBnUCAoJZAnpKnQNxTqUCTWIVAUwSzQNm+mUD8MgpBpczdQDfzr0AYvIRAoU3jQA6C6UAaz51A9RX0QAPOA0FIQIhAVWyUQJa9ikC0HotAbr0GQZEF2UCzSAxBwWbHQH41nkArUAdBNQKaQDFSukBH9MtAUD2iQDiAhUCzNg1BWdnSQL6yjkBRrJtAvDWZQI4eCEHk55pASNaWQIzvBkFkTe1A3KbeQA==",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "Peter is aesthetically pleasing to look at",
           0.583
          ],
          [
           "@doctorofinfo I was just introducing a little levity to the convo. Yep!",
           0.54
          ],
          [
           "The human race has one really effective weapon, and that is laughter. -- Mark Twain",
           0.44
          ],
          [
           "@AphoticSanguine —but be a little playful. \\n\\nHe hesitantly pulls away, just enough so he could get words out, lips brushing against—",
           0.46
          ],
          [
           "@weebtard sparkling water wyd",
           0.229
          ],
          [
           "I love Mary's undying optimism. You could present her with dog shite and she'd find something good to say. #GBBO",
           0.562
          ],
          [
           "@UKLittleKitchen Defo a hearty root veg gratin. Nice comfort food as Autumn kicks in",
           0.48
          ],
          [
           "#ThisIsUs has messed with my mind &amp; now I'm anticipating the next episode with #apprehension &amp; ! #isthereahelplineforthis",
           0.4
          ],
          [
           "@biggerthanyuu He's flushed upon hearing the feeling is reciprocated. He's elated to shove himself right into his arms and hug him tightly.+",
           0.5
          ],
          [
           "$SRPT Why would Etep patients &amp; Mom's advocate for a drug if it did not work? Anyone listen to the Etep MD's @ Adcomm.. all were elated.",
           0.22
          ],
          [
           "Something about these cool, breezy fall days.. 😍🍂🌾🍁",
           0.729
          ],
          [
           "@ItWontCostMuch_ 'Bed done... floor will be done last... curtains! A-hah!' She tried to sound all happy and cheery but she really wasn't.--",
           0.229
          ],
          [
           "@bradshawjp Sweet! ",
           0.646
          ],
          [
           "On the bright side, my music theory teacher just pocket dabbed and said, 'I know what's hip.' And walked away 😂😭",
           0.521
          ],
          [
           "@jessbr0ughton don't be shy next time! We're a cheery bunch. :) \\n\\nSam. X",
           0.48
          ],
          [
           "@Hank_nsno @RonaldKoeman cheering and clapping I assume",
           0.417
          ],
          [
           "Kayaking is merriment together with sevylor inflatable kayaks: eYGgJxMl",
           0.562
          ],
          [
           "@Norn_IronMaiden @forest_fr1ends It's hilarious",
           0.694
          ],
          [
           "God just replaced my sadness with laughter, can't go the whole day sad ...",
           0.615
          ],
          [
           "Oh that cheery fucking note, good night shit heads X",
           0.188
          ],
          [
           "Good morning, Trondheim! #optimism #productivity ⛅️❤️🇳🇴🏢💻🖥🏋🏻💪🏼📺🍿",
           0.771
          ],
          [
           "@mediacrooks @thenewshour @LodhiMaleeha @ndtv @IndiaToday This is hilarious ! Not a Freudian slip, eh !",
           0.667
          ],
          [
           "@alpuzz Ah, but once I got it to work, there was much rejoicing! Lol thanks will get it to do taht now.",
           0.812
          ],
          [
           "@Singaholic121 Good morning, love! Happy first day of fall. Let's make some awesome #autumnmemories #annabailey  ",
           0.86
          ],
          [
           "I'm a cheery ghost.",
           0.58
          ],
          [
           "@RealestCastiel just sitting close to him for an extended period of time was exhilarating because he's so beautiful and lively lol",
           0.72
          ],
          [
           "@iamTinaDatta love you so much #smile 😊😊",
           0.896
          ],
          [
           "Omg. You've got to watch the new series 'This is Us'.....wow. Best tv show I've seen in a long time.\\n#tears #laughter #moretears",
           0.827
          ],
          [
           "@Blancalanka96 thought it'd be fun and it is not fun but on the bright side I don't have to fight for parking",
           0.34
          ],
          [
           "Just watched Django Unchained, Other people may frown, but I titter in delight! 2/5",
           0.536
          ],
          [
           "Yo this 3 v 3 overtime in hockey got me sweaty damn this ish exhilarating",
           0.68
          ],
          [
           "@kymwhitley hello Miss Lady I'm sure today brings you happiness and laughter use your voice also to make us laugh  god knows we need it",
           0.562
          ],
          [
           "@LFScott57 Miss Cookie sends her thanks! She's not as spry as she used to be - like me! She doesn't have the adventures the young pups do!",
           0.6
          ],
          [
           "@berniedole looks that way. But let's think about Rohan last week ... ",
           0.131
          ],
          [
           "@delon03 can you at least just walk past her and break out into laughter",
           0.417
          ],
          [
           "The current run of superman continues to be a delight! You can feel the love poured into it by everone on the creative team #superman",
           0.654
          ],
          [
           "@r0Ils ppl get triggered over u smiling they're irrelevant",
           0.17
          ],
          [
           "Google caffeine-an sprightly lengthening into the corridor re seo: WgJ",
           0.2
          ],
          [
           "When we give cheerfully and accept gratefully, everyone is blessed. »Maya Angelou",
           0.712
          ],
          [
           "A lifetime of laughter at the expense of the death of a bachelor",
           0.354
          ],
          [
           "Each day is what you make of it! #goals #challenges #business #goals   #success #photographer #photography #ThursdayThoughts",
           0.604
          ],
          [
           "@NateBLoL no it was that clear American naturally flavored sparkling water",
           0.312
          ],
          [
           "If any trump supporters and Hillary haters wanna chirp some weak minded, pandering liberals just tweet at @EmmyA2 @snickerfritz04",
           0.1
          ],
          [
           "@Casper10666 I assure you there is no laughter, but increasing anger at the costs, and arrogance of Westminster.",
           0.167
          ],
          [
           "It's #HobbitDay! \\nHobbit's give gifts on their birthdays, so I'm sharing the gift of #glee today! Find something that makes you happy!",
           0.708
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "stvLQMfqu0BJcZpAcuGrQMb3x0BwYeNAQnXSQMPPAEHUjLlA86DPQBqGy0BF6LFA82/JQGVywUDwobhAYW6iQMbgtUAwDp9AjHKoQCXQ/0AaQMpAegeeQEA0sUC32cBAFNK5QErCxkDOjp5AiBu/QAkw1UAThbFApnT3QF4Zo0Bs/stAIj/SQAE5nkC85sFAXHKbQNf3uEBEzKdAi8CVQEvW1EAdvsVAHpW3QCwamUDSoqpA",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "Rij9QOM25kDngO1AXZjmQIzG3kAig9ZAxkEDQY+AB0Ff7ABBzgqyQBdlD0GQ6etABKT2QKPK4kA5M/JADXvgQHNl4EANINhA1vP+QF/zu0C9TQxBlTK+QJHF80A8ZBBBdG/vQIfNA0E8y/5AoGwGQX9R5kCKNvtAG80CQS/fAEG6DfVAkTnNQGe340Bm/AZBnJ7xQPEC1UBdLgdByUfjQKmsB0EsT9tAuXKlQNOqykCOzAdB",
          "dtype": "f4"
         },
         "yaxis": "y"
        },
        {
         "customdata": [
          [
           "November #canola lost $5.50 to $464.20 per tonne.",
           0.479
          ],
          [
           "Had to give up on The Blue Guitar, couldn't stand main character. Sort of skim-read to the end which got grim and unsettling . . . 1/2",
           0.583
          ],
          [
           "@CrucialBMXShop ohh silver lake came up a lot on there! Is that where you guys stayed?",
           0.208
          ],
          [
           "Please bear with me, I'm not Twitter savvy😝 in real life I'm a Facebook person. Help me gain followers 🤓 #blog #selfhelp ",
           0.146
          ],
          [
           "@ManUtd Rooney needs to come off! Absolutely dreadful! 🙈🙈🙈 class goal from @carras16 @carras16 showing why he should be in the team!!",
           0.5
          ],
          [
           "@littlebakaa @AlcohoIPorn give me a smiling emoticon will ya? i dont like the idea of you frowning &gt;.&lt;",
           0.417
          ],
          [
           "Damn gud #premiere #LethalWeapon...#funny and ",
           0.229
          ],
          [
           "Corbyn loses and I walk up to a crying Corbyn supporter and whisper\\n\\n'Don't mourn. Organise'\\n\\nAnd laugh and laugh",
           0.354
          ],
          [
           "Sometimes The Worst Place You Can Be Is In Your Own Head.'\\n\\n#quotes #worstenemy #depression #thinktoomuch",
           0.854
          ],
          [
           "@MSNBC @fox @cnn @realDonaldTrump @HillaryClinton. Using fear to state his views. Not getting the facts before making a serious statement???",
           0.417
          ],
          [
           "@cotsonika @NHL well, they should all be unhappy for the way they played.  Right @fmjacob ??",
           0.542
          ],
          [
           "@EBled2 Great to have you as our tournament chair and award was #serious",
           0.132
          ],
          [
           "@hannah_2401 hannah stop being mournful and chill 💁",
           0.188
          ],
          [
           "@msfang they say you attract what you see, maybe I shouldn't be a pessimist but I don't wanna take any chances lol can't wait to relocate",
           0.333
          ],
          [
           "Honestly don't give af who wins out of us and pine, I'm just worried about getting drunk Saturday night😂",
           0.208
          ],
          [
           "Condolences to the  JC and the Georges family.. #sad",
           0.771
          ],
          [
           "@JonathanHatfull I’ll look forward to it. Hoping for lots of stetson-tilting and rueful looks into whiskey glasses.",
           0.333
          ],
          [
           "gloomy weather puts me in the best mood",
           0.271
          ],
          [
           "Absolutely can not believe the generosity pouring out for us, but Id give everything I have for Nick to be healthy and happy. #lost",
           0.542
          ],
          [
           "@everton_de_leon @sterushton Genuinely grim stuff. Over a century of history sold off by some porn baron twats for a minty new stadium. Urgh",
           0.624
          ],
          [
           "@cburt43 turn that frown upside down",
           0.27
          ],
          [
           "Sky news still pushing the Brexit gloom line, managing to ignore the fact it's simply not happening. 'But in the future.....'",
           0.396
          ],
          [
           "Learning to trust God can quiet a troubled &amp; restless heart, bring peace to a weary soul, &amp; eliminate the hopelessness that #addiction is!",
           0.24
          ],
          [
           "@pureleine though lately with how bad my depression has been i feel like my body is like just, taking what little it can get",
           0.771
          ],
          [
           "Cause fail or pass I refuse to be sober",
           0.604
          ],
          [
           "Very long day. Thank goodness for Bake Off to brighten up a weary Wednesday ☺ #GBBO",
           0.188
          ],
          [
           "Patti seems so sad. She stamped and ran behind the sofa. We will have to give her plenty of love and affection...more than usual. #sad",
           0.729
          ],
          [
           "Going home is depressing",
           0.896
          ],
          [
           "Lisa: Getting what you want all the time will ultimately leave you unfulfilled and joyless.",
           0.5
          ],
          [
           "Be joyful in hope, patient in affliction, faithful in prayer. Romans 12:12",
           0.216
          ],
          [
           "@SilkInSide @TommyJoeRatliff that's so pretty! I love the sky in the background and the purple highlights with the dull colors is great",
           0.088
          ],
          [
           "We have left #Maine. #sadness",
           0.771
          ],
          [
           "I sulk too much for my own good.",
           0.896
          ],
          [
           "That's me for the evening, though! Way too lit to finish these off properly without causing some serious mischief.",
           0.396
          ],
          [
           "Don't wanna go to work but I want the money #sad",
           0.729
          ],
          [
           "@LeePorter94 @DomMcGovern_ hi Dom I saw u at Notts county away, looking for 1 mufc away ticket will pay ",
           0.312
          ],
          [
           "On bedrest since I got out of the hospital. U find in unopened beer.. what do I do. Pour that shit out! No alcohol at all for me #sober",
           0.44
          ],
          [
           "This shit hurting my heart 😪 that's how serious it is .",
           0.875
          ],
          [
           "Might go on @RadioX tomorrow to hopefully win a new car. My current one stinks of gone off milk. #grim",
           0.458
          ],
          [
           "All I want to do is watch some netflix but I am stuck here in class. #depressing",
           0.667
          ],
          [
           "We are about a little over an hour away! We will arrive soon, do not fret!",
           0.125
          ],
          [
           "“Dyslexia is the affliction of a frozen genius.”― Stephen Richards",
           0.333
          ],
          [
           "you are on an endless journey of figuring yourself out; don't be discouraged when you don't know who you are yet.",
           0.375
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "orientation": "v",
         "showlegend": true,
         "type": "scatter",
         "x": {
          "bdata": "X9biQD++DkEjbMlA8yfdQIjI+0Dhb6JAO5u6QBWulkAoxRJBEiasQJrg20ADgcVA/dizQLZz3EC1HvZAYWMZQZC7wUCgH81Al8+zQGsd/EAHlaVAPnubQIR8rUBfJxVB9R35QNT700DTAxdBDpUXQfxzC0FezaZAFGHKQOPCGkHcjQ1Br3XwQDAAGEEEIftA1o79QFK6FUFqjONAJksSQVMhBkHKQA9BPAkMQQ==",
          "dtype": "f4"
         },
         "xaxis": "x",
         "y": {
          "bdata": "fQT0QC6U4kDkM9NAol7pQG3sg0AW2vFAgCX8QDxg3EBMkfBAJhunQGTvskBh6exA62fpQHqE7kDQ7NxAkYbfQPe76UCe2Q9BTzUHQROEkECSZvZAiEmzQKO+C0EVSvBAqJnZQLlRAEE34etAYWbyQI/n8kDyGQlBwnoHQVTm7kBAB+xA3abgQOkU6kAlooJAmJDUQNym2EA+6N5A/WnqQBzlCUFetu1ABtv5QA==",
          "dtype": "f4"
         },
         "yaxis": "y"
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "2D UMAP Projection of Text Embeddings"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP1"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "UMAP2"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import plotly.express as px\n",
    "\n",
    "# Concatenate the training and test data\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "\n",
    "# Prepare the embeddings for UMAP\n",
    "# Convert the list of embeddings into a 2D numpy array\n",
    "X_embeddings = np.array(combined_df['embeddings_values'].tolist())\n",
    "\n",
    "# Apply UMAP for dimensionality reduction\n",
    "reducer = umap.UMAP(n_components=2, metric='cosine', random_state=28) \n",
    "embedding_2d = reducer.fit_transform(X_embeddings)\n",
    "\n",
    "# Create a DataFrame for plotting\n",
    "df_plot = pd.DataFrame(embedding_2d, columns=['UMAP1', 'UMAP2'])\n",
    "df_plot['emotion'] = combined_df['emotion']\n",
    "df_plot['intensity'] = combined_df['intensity']\n",
    "df_plot['text'] = combined_df['text']\n",
    "\n",
    "\n",
    "# Visualize the embeddings with Plotly\n",
    "fig = px.scatter(\n",
    "    df_plot,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='emotion',  # Color points by the 'emotion' column\n",
    "    hover_data=['text', 'intensity'],  # Show text and intensity on hover\n",
    "    title='2D UMAP Projection of Text Embeddings'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that even with Gemini's embeddings there doesn't seem to be a clear 2D separation of clusters with our data classes. It could be because emotions are often not discrete. Texts can contain mixed feelings (e.g., \"bittersweet\") or use similar language to express different emotions, causing their embeddings to be naturally close in semantic space. And also the process of projecting high-dimensional embeddings down to a 2D visualization inevitably loses some information, which can make distinct clusters appear to overlap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_8_1_1_'></a>[**>>> Exercise 4 (Take home):**](#toc0_)\n",
    "\n",
    "Apply UMAP to the same embeddings to reduce the dimensionality to 3D vectors and plot the 3D graph, discuss the differences and similarities with the 2D graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\81203\\DM2025\\DM2025-Lab2-Exercise\\.venv\\Lib\\site-packages\\umap\\umap_.py:1952: UserWarning: n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "customdata": [
          [
           "@saclivin @MrsCagg specific &amp; intentional way. And part of that intention is to provoke conversation around systemic racism towards blacks.",
           0.583
          ],
          [
           "Now they fret about scuffs. I’ll take scuffs (which…come in) for a phone I can use wet handed or drop in a toilet any day.",
           0.396
          ],
          [
           "@Freepenalties @TMortimerFtbl Doll is a vile creature on the touchline. Every game he has tantrums &amp; shouts at the ref. Would love to see",
           0.479
          ],
          [
           "Police Officers....should NOT have the right to just 'shoot' human beings without provocation. It's wrong.\\n\\n@ORConservative @MichaelaAngelaD",
           0.688
          ],
          [
           "@BarackObama I love Lizzy Warren's latest rage against Wall Street.",
           0.177
          ],
          [
           "I need to stop second guess myself and just go with the first thought and go with it. ",
           0.208
          ],
          [
           "Recommended reading: Prisoners of Hate by Aaron Beck ",
           0.292
          ],
          [
           "#Taurus will react angrily when she can't take being provoked any longer.",
           0.438
          ],
          [
           "This provocation sets off a curiosity. An entity is feeding fuel to the fire. speaking quatrains. Hmmm America needs to be vigilant now",
           0.5
          ],
          [
           "@savageimiike one of my favorite songs brother, real talk. #rage",
           0.417
          ],
          [
           "Colors of the leaves are- changing.  Heatwaves in LA still- raging.  Lattes made in batches. Visit pumpkin patches. #FallSongs",
           0.271
          ],
          [
           "@Thebeast_ufc what happened to the suicide tweet it was a joke obviously how could that offend anyone?🤔",
           0.542
          ],
          [
           "If i could just get my line to block! #germantownbroncos #lilleague #popwarner #Broncos #usafootball  #lineman",
           0.417
          ],
          [
           "@jwolfie_ why you gotta use the dark skin emoji ",
           0.479
          ],
          [
           "@CBSBigBrother never bring back Meech and Bridgette. Crying because someone looks at you? Ugh, and Bridgette. ",
           0.479
          ],
          [
           "Ellie just gave me loads of gifts with notes on em for uni n I burst out in tears, I LOVE HER😩",
           0.146
          ],
          [
           "@Ms_HeartAttack peanut butter takes away the sting",
           0.188
          ],
          [
           "That way ur so angry you can literally feel ur blood boiling",
           0.75
          ],
          [
           "People irritate me 🙄",
           0.646
          ],
          [
           "I believe I'm gonna start singing in my snap stories on the tractor. Switch it up a little bit.",
           0.375
          ],
          [
           "@savageimiike one of my favorite songs brother, real talk. ",
           0.157
          ],
          [
           "How is it suppose to work if you do that? Wtf dude? Thanks for pissing me off. ",
           0.875
          ],
          [
           "Puzzle investing opening portland feodal population is correlative straight a snorting infuriate: XLzjYhG",
           0.458
          ],
          [
           "I hate my lawn mower. If it had a soul, I'd condemn it to the fiery pits of Hell.",
           0.833
          ],
          [
           "@LisaAsquithtobe @craig8710 @WayneHaselden @june65wigan everyone is against wigan because we are the biggest club #bitter",
           0.562
          ],
          [
           "Ok but I just got called a 'White Devil' on the train and I didnt know whether to laugh or be offended",
           0.484
          ],
          [
           "im also definitely still bitter about the yellow ranger not being asian, but asian representation in hollywood is essentially a shrug anyway",
           0.417
          ],
          [
           "I don't get what point is made when reporting on Charlotte looting @CNNAshleigh. Why not explore what looting businesses symbolizes ",
           0.438
          ],
          [
           "@ashleighjessica @zacflint1 I'd give that pout the firm D",
           0.5
          ],
          [
           "I think I must scare my coworkers when I'm eating like a rabid animal on my breaks #srry",
           0.5
          ],
          [
           "You ever just find that the people around you really irritate you sometimes? That's me right now 😒",
           0.792
          ],
          [
           "Hell hath not fury like a hamstring cramp. #ouch",
           0.542
          ],
          [
           "could never be a angry drunk lol yall weirdos just enjoy your time",
           0.521
          ],
          [
           "@mdivincenzo9 he's stupid, I hate him lol #bitter",
           0.646
          ],
          [
           "@Disneyland #nothappy and still #charging the #fullprice 😡😡 #fuming some your #bestrides 😳😳",
           0.646
          ],
          [
           "So Rangers v Celtic ll #revenge",
           0.333
          ],
          [
           "I wonder what would happen if I were to tell some people the truth #savage #uhoh ",
           0.458
          ],
          [
           "Bitches aggravate like what inspires you to be the biggest cunt known to man kind?",
           0.854
          ],
          [
           "S/O to the girl that just hit my car...not only did she get lucky w/ no scratch but also from being spared the wrath of sleep deprived Kait🙃",
           0.542
          ],
          [
           "@TrussElise Obama must be fuming.. lol",
           0.5
          ],
          [
           "Everybody talking about 'the first day of fall' but summer '16 is never gonna die #revenge @Drake",
           0.417
          ],
          [
           "@pbhushan1 @IndianExpress so in your opinion is this the worst delhi govt? #acrid  #hypocrisy",
           0.526
          ],
          [
           "All Brian does is sleep and aggravate me",
           0.833
          ],
          [
           "@TrueAggieFan oh so that's where Brian was! Where was my invite? #offended",
           0.417
          ],
          [
           "@TrevorHMoore @paget_old In Scotland, the right-wingers are the most rabid anti-nationalists. Socialists are mostly in favour.",
           0.604
          ],
          [
           "I think our defense here at USC is playing well, we just need to fix a few things on offense and we can win the PAC 12 this year'",
           0.25
          ],
          [
           "Realest ever, relentless ever, inevitable that I win.",
           0.415
          ],
          [
           "It's the most magical time of the year......Xmas party announced and the #outrage commences. Gotta love Silicon Valley millennials.",
           0.429
          ]
         ],
         "hovertemplate": "emotion=anger<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "anger",
         "marker": {
          "color": "#636efa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "anger",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "n00XQadN9EDzZwxBpjscQe0lHUFYHPFA1PkGQRefA0EkkRRBHwIBQadX80DKMxdBOBL6QOf8FEGfOBZBnzIGQYWABkE4JQBBINQAQbrE/UDr7gBBElUFQfB9DkFU3QFBtGgPQcwgFkFgZ/VA3SccQRShEEHetf1ATx39QPe79kBVXgRBlqgKQWXAFUHWGQtBiM8DQXZnB0HP8ARB9fUfQSQK9kAQsx5B7e/9QOOYFUHy+SFB6ML1QKgw/EBn0hdB",
          "dtype": "f4"
         },
         "y": {
          "bdata": "v6vcQNW+3EBmbAxBDCXxQO9a30BjfsZAssQCQWIb+UDh4N1ANFu5QPLkq0ALR+FAsfbFQKJY10Adif9AA7OWQBTbxkD+A/1AoMH9QG+PukA1KLRA4W/7QCyd30AAjwFBeTkGQe7vrEDVGepAw9boQAcXtEB+it5Ase38QBsm+UBEzu1Aq+oBQZCQ/0DXo/FAYTLjQMmIAUHJFalAFmbCQKmJrUC00dRA/p0CQeOx20BP8s9AA33GQHMwuUBMHtdA",
          "dtype": "f4"
         },
         "z": {
          "bdata": "rnx3QD6ChkCqf0JAJyeIQDbfg0A0y51AzzCGQNPQjUCxXI5AcKcrQHSJO0BfGVlAJcSIQNXMY0DEolpA3bJTQCvVb0AEKoxAc2+JQFWifUDA9y1AgUSGQNagi0C+BntAh1lQQGw9g0C3YYJAMiGJQIrFV0DTr65AtRSQQMvddkBIlIhAqdZ4QHd7KkBJFChAOI2kQC1VhEBE0INARzuCQDQDMUDxnZlAjTSEQHlmPEAhFHZA4oCKQCojM0CcfD9A",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "you come running back to me saying how much you miss me then cower away when we acc try a friendship 👍🏼",
           0.521
          ],
          [
           "#Terrorism can be destroyed easily if #wholeworld came together great strength..they could destroy this #fear from #humanity..",
           0.5
          ],
          [
           "While we focus on issue of #IPCA @IHFOKids Indulges in #intimidation @BringRoshniHome @ChildrensIssues @MEAIndia @MinistryWCD #StopCruelty",
           0.562
          ],
          [
           "Recently changed to @firstdirect and its the worst service I've ever encountered nearly require DNA to access anything. #awful 😩😩😩",
           0.5
          ],
          [
           "i might have #hysteria ,i don't kno if it's just #anxiety or both,..need a diagnosis cuz somethin' is messed up,need ert bu i nvr come out",
           0.86
          ],
          [
           "Most Americans think the media is nothing but Government propaganda BS. #lies #control #BS #RiggedSystem  #garbage #oreillyfactor",
           0.521
          ],
          [
           "Obama admin rejects Texas plan to have refugees vetted for terrorism so Texas pulls of of fed refugee resettlement program. Aiding .",
           0.458
          ],
          [
           "Thoroughly enjoying AHS tonight. #ahs  #americanhorrorstory",
           0.146
          ],
          [
           "@BrumSciComm in a danish.  What horror, what depths. #gbbo",
           0.542
          ],
          [
           "@JasonBHampton it's Bowers. I went and drove it for a while this evening #horrible",
           0.447
          ],
          [
           "It's 5:55am. I'm hungry but there is no food. ",
           0.417
          ],
          [
           "And I would advise that everyone wait to watch @KevinCanWaitCBS ,or actually don't wait, just don't even watch it because it is #awful",
           0.229
          ],
          [
           "@JaySekulow what can we do 2 get @realDonaldTrump 2 reveal his taxes? That is the immediate danger. But u will not answer me. ",
           0.646
          ],
          [
           "#Aleppo city is burning. The head of #terrorism #Assad regime &amp; #Russia are bombarding the city right now with #whitephosphrus #bombs !",
           0.729
          ],
          [
           "I feel horrible. I have accounting today but physically and mentally am not okay 😪",
           0.833
          ],
          [
           "She was so posh it frightened me. I'm still scared.",
           0.81
          ],
          [
           "@thebully10 does being a #bully make u feel like a #bigman? Cos it makes u a #twat",
           0.396
          ],
          [
           "@alicemazzy he was more partisan on social issues a few years back; now he just concern trolls the center left as Chait does the far left",
           0.354
          ],
          [
           "@ManUtd it was a terrible Freekick...",
           0.347
          ],
          [
           "Sir, my concern is not whether God is on our side; my greatest concern is to be on God's side, for God is always right.' - Abraham Lincoln",
           0.333
          ],
          [
           "I seem to alternate between 'sleep-full' and sleepless nights. Tonight is a sleepless one. 😕 #insomnia  #notfair",
           0.583
          ],
          [
           "@jessespector @nasboat old rich white religious guy supports republicans. Not shocking at all.",
           0.271
          ],
          [
           "@CBSThisMorning @newsgirl123456 again, profiling DOESN'T discourage (September 20, 2016; 18:41 EDT) #terror #TRUMP #FAIL",
           0.667
          ],
          [
           "@Miami4Trump Yeah, but bad part is the #terrorism #terror Muslims won't be the ones leaving #ObamaLegacy #nationalsecurity #disaster #Obama",
           0.63
          ],
          [
           "We, #Indians, can hold our heads up high and stay unafraid. The #UNGA is well-informed about #Pakistan's #terrorism business and deception.",
           0.438
          ],
          [
           "@mcdermo11 @rogerc32 u gave Laura so much constructive criticism she blocked u 'Lazy Give Up Now No Hope Retire' same with Heather #bully",
           0.521
          ],
          [
           "Romero, Rojo, Blind, Memphis, Rooney. This is nearly a starting line up I’d wanna punch in the face rather than shake their hand.",
           0.438
          ],
          [
           "@carlybigelow13 first you take the room now you wanna beat me up ",
           0.412
          ],
          [
           "#Muslims are the principle victims of #terrorism. More Muslims are dying at the hands of these #terrorists than anyone else. #YounusAlGohar",
           0.583
          ],
          [
           "procrasting is fun until im an hour away from the time its due and i still havent finished so i have a panic attack",
           0.92
          ],
          [
           "@1NatalieMaines Can you imagine being the person who has to spray tan him? ",
           0.28
          ],
          [
           "@bdp514am We are a tired and restless community. We are human and tired of asking for change only to be ignored.",
           0.458
          ],
          [
           "Still waiting to see if my @london2012track will make an appearance next week - two months today it was ordered #shocking #badservice",
           0.583
          ],
          [
           "My study skills are terrible 😒",
           0.562
          ],
          [
           "Swear all of my guy friends are scaredy cats. You don't do horror movies. You don't do haunted houses. Wtf do you do then?",
           0.271
          ],
          [
           "Fosu Mensah is having a complete nightmare! It's the reason all Northamptons attacks come from the left.",
           0.604
          ],
          [
           "I have no #alarm preset #life will #wakemeup",
           0.396
          ],
          [
           "It's 5:55am. I'm hungry but there is no food. #panic",
           0.723
          ],
          [
           "How can you blame the manager watching these players play? It's abysmal. Our team are dreadful. If Jose can't save us. No-one can.  #mufc",
           0.458
          ],
          [
           "$100 says Teufel is 'reassigned' within the organization before next year, but I wish it was sooner... #Mets #thirdbasecoach #terrible #lgm",
           0.417
          ],
          [
           "@Avanquest i have unsubscribed 3 times from your spam emails still coming? STOP THE EMAILS #avanquest #software #terrible",
           0.438
          ],
          [
           "Ronaldo has been shocking. He's tried to do skill twice and he's nearly fallen over both times",
           0.5
          ],
          [
           "It's never the end / When the moment is dire. / A small spark of hope / Can relight a new fire.",
           0.396
          ],
          [
           "im what a 90s tv bully would call 'a nerd' but i would rather shove one thousand nickels into my right earhole than go to new york comic con",
           0.25
          ],
          [
           ".@Tolumanda love it! so true. As @Deedeey_ taught me, fear can be an illusion. #coaching  #courage",
           0.375
          ],
          [
           "a #monster is only a #monster if you view him through ",
           0.438
          ],
          [
           "@gdimelow @TheDailyShow @NivenJ1 @jordanklepper These interviews scare the crap out of me. I never imagined so many dumb, dumb Americans.",
           0.812
          ],
          [
           "Idk if it's hella hot in here or I'm nervous",
           0.68
          ],
          [
           "We can't stop racism overnight. Nor gun violence. Nor terrorism. But we CAN literally stop Trump overnight. So, like, let's? #ImWithHer",
           0.521
          ],
          [
           "@jody_paterson So I worry about emphasis on 'keeping family together' as a guiding principle, due to my own experiences",
           0.396
          ],
          [
           "@RobdotThom @sulphurhoops in fact they need to start making all holidays! Maybe even e dry month pick a theme so we can have them all year",
           0.229
          ],
          [
           "I have been seeing terrible terrible prescriptions this week. What's going on?",
           0.438
          ],
          [
           "Trying to book holiday flights on @britishairways website is becoming a #nightmare",
           0.458
          ],
          [
           "I don't want speak front to him #afraid #intimidate #nopanicattack",
           0.875
          ],
          [
           "@madhav_pastey moral of the story, never check mails in the night. PS. Most notices have nothing much to worry about. @ashwinikn",
           0.354
          ],
          [
           "You want  bad service use #frontier they have #terrible service. Go to #AT&amp;T anybody is better. I am going to complain to better business",
           0.333
          ],
          [
           "@lukeshawtime terrible",
           0.521
          ],
          [
           "@LethalWeaponFOX This show SUCKS! #lame #awful you even used the same names?? lol SO SO bad! #Failed #notworth2minutes. Off air SOON",
           0.396
          ],
          [
           "Another fun fact: i am afraid",
           0.667
          ],
          [
           "Nothing worse than an uber driver that can't drive. ",
           0.562
          ],
          [
           "@stephenfhayes Mustard gas = hostile work environment, not #terrorism; call #OSHA not #military",
           0.708
          ],
          [
           "@AlaskaGurus @adventuretweets agreed! 😍 an awe to meet such beautiful, powerful animals.",
           0.208
          ],
          [
           "@BuzzFeed so this houses will get into my instestines and scare my poop and I'll shit my pants?",
           0.7
          ],
          [
           "Tweeting from the sporadic wifi on the tube #perilous",
           0.434
          ]
         ],
         "hovertemplate": "emotion=fear<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "fear",
         "marker": {
          "color": "#EF553B",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "fear",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "grbeQN5UIEEcxBlB7/UTQQZzAEFBkRlBF0oiQZyACkGaRPdA4MwFQaKN7kAFExVBy9AcQdgZIUFU/NpA860GQVTUD0HaCSBBtBANQXzHC0EavehAPGIhQUApIkFyyh9BbzIeQafPFEH3TgpBaN0QQUOTIkETDAFBEBoWQem8DEGl6RRBXIvjQBDcA0GGEgdBMZPwQG4/90APvw1BUuURQSyCF0ECeQhB/ewAQV3d70BUzg5BE00VQeQwFEHI8P1ANO4hQZOcE0F48A5Bb1gEQRh8FUHpbAhBrLYSQe+pFkF3jQlBvO4WQfUIBUFmOAhBFtIfQWUxBkHqUQNBdoD7QA==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "+HfeQGid4kCM5sxAnC4JQSby0kBzgPtA+l3mQBj+l0AHftdAuWAEQbLP3EBMRQhBurjlQM2i5EBt6uBAGrPbQJth/UD3kNtAnYgLQf5OoEA07tpAolbZQNwH6kBPcuJA+W3XQOZo+kApdg5BznjzQN5Q5kBM/NNADoi9QOHW7kDfZgJBa9nhQIQU7EB/GANBjpXeQEB22kCRKhBBTS8MQf0TB0H2JQxBko2pQBgt5UARV9dAVQnkQCmaAEHpVNFARTbsQILhykDlgdBAp7L9QJntBUGDpddAuB3FQKxjBkG90wVB+PIFQRgW20C1FwdB/UjsQFm9okAcielA+LzLQA==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "JPqMQAtEqECmYZ9AG9Y5QIhqukBrg4NAc5ufQO+uS0CbTlRAh1VBQALgrkAWcVlAQcGVQB52pkDJYJ5Axe+3QDs/bUCtD35AHd80QLsFk0B8z6VAggd8QLCPmkAgFJxAxoOmQEbnZ0CzyjVAnWNlQHw2qECXrblADjBVQNRaeEBLdSdA7yWcQK4opECZ2TRANLitQEx6tUBWkTlAbrVNQJuRP0BPCTlAJEOOQIPrhkDXjbNA0pypQHXDgkDrB69AR0qUQF9/mUBQSy9AwgVFQNH+KkAVyLpAFwOhQOOMN0BLdTVA3fphQMtft0D4u0tA/5uhQKlvMECRJqdA06pwQA==",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "Peter is aesthetically pleasing to look at",
           0.583
          ],
          [
           "@doctorofinfo I was just introducing a little levity to the convo. Yep!",
           0.54
          ],
          [
           "The human race has one really effective weapon, and that is laughter. -- Mark Twain",
           0.44
          ],
          [
           "@AphoticSanguine —but be a little playful. \\n\\nHe hesitantly pulls away, just enough so he could get words out, lips brushing against—",
           0.46
          ],
          [
           "@weebtard sparkling water wyd",
           0.229
          ],
          [
           "I love Mary's undying optimism. You could present her with dog shite and she'd find something good to say. #GBBO",
           0.562
          ],
          [
           "@UKLittleKitchen Defo a hearty root veg gratin. Nice comfort food as Autumn kicks in",
           0.48
          ],
          [
           "#ThisIsUs has messed with my mind &amp; now I'm anticipating the next episode with #apprehension &amp; ! #isthereahelplineforthis",
           0.4
          ],
          [
           "@biggerthanyuu He's flushed upon hearing the feeling is reciprocated. He's elated to shove himself right into his arms and hug him tightly.+",
           0.5
          ],
          [
           "$SRPT Why would Etep patients &amp; Mom's advocate for a drug if it did not work? Anyone listen to the Etep MD's @ Adcomm.. all were elated.",
           0.22
          ],
          [
           "Something about these cool, breezy fall days.. 😍🍂🌾🍁",
           0.729
          ],
          [
           "@ItWontCostMuch_ 'Bed done... floor will be done last... curtains! A-hah!' She tried to sound all happy and cheery but she really wasn't.--",
           0.229
          ],
          [
           "@bradshawjp Sweet! ",
           0.646
          ],
          [
           "On the bright side, my music theory teacher just pocket dabbed and said, 'I know what's hip.' And walked away 😂😭",
           0.521
          ],
          [
           "@jessbr0ughton don't be shy next time! We're a cheery bunch. :) \\n\\nSam. X",
           0.48
          ],
          [
           "@Hank_nsno @RonaldKoeman cheering and clapping I assume",
           0.417
          ],
          [
           "Kayaking is merriment together with sevylor inflatable kayaks: eYGgJxMl",
           0.562
          ],
          [
           "@Norn_IronMaiden @forest_fr1ends It's hilarious",
           0.694
          ],
          [
           "God just replaced my sadness with laughter, can't go the whole day sad ...",
           0.615
          ],
          [
           "Oh that cheery fucking note, good night shit heads X",
           0.188
          ],
          [
           "Good morning, Trondheim! #optimism #productivity ⛅️❤️🇳🇴🏢💻🖥🏋🏻💪🏼📺🍿",
           0.771
          ],
          [
           "@mediacrooks @thenewshour @LodhiMaleeha @ndtv @IndiaToday This is hilarious ! Not a Freudian slip, eh !",
           0.667
          ],
          [
           "@alpuzz Ah, but once I got it to work, there was much rejoicing! Lol thanks will get it to do taht now.",
           0.812
          ],
          [
           "@Singaholic121 Good morning, love! Happy first day of fall. Let's make some awesome #autumnmemories #annabailey  ",
           0.86
          ],
          [
           "I'm a cheery ghost.",
           0.58
          ],
          [
           "@RealestCastiel just sitting close to him for an extended period of time was exhilarating because he's so beautiful and lively lol",
           0.72
          ],
          [
           "@iamTinaDatta love you so much #smile 😊😊",
           0.896
          ],
          [
           "Omg. You've got to watch the new series 'This is Us'.....wow. Best tv show I've seen in a long time.\\n#tears #laughter #moretears",
           0.827
          ],
          [
           "@Blancalanka96 thought it'd be fun and it is not fun but on the bright side I don't have to fight for parking",
           0.34
          ],
          [
           "Just watched Django Unchained, Other people may frown, but I titter in delight! 2/5",
           0.536
          ],
          [
           "Yo this 3 v 3 overtime in hockey got me sweaty damn this ish exhilarating",
           0.68
          ],
          [
           "@kymwhitley hello Miss Lady I'm sure today brings you happiness and laughter use your voice also to make us laugh  god knows we need it",
           0.562
          ],
          [
           "@LFScott57 Miss Cookie sends her thanks! She's not as spry as she used to be - like me! She doesn't have the adventures the young pups do!",
           0.6
          ],
          [
           "@berniedole looks that way. But let's think about Rohan last week ... ",
           0.131
          ],
          [
           "@delon03 can you at least just walk past her and break out into laughter",
           0.417
          ],
          [
           "The current run of superman continues to be a delight! You can feel the love poured into it by everone on the creative team #superman",
           0.654
          ],
          [
           "@r0Ils ppl get triggered over u smiling they're irrelevant",
           0.17
          ],
          [
           "Google caffeine-an sprightly lengthening into the corridor re seo: WgJ",
           0.2
          ],
          [
           "When we give cheerfully and accept gratefully, everyone is blessed. »Maya Angelou",
           0.712
          ],
          [
           "A lifetime of laughter at the expense of the death of a bachelor",
           0.354
          ],
          [
           "Each day is what you make of it! #goals #challenges #business #goals   #success #photographer #photography #ThursdayThoughts",
           0.604
          ],
          [
           "@NateBLoL no it was that clear American naturally flavored sparkling water",
           0.312
          ],
          [
           "If any trump supporters and Hillary haters wanna chirp some weak minded, pandering liberals just tweet at @EmmyA2 @snickerfritz04",
           0.1
          ],
          [
           "@Casper10666 I assure you there is no laughter, but increasing anger at the costs, and arrogance of Westminster.",
           0.167
          ],
          [
           "It's #HobbitDay! \\nHobbit's give gifts on their birthdays, so I'm sharing the gift of #glee today! Find something that makes you happy!",
           0.708
          ]
         ],
         "hovertemplate": "emotion=joy<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "joy",
         "marker": {
          "color": "#00cc96",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "joy",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "NtkIQdMCEkEFjxRBaicQQVtwEkEnWfJAPbf1QCEIA0EcBg1BAcQLQYTE9kDFSwlBRI8IQWrCDkE4AAlBT1UXQcsYEEH12RtBwGsOQcW0BEEjy/JA43AcQd4DDkG/GvhAqrgKQWOjCkGDaAZBw8MHQWlVBUGQ4w9BaSkBQSH6DEFWrP5A4mANQZNjGEGlHwlBH10XQaZQEEEJ9gJBug8aQZ0K8UDAqxNBvdgeQWZvIEGwagBB",
          "dtype": "f4"
         },
         "y": {
          "bdata": "y1arQC3FuUBBgKFAFEasQElIyECef89A6JuwQBYBykBscKRAyqfcQDYNpEA+YbFAIHWzQHJwp0AXLrNAky6xQEKgvEB2d7NAr+ydQNWD+EC46KBABZTEQCCBpkBckZxAVJWxQNADo0AttJZA72SVQDsSuEAIsJtAM3zSQGlZnkAeFq1Aq6XWQCJcrkCrdZtAPrSuQLibykChmZtAFUGoQBUApECjA8JA+Q7qQEcpvUA5HZ1A",
          "dtype": "f4"
         },
         "z": {
          "bdata": "ts0yQAX4dkBR8YRAJDpQQDhtU0BcUlFAPPpUQAuhsUDvpEdApz09QC+qQUDSzXVAWXo0QJzYiEAMRWlAcfVwQFuXg0BgVnpAGp+GQMPpgkAp2lxAyvCWQEEra0CIRUpAj5qGQOJcNEBXdldA9zhSQC/Lh0BdXW1AHS6gQLz8eUDw1HtAEaE6QI1ba0AA+jVA2V1aQDgGhkBmRH5AfaqEQDsEZkCObTpA/ASCQJn6ekC992ZA",
          "dtype": "f4"
         }
        },
        {
         "customdata": [
          [
           "November #canola lost $5.50 to $464.20 per tonne.",
           0.479
          ],
          [
           "Had to give up on The Blue Guitar, couldn't stand main character. Sort of skim-read to the end which got grim and unsettling . . . 1/2",
           0.583
          ],
          [
           "@CrucialBMXShop ohh silver lake came up a lot on there! Is that where you guys stayed?",
           0.208
          ],
          [
           "Please bear with me, I'm not Twitter savvy😝 in real life I'm a Facebook person. Help me gain followers 🤓 #blog #selfhelp ",
           0.146
          ],
          [
           "@ManUtd Rooney needs to come off! Absolutely dreadful! 🙈🙈🙈 class goal from @carras16 @carras16 showing why he should be in the team!!",
           0.5
          ],
          [
           "@littlebakaa @AlcohoIPorn give me a smiling emoticon will ya? i dont like the idea of you frowning &gt;.&lt;",
           0.417
          ],
          [
           "Damn gud #premiere #LethalWeapon...#funny and ",
           0.229
          ],
          [
           "Corbyn loses and I walk up to a crying Corbyn supporter and whisper\\n\\n'Don't mourn. Organise'\\n\\nAnd laugh and laugh",
           0.354
          ],
          [
           "Sometimes The Worst Place You Can Be Is In Your Own Head.'\\n\\n#quotes #worstenemy #depression #thinktoomuch",
           0.854
          ],
          [
           "@MSNBC @fox @cnn @realDonaldTrump @HillaryClinton. Using fear to state his views. Not getting the facts before making a serious statement???",
           0.417
          ],
          [
           "@cotsonika @NHL well, they should all be unhappy for the way they played.  Right @fmjacob ??",
           0.542
          ],
          [
           "@EBled2 Great to have you as our tournament chair and award was #serious",
           0.132
          ],
          [
           "@hannah_2401 hannah stop being mournful and chill 💁",
           0.188
          ],
          [
           "@msfang they say you attract what you see, maybe I shouldn't be a pessimist but I don't wanna take any chances lol can't wait to relocate",
           0.333
          ],
          [
           "Honestly don't give af who wins out of us and pine, I'm just worried about getting drunk Saturday night😂",
           0.208
          ],
          [
           "Condolences to the  JC and the Georges family.. #sad",
           0.771
          ],
          [
           "@JonathanHatfull I’ll look forward to it. Hoping for lots of stetson-tilting and rueful looks into whiskey glasses.",
           0.333
          ],
          [
           "gloomy weather puts me in the best mood",
           0.271
          ],
          [
           "Absolutely can not believe the generosity pouring out for us, but Id give everything I have for Nick to be healthy and happy. #lost",
           0.542
          ],
          [
           "@everton_de_leon @sterushton Genuinely grim stuff. Over a century of history sold off by some porn baron twats for a minty new stadium. Urgh",
           0.624
          ],
          [
           "@cburt43 turn that frown upside down",
           0.27
          ],
          [
           "Sky news still pushing the Brexit gloom line, managing to ignore the fact it's simply not happening. 'But in the future.....'",
           0.396
          ],
          [
           "Learning to trust God can quiet a troubled &amp; restless heart, bring peace to a weary soul, &amp; eliminate the hopelessness that #addiction is!",
           0.24
          ],
          [
           "@pureleine though lately with how bad my depression has been i feel like my body is like just, taking what little it can get",
           0.771
          ],
          [
           "Cause fail or pass I refuse to be sober",
           0.604
          ],
          [
           "Very long day. Thank goodness for Bake Off to brighten up a weary Wednesday ☺ #GBBO",
           0.188
          ],
          [
           "Patti seems so sad. She stamped and ran behind the sofa. We will have to give her plenty of love and affection...more than usual. #sad",
           0.729
          ],
          [
           "Going home is depressing",
           0.896
          ],
          [
           "Lisa: Getting what you want all the time will ultimately leave you unfulfilled and joyless.",
           0.5
          ],
          [
           "Be joyful in hope, patient in affliction, faithful in prayer. Romans 12:12",
           0.216
          ],
          [
           "@SilkInSide @TommyJoeRatliff that's so pretty! I love the sky in the background and the purple highlights with the dull colors is great",
           0.088
          ],
          [
           "We have left #Maine. #sadness",
           0.771
          ],
          [
           "I sulk too much for my own good.",
           0.896
          ],
          [
           "That's me for the evening, though! Way too lit to finish these off properly without causing some serious mischief.",
           0.396
          ],
          [
           "Don't wanna go to work but I want the money #sad",
           0.729
          ],
          [
           "@LeePorter94 @DomMcGovern_ hi Dom I saw u at Notts county away, looking for 1 mufc away ticket will pay ",
           0.312
          ],
          [
           "On bedrest since I got out of the hospital. U find in unopened beer.. what do I do. Pour that shit out! No alcohol at all for me #sober",
           0.44
          ],
          [
           "This shit hurting my heart 😪 that's how serious it is .",
           0.875
          ],
          [
           "Might go on @RadioX tomorrow to hopefully win a new car. My current one stinks of gone off milk. #grim",
           0.458
          ],
          [
           "All I want to do is watch some netflix but I am stuck here in class. #depressing",
           0.667
          ],
          [
           "We are about a little over an hour away! We will arrive soon, do not fret!",
           0.125
          ],
          [
           "“Dyslexia is the affliction of a frozen genius.”― Stephen Richards",
           0.333
          ],
          [
           "you are on an endless journey of figuring yourself out; don't be discouraged when you don't know who you are yet.",
           0.375
          ]
         ],
         "hovertemplate": "emotion=sadness<br>UMAP1=%{x}<br>UMAP2=%{y}<br>UMAP3=%{z}<br>text=%{customdata[0]}<br>intensity=%{customdata[1]}<extra></extra>",
         "legendgroup": "sadness",
         "marker": {
          "color": "#ab63fa",
          "symbol": "circle"
         },
         "mode": "markers",
         "name": "sadness",
         "scene": "scene",
         "showlegend": true,
         "type": "scatter3d",
         "x": {
          "bdata": "u975QDXT4UBUaxNBba0AQRLfC0FlWhRBEjcRQT11GEFeN9hAq8waQeleD0HNEg1BP7cKQY5sAkHJawJB0wvWQM1PCUHg8ulA9JsAQc1KD0GwhQ9Ba94fQf4wCEH1OtpAR/sCQRiR9UAs89hATI7SQLO55kD35QRBabEGQbhJ0kDgXuNAph8FQWrA1EBtMA9BiCABQf3K20C1p/ZA+yjZQMnfAEFnIN5AqAfsQA==",
          "dtype": "f4"
         },
         "y": {
          "bdata": "5FS7QG4a00D9AsVAeqe9QPU+D0G/bK5A+I6ZQJGoq0Dxld5AvHjgQEQM6kBw8LpA4MW6QGAavkDknNxA+uzhQJM9vkCiKa5A0yWcQOz8C0FzEbBAvg7NQDHMn0Dy3dtAg2PZQDUFrUAzpM9AvEzWQPZSxUDOe5tAjM+qQJPA1EAFK9FABjbPQHwN1kA0VA5BVEPkQKKt50AFBtFAAJLdQIqrzkBwVeZAfb7CQA==",
          "dtype": "f4"
         },
         "z": {
          "bdata": "72BoQA4xnEA/GTRAGiyJQHz7N0DU+FNAD6FhQIMMgUBdTqpAQrqcQEVPOUDzlTFAp5FrQM4kjEDm3JBATfOUQFaTVkDbnGxA5YVxQDfJPEBc5mZAgf6KQCJPlUCrP6dAxLeJQFOLYECdVJhAHSehQDismUDFyIdAmicrQLG+mkCbu5tAPBCKQC5hn0ATYi5A10GPQKdklkDhPGJACuykQGgHtUD6aapAAhuiQA==",
          "dtype": "f4"
         }
        }
       ],
       "layout": {
        "legend": {
         "title": {
          "text": "emotion"
         },
         "tracegroupgap": 0
        },
        "scene": {
         "domain": {
          "x": [
           0,
           1
          ],
          "y": [
           0,
           1
          ]
         },
         "xaxis": {
          "title": {
           "text": "UMAP1"
          }
         },
         "yaxis": {
          "title": {
           "text": "UMAP2"
          }
         },
         "zaxis": {
          "title": {
           "text": "UMAP3"
          }
         }
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermap": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermap"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "3D UMAP Projection of Text Embeddings"
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Answer here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import umap.umap_ as umap\n",
    "\n",
    "train_df_new = pd.read_pickle(\"data/train_df_sample_embeddings.pkl\")\n",
    "test_df_new = pd.read_pickle(\"data/test_df_sample_embeddings.pkl\")\n",
    "\n",
    "combined_df = pd.concat([train_df_new, test_df_new], ignore_index=True)\n",
    "\n",
    "def to_vector(emb):\n",
    "    # emb 可能是: [Embedding(...)] 或 dict 或 list[float]\n",
    "    if emb is None:\n",
    "        return None\n",
    "    if isinstance(emb, list) and len(emb) == 1:\n",
    "        emb = emb[0]\n",
    "    if hasattr(emb, \"values\"):\n",
    "        return np.array(emb.values, dtype=np.float32)\n",
    "    if isinstance(emb, dict) and \"values\" in emb:\n",
    "        return np.array(emb[\"values\"], dtype=np.float32)\n",
    "    if isinstance(emb, (list, tuple)) and len(emb) > 0 and isinstance(emb[0], (int, float)):\n",
    "        return np.array(emb, dtype=np.float32)\n",
    "    return None\n",
    "\n",
    "X_embeddings = np.vstack([to_vector(e) for e in combined_df[\"embeddings\"].tolist()])\n",
    "\n",
    "reducer_3d = umap.UMAP(n_components=3, metric=\"cosine\", random_state=28)\n",
    "embedding_3d = reducer_3d.fit_transform(X_embeddings)\n",
    "\n",
    "df_plot_3d = pd.DataFrame(embedding_3d, columns=[\"UMAP1\", \"UMAP2\", \"UMAP3\"])\n",
    "df_plot_3d[\"emotion\"] = combined_df[\"emotion\"].values\n",
    "df_plot_3d[\"intensity\"] = combined_df[\"intensity\"].values\n",
    "df_plot_3d[\"text\"] = combined_df[\"text\"].values\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df_plot_3d,\n",
    "    x=\"UMAP1\",\n",
    "    y=\"UMAP2\",\n",
    "    z=\"UMAP3\",\n",
    "    color=\"emotion\",\n",
    "    hover_data=[\"text\", \"intensity\"],\n",
    "    title=\"3D UMAP Projection of Text Embeddings\"\n",
    ")\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3D UMAP 的觀察:\n",
    "- 整體來看 3D 並沒有讓四個 emotion 明顯分開, 多數點仍然重疊, 跟 2D 圖差不多。\n",
    "- 不過在 3D 圖中, 綠色的 joy 比 2D 更容易看出有一段區域出現聚集, 代表在第三個維度加入後, joy 的部分樣本在嵌入空間裡有比較一致的方向。\n",
    "- 這也合理, 因為情緒文本本來就不是離散類別, 很多句子會混合情緒或用相似語氣表達不同情緒, 使得 embeddings 在語意空間中本來就靠近。\n",
    "- 另外, 不論 2D 或 3D, UMAP 都是把高維向量投影到低維, 投影過程一定會丟失資訊, 所以即使原本高維有差異, 低維也可能看起來重疊。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_9_'></a>[**2.5 Retrieval-Augmented Generation (RAG)**](#toc0_)\n",
    "\n",
    "`NOTE: This whole section including the exercise is now considered a bonus section, not counted for the main grade.`\n",
    "\n",
    "RAG (Retrieval-Augmented Generation) is a technique where a language model combines document retrieval with text generation. In RAG, a retrieval system first finds relevant documents or text chunks, and then the language model uses this retrieved information to generate a more informed and accurate response. This method enhances the model's ability to answer questions by grounding its responses in real, external data.\n",
    "\n",
    "In the following code, we will load a webpage as a document, which allows us to retrieve text from a URL. After loading the content, we will split the document into smaller, manageable chunks, making it easier for our model to process. Then, we'll generate embeddings for these chunks with a specified LLM model (Gemini Embedding Model). These embeddings will be stored in a vector database, which enables us to perform similarity searches. By setting up this retrieval system, we can use a RAG chain to answer questions. The retriever finds relevant text chunks from the document based on a query, and the LLM generates a response by incorporating this retrieved information, making the answers more grounded and accurate.\n",
    "\n",
    "In this example we use the library langchain, for documentation on more functions of the library you can check the following link: [LangChain Tutorials](https://python.langchain.com/docs/tutorials/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Function to load, split, and retrieve documents\n",
    "def load_and_retrieve_docs(url):\n",
    "    loader = WebBaseLoader(\n",
    "        web_paths=(url,),\n",
    "        bs_kwargs=dict() \n",
    "    ) \n",
    "    docs = loader.load() #We will load the URL that will serve as our data source\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150) #We will divide the URL in chunks of text for easier comparison in the vector space\n",
    "    splits = text_splitter.split_documents(docs)\n",
    "    #print(splits) #You can print this to see how the chunks in the url where split\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")\n",
    "    vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings) #Our vector space for comparison\n",
    "    return vectorstore.as_retriever()\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs) #Format the retrieved docs in an orderly manner for prompting\n",
    "\n",
    "# Define the Gemini LLM function\n",
    "def gemini_llm(question, context):\n",
    "    system_prompt = \"You are a RAG Agent that needs to provide a well structured answer based on the provided question and context.\"\n",
    "    formatted_prompt = f\"Question: {question}\\n\\nContext: {context}\"\n",
    "    response, logs = prompt_gemini(input_prompt = formatted_prompt, system_instruction = system_prompt, with_tokens_info = True)\n",
    "    print(f\"logs: \\n{logs}\")\n",
    "    # print(f\"Retrieved context: \\n{context}\\n\\n\") # You can print this to observe the retrieved context\n",
    "    return response\n",
    "\n",
    "\n",
    "# Define the RAG chain\n",
    "def rag_chain(question, retriever):\n",
    "    retrieved_docs = retriever.invoke(question)\n",
    "    formatted_context = format_docs(retrieved_docs)\n",
    "    return gemini_llm(question, formatted_context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs: \n",
      "{'model': 'gemini-2.5-flash-lite', 'input_tokens': 730, 'output_tokens': 70}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the provided text, the key challenges in realizing AGI's full potential are:\n",
       "\n",
       "*   **Improvements in Machine Learning:** Continued advancements in machine learning algorithms are crucial.\n",
       "*   **Computational Power:** Significant increases in computational power are necessary.\n",
       "*   **Data Availability:** Greater availability of data is a key factor for progress."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "url=\"https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\"\n",
    "# Create the retriever\n",
    "retriever = load_and_retrieve_docs(url)\n",
    "\n",
    "# Use the RAG chain\n",
    "result = rag_chain(question=\"What are the Key Challenges in Realizing AGI’s Full Potential\", retriever=retriever)\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##### <a id='toc1_5_9_1_1_'></a>[**Actual answer in the URL:**](#toc0_)\n",
    "\n",
    "![pic11.png](pics/pic11.png)\n",
    "\n",
    "##### <a id='toc1_5_9_1_2_'></a>[**Content in the URL that might get into the generated answer because of similar semantic meaning:**](#toc0_)\n",
    "\n",
    "![pic12.png](pics/pic12.png)\n",
    "\n",
    "source: https://qbotica.com/understanding-artificial-general-intelligence-agi-an-in-depth-overview/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_9_1_3_'></a>[**>>> Bonus Exercise 5 (Take home):**](#toc0_)\n",
    "\n",
    "`NOTE: This exercise is now considered a bonus one, not counted for the main grade, only as extra points.`\n",
    "\n",
    "Your task is to test the RAG system with your own chosen URL and analyze its performance.\n",
    "\n",
    "1. Find a URL of a webpage with interesting text content to test the RAG pipeline.\n",
    "2. Make a question about the content in the webpage you chose.\n",
    "3. Discuss how good the question was answered by the model, if the model missed important information related to your question.\n",
    "4. Display a screenshot of the real answer in the webpage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_10_'></a>[**2.6 Few-Shot Prompting Classification:**](#toc0_)\n",
    "\n",
    "Few-shot prompting is a technique where a Large Language Model (LLM) is given a small number of labeled examples within a prompt to guide its classification. This allows the model to perform a new task with minimal data, avoiding the need for extensive fine-tuning.\n",
    "\n",
    "In this lab, we will use the Gemini API to perform zero-shot, 1-shot, and 5-shot emotion classification:\n",
    "\n",
    "*   **Zero-shot:** The model classifies text without any prior examples.\n",
    "*   **1-shot:** The model is given one example for each emotion before classifying.\n",
    "*   **5-shot:** The model is given five examples per emotion for better context.\n",
    "\n",
    "To make our implementation robust and efficient, we are incorporating two key features:\n",
    "\n",
    "1.  **Structured Output:** We provide the Gemini model with a specific output schema (`Emotions` class). This instructs the model to return *only* a valid emotion label (e.g., `joy`), which makes the output predictable and reliable, minimizing errors.\n",
    "2.  **API Rate Handling:** The code includes a function to manage the requests-per-minute limit of the Gemini API.\n",
    "\n",
    "We will test the model's performance on a small sample of 20 texts per emotion to ensure the process runs quickly. If the model provides an invalid response, the code will automatically retry the request until a valid classification is received.\n",
    "\n",
    "**Prompt Structure:**\n",
    "`System Instruction -> Task Description -> Examples (if not zero-shot) -> Text to Classify`\n",
    "\n",
    "\n",
    "<span style=\"color:green\">For the exercises in this section there is no need to re-run the cells, you can use the data that has been saved previously to the corresponding directory.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton for visualizing confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, title='Confusion matrix',\n",
    "                          cmap=sns.cubehelix_palette(as_cmap=True)):\n",
    "    \"\"\"\n",
    "    This function is modified from: \n",
    "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "    \"\"\"\n",
    "    classes.sort()\n",
    "    tick_marks = np.arange(len(classes))    \n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(5,5))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels = classes,\n",
    "           yticklabels = classes,\n",
    "           title = title,\n",
    "           xlabel = 'Predicted label',\n",
    "           ylabel = 'True label')\n",
    "\n",
    "    fmt = 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    ylim_top = len(classes) - 0.5\n",
    "    plt.ylim([ylim_top, -.5])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import enum\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import time\n",
    "# Define the emotion labels\n",
    "emotions = ['anger', 'fear', 'joy', 'sadness']\n",
    "# Define the model to use for few-shot prompting\n",
    "\n",
    "# Schema for the output, the type enum can be used to make a pool of options if what we want is to classify our text selecting only one of them\n",
    "class Emotions(enum.StrEnum):\n",
    "    ANGER = 'anger'\n",
    "    FEAR = 'fear'\n",
    "    JOY = 'joy'\n",
    "    SADNESS = 'sadness'\n",
    "\n",
    "\n",
    "# Function to handle the rate limits of gemini models\n",
    "def handle_rate_limit(request_count, first_request_time, max_calls_per_min):\n",
    "    current_time = time.time()\n",
    "\n",
    "    # Initialize timer on the first request of a new window\n",
    "    if request_count == 0:\n",
    "        first_request_time = current_time\n",
    "\n",
    "    request_count += 1\n",
    "\n",
    "    # If the rate limit is reached\n",
    "    if request_count > max_calls_per_min:\n",
    "        elapsed_time = current_time - first_request_time\n",
    "        if elapsed_time < 60:\n",
    "            wait_time = 60 - elapsed_time\n",
    "            print(f\"Rate limit of {max_calls_per_min} requests per minute reached. Waiting for {wait_time:.2f} seconds.\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "        # Reset for the new window\n",
    "        request_count = 1\n",
    "        first_request_time = time.time()\n",
    "    \n",
    "    return request_count, first_request_time, max_calls_per_min\n",
    "\n",
    "# Function to sample examples per emotion category\n",
    "def sample_few_shots(df, emotions, num_samples=5):\n",
    "    few_shot_examples = {}\n",
    "    for emotion in emotions:\n",
    "        few_shot_examples[emotion] = df[df['emotion'] == emotion].sample(n=num_samples, random_state=42)\n",
    "    return few_shot_examples\n",
    "\n",
    "# Function to build the prompt based on the number of examples (few-shot, 1-shot, zero-shot)\n",
    "def build_prompt(examples, emotions, num_shots=5):\n",
    "    classification_instructions = \"\"\"\n",
    "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
    "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt = classification_instructions + \"\\n\\n\"\n",
    "    \n",
    "    if num_shots > 0:\n",
    "        prompt += f\"Examples: \\n\"\n",
    "        for emotion in emotions:\n",
    "            for _, row in examples[emotion].iterrows():\n",
    "                prompt += f\"Text: {row['text']}\\nClass: {emotion}\\n\\n\" #Show the examples in the same format it will be shown for the classification text\n",
    "                if num_shots == 1:  # If 1-shot, break after the first example for each emotion\n",
    "                    break\n",
    "    return prompt\n",
    "\n",
    "# Function to classify using the LLM with retry for incorrect responses\n",
    "def classify_with_llm(test_text, prompt_base, system_prompt, classes, schema):\n",
    "    response = None\n",
    "    while not response or response not in classes:\n",
    "        full_prompt = f\"{prompt_base}\\nClassification:\\nText: {test_text}\\nClass: \" #The classification text will leave the emotion label to be filled in by the LLM\n",
    "        try:\n",
    "            result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt)\n",
    "            # print(f\"result: {result} \\n\")\n",
    "            # print(f\"type: {type(result)}\")\n",
    "            if not result:\n",
    "                # In case of giving empty responses with temperature 0.0, we set a higher temperature to seek for different responses\n",
    "                result = prompt_gemini(input_prompt = [full_prompt], schema = schema, system_instruction = system_prompt, temperature=1.0)\n",
    "\n",
    "            try:\n",
    "                # If the result is in the correct format it can be parsed using json\n",
    "                response = json.load(result)\n",
    "            except:\n",
    "                # In case it's not in a json friendly format\n",
    "                # Deleting characters \" and ' in case they appear in our response with the class of the text \n",
    "                response = result.replace('\"', '')    \n",
    "                response = response.replace(\"'\", \"\")  \n",
    "\n",
    "                \n",
    "        # except exceptions.ResourceExhausted as e:\n",
    "        except Exception as e:\n",
    "            print(f\"Waiting to retry... Error: {e}\")\n",
    "            time.sleep(15)\n",
    "            print(f\"test_text: {test_text}\")\n",
    "            return classify_with_llm(test_text, prompt_base, system_prompt, classes, schema) # Retry the request\n",
    "\n",
    "\n",
    "        if response not in classes:  # Retry if not a valid response\n",
    "            print(f\"Invalid response: {response}. Asking for reclassification.\")\n",
    "    return response\n",
    "\n",
    "# Main function to run the experiment with the option for zero-shot, 1-shot, or 5-shot prompting\n",
    "def run_experiment(df_train, df_test, num_test_samples=5, num_shots=5):\n",
    "    # Sample examples for few-shot prompting based on num_shots\n",
    "    if num_shots > 0:\n",
    "        few_shot_examples = sample_few_shots(df_train, emotions, num_samples=num_shots) \n",
    "        prompt_base = build_prompt(few_shot_examples, emotions, num_shots=num_shots)\n",
    "    else:\n",
    "        prompt_base = build_prompt(None, emotions, num_shots=0)  # Zero-shot has no examples\n",
    "\n",
    "    # System prompt for our classification model:\n",
    "    system_prompt = \"You are an emotion classification model for text data. Do not give empty responses, classify according to the list of possible classes.\"\n",
    "\n",
    "    # Prepare to classify the test set\n",
    "    results_data = []\n",
    "\n",
    "    print(prompt_base)\n",
    "    # Sample 20 examples per emotion for the test set to classify\n",
    "    test_samples = sample_few_shots(df_test, emotions, num_samples=num_test_samples)\n",
    "\n",
    "    # Variables to handle rate limit of gemini\n",
    "    request_count = 0\n",
    "    max_calls_per_min = 15 # Gemini 2.5 Flash Lite has this maximum set in the documentation\n",
    "    first_request_time = None\n",
    "\n",
    "    # Classify 20 test examples (5 from each category) and save predictions\n",
    "    for emotion in emotions:\n",
    "        for _, test_row in tqdm(test_samples[emotion].iterrows(), desc=f\"Processing samples for emotion: {emotion}...\", total=num_test_samples):\n",
    "            test_text = test_row['text']\n",
    "            request_count, first_request_time, max_calls_per_min = handle_rate_limit(request_count, first_request_time, max_calls_per_min)  # Check and handle rate limit before each API call\n",
    "            predicted_emotion = classify_with_llm(test_text = test_text, prompt_base = prompt_base, system_prompt = system_prompt, classes = emotions, schema = Emotions)\n",
    "            # Append the results data:\n",
    "            results_data.append({\n",
    "                    'text': test_text,\n",
    "                    'true_emotion': emotion,\n",
    "                    'predicted_emotion': predicted_emotion\n",
    "                })\n",
    "\n",
    "    # Create dataframe to save the results data\n",
    "    results_df = pd.DataFrame(results_data)\n",
    "    \n",
    "    # Extract just the true and predicted labels for metrics calculations\n",
    "    true_labels = results_df['true_emotion']\n",
    "    predictions = results_df['predicted_emotion']\n",
    "\n",
    "    output_dir = \"./results/llm_classification_results\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    # Save the results\n",
    "    filename = f\"{output_dir}/results_samples_{num_test_samples}_shots_{num_shots}.csv\"\n",
    "    \n",
    "    # Save the DataFrame to CSV\n",
    "    results_df.to_csv(filename, index=False)\n",
    "    print(f\"\\nResults saved to {filename}\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(true_labels, predictions)\n",
    "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Classification report\n",
    "    print(classification_report(y_true=true_labels, y_pred=predictions))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(y_true=true_labels, y_pred=predictions) \n",
    "    my_tags = ['anger', 'fear', 'joy', 'sadness']\n",
    "    plot_confusion_matrix(cm, classes=my_tags, title=f'Confusion matrix for classification with \\n{num_shots}-shot prompting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important: The next part should take around 16 minutes to finish running due to API Rate Limits**\n",
    "\n",
    "**Note:** You might see an `429 RESOURCE_EXHAUSTED` error when running the following code all at once, this is because the `current API Rate Limit handling cannot reliably find out how many requests we have left per minute` from cell to cell, there is no Gemini feature created for it to get the information from their servers. So, `if you don't want to see the error you can just wait 1 minute` after one cell finished processing. But `even if there is an error showing it is fine`, internally in the code `there is a retry that happens every 15 seconds` until we finish processing our sampled data. `The lab is designed to never reach the total rate limit per day quota.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  35%|███▌      | 7/20 [00:06<00:11,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 40.258846087s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 40.218213084s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '40s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 25.166418906s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 25.127016501s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 10.072538808s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 10.027350567s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 54.969023192s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 54.931742409s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 39.850695933s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '39s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 39.817342395s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '39s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 24.753052433s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 24.721573425s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 9.665379766s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 9.627147701s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 54.571667406s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 54.544027378s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 39.49155046s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '39s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 39.452112319s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '39s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 24.379650489s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 24.340420466s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '24s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 9.296770405s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 9.249531676s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 54.191405552s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 54.146617689s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '54s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 39.045364862s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '39s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 38.982903157s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 23.927508288s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 23.884678173s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 8.824326662s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 8.786741297s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 53.728604601s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 53.681561759s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 38.576735831s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 38.51917996s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 23.436958456s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 23.361429325s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 8.257206107s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 8.209882708s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 53.137927642s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 53.060636128s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 37.94133708s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '37s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 37.869882637s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '37s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.784008506s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.73947656s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 7.645864139s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 7.58615744s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '7s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 52.499218781s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 52.456979273s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 37.297412151s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '37s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 37.233749446s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '37s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.103852837s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 22.051165183s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 6.960281025s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 6.912904838s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 51.821988466s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '51s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 51.7755762s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '51s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 36.677581078s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 36.629013078s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 21.546375572s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 21.498238174s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 6.420167412s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 6.376338272s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 51.218622466s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '51s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 51.177002492s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '51s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 36.085149531s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 36.037277904s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '36s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 20.974414057s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 20.923987986s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 5.8659651s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 5.831348025s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 50.765951844s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '50s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 50.732022426s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '50s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 35.672925932s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 35.630299111s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Just joined #pottermore and was sorted into HUFFLEPUFF 😡😡😡 \n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 20.568719654s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 20.53297477s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:  35%|███▌      | 7/20 [09:41<17:59, 83.01s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Example of running the experiment with zero-shot prompting\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_test_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_shots\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 135\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(df_train, df_test, num_test_samples, num_shots)\u001b[39m\n\u001b[32m    133\u001b[39m test_text = test_row[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    134\u001b[39m request_count, first_request_time, max_calls_per_min = handle_rate_limit(request_count, first_request_time, max_calls_per_min)  \u001b[38;5;66;03m# Check and handle rate limit before each API call\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m predicted_emotion = \u001b[43mclassify_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_base\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43memotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mEmotions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Append the results data:\u001b[39;00m\n\u001b[32m    137\u001b[39m results_data.append({\n\u001b[32m    138\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: test_text,\n\u001b[32m    139\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtrue_emotion\u001b[39m\u001b[33m'\u001b[39m: emotion,\n\u001b[32m    140\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mpredicted_emotion\u001b[39m\u001b[33m'\u001b[39m: predicted_emotion\n\u001b[32m    141\u001b[39m     })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     97\u001b[39m     time.sleep(\u001b[32m15\u001b[39m)\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest_text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclassify_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Retry the request\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m classes:  \u001b[38;5;66;03m# Retry if not a valid response\u001b[39;00m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Asking for reclassification.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     97\u001b[39m     time.sleep(\u001b[32m15\u001b[39m)\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest_text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclassify_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Retry the request\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m classes:  \u001b[38;5;66;03m# Retry if not a valid response\u001b[39;00m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Asking for reclassification.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "    \u001b[31m[... skipping similar frames: classify_with_llm at line 99 (34 times)]\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     97\u001b[39m     time.sleep(\u001b[32m15\u001b[39m)\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest_text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclassify_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Retry the request\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m classes:  \u001b[38;5;66;03m# Retry if not a valid response\u001b[39;00m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Asking for reclassification.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWaiting to retry... Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     time.sleep(\u001b[32m15\u001b[39m)\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest_text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m classify_with_llm(test_text, prompt_base, system_prompt, classes, schema) \u001b[38;5;66;03m# Retry the request\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with zero-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You will be given a text extracted from social media and your task is to classify the text into one of the following emotion categories: \n",
      "\"anger\" | \"fear\" | \"joy\" | \"sadness\"\n",
      "    \n",
      "\n",
      "Examples: \n",
      "Text: I really really resent having to go to bed at a sensible hour, you guys. I WANT TO TALK TO MY PEOPLE.\n",
      "Class: anger\n",
      "\n",
      "Text: The focal points of war lie in #terrorism and the #UN needs to address #violentextremism\n",
      "Class: fear\n",
      "\n",
      "Text: @TampaBayRay I cried with laughter.\n",
      "Class: joy\n",
      "\n",
      "Text: @EBled2 Great to have you as our tournament chair and award was #serious\n",
      "Class: sadness\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 57.64466372s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 57.604280733s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n",
      "test_text: Anger, resentment, and hatred are the destroyer of your fortune today.\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 42.538074769s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}\n",
      "Error occurred when generating response, error: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash-lite\\nPlease retry in 42.501503381s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}\n",
      "Waiting to retry... Error: 'NoneType' object has no attribute 'replace'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing samples for emotion: anger...:   0%|          | 0/20 [00:30<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# If the result is in the correct format it can be parsed using json\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     response = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:293\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    276\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[33;03ma JSON document) to a Python object.\u001b[39;00m\n\u001b[32m    278\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    291\u001b[39m \u001b[33;03mkwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m(),\n\u001b[32m    294\u001b[39m     \u001b[38;5;28mcls\u001b[39m=\u001b[38;5;28mcls\u001b[39m, object_hook=object_hook,\n\u001b[32m    295\u001b[39m     parse_float=parse_float, parse_int=parse_int,\n\u001b[32m    296\u001b[39m     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 90\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# In case it's not in a json friendly format\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Deleting characters \" and ' in case they appear in our response with the class of the text \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     response = \u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreplace\u001b[49m(\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m)    \n\u001b[32m     91\u001b[39m     response = response.replace(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'replace'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Example of running the experiment with 1-shot prompting\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_test_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_shots\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 135\u001b[39m, in \u001b[36mrun_experiment\u001b[39m\u001b[34m(df_train, df_test, num_test_samples, num_shots)\u001b[39m\n\u001b[32m    133\u001b[39m test_text = test_row[\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    134\u001b[39m request_count, first_request_time, max_calls_per_min = handle_rate_limit(request_count, first_request_time, max_calls_per_min)  \u001b[38;5;66;03m# Check and handle rate limit before each API call\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m predicted_emotion = \u001b[43mclassify_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_base\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43memotions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mEmotions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Append the results data:\u001b[39;00m\n\u001b[32m    137\u001b[39m results_data.append({\n\u001b[32m    138\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: test_text,\n\u001b[32m    139\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mtrue_emotion\u001b[39m\u001b[33m'\u001b[39m: emotion,\n\u001b[32m    140\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mpredicted_emotion\u001b[39m\u001b[33m'\u001b[39m: predicted_emotion\n\u001b[32m    141\u001b[39m     })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     97\u001b[39m     time.sleep(\u001b[32m15\u001b[39m)\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest_text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclassify_with_llm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Retry the request\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m classes:  \u001b[38;5;66;03m# Retry if not a valid response\u001b[39;00m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid response: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Asking for reclassification.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 97\u001b[39m, in \u001b[36mclassify_with_llm\u001b[39m\u001b[34m(test_text, prompt_base, system_prompt, classes, schema)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     96\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mWaiting to retry... Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m     time.sleep(\u001b[32m15\u001b[39m)\n\u001b[32m     98\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtest_text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m classify_with_llm(test_text, prompt_base, system_prompt, classes, schema) \u001b[38;5;66;03m# Retry the request\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 1-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_experiment' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Example of running the experiment with 5-shot prompting\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[43mrun_experiment\u001b[49m(train_df, test_df, num_test_samples=\u001b[32m20\u001b[39m, num_shots=\u001b[32m5\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'run_experiment' is not defined"
     ]
    }
   ],
   "source": [
    "# If you see '429 RESOURCE_EXHAUSTED' errors it's fine, wait until the data gets processed, it will keep retrying until it finishes\n",
    "\n",
    "# Example of running the experiment with 5-shot prompting\n",
    "run_experiment(train_df, test_df, num_test_samples=20, num_shots=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_1_'></a>[**>>> Exercise 6 (Take home):**](#toc0_)\n",
    "\n",
    "Compare and discuss the overall results of the zero-shot, 1-shot and 5-shot classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer here\n",
    "\"\"\"\n",
    "Exercise 6:\n",
    "\n",
    "整體準確率(80 筆樣本):\n",
    "- 0-shot accuracy = 0.50\n",
    "- 1-shot accuracy = 0.55\n",
    "- 5-shot accuracy = 0.562\n",
    "\n",
    "觀察:\n",
    "- shot 數增加後, 整體有小幅提升, 代表提供範例可以讓模型更貼近任務定義與輸出格式。\n",
    "- 但提升幅度不大, 代表情緒分類本身界線不清楚, 句子可能混合情緒, 或語氣/反諷讓模型難判斷。\n",
    "- 也可能因為範例數量仍有限, 或範例分布沒有完全覆蓋資料中的各種寫法, 所以效果提升有限。\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##### <a id='toc1_5_10_1_2_'></a>[**>>> Exercise 7 (Take home):**](#toc0_)\n",
    "\n",
    "**Case Study:** Check the results' files inside the `results/llm_classification_results` directory and find cases where the **text classification improves with more examples** (pred emotion is right with examples), **cases where it does not improve** (pred emotion always wrong) and **cases where the classification got worse with more examples** (pred emotion goes from right to wrong with examples). For this you need to load the results with pandas and handle the data using its dataframe functions. Discuss about the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "Exercise 7:\n",
    "\n",
    "我使用 results/llm_classification_results 的三個結果檔(0-shot, 1-shot, 5-shot)比較同一批資料在不同 shot 設定下的 predicted_emotion。\n",
    "\n",
    "案例統計:80 筆:\n",
    "- 變好(0-shot 錯 -> 5-shot 對): 10\n",
    "- 變差(0-shot 對 -> 5-shot 錯): 5\n",
    "- 沒改善(0, 1, 5 都錯): 29\n",
    "\n",
    "1) 變好案例\n",
    "- \"@CozanGaming ... raging ...\" true=anger, 0-shot=joy, 1-shot=sadness, 5-shot=anger\n",
    "  這類句子有明確負面情緒詞(raging), 但在 0-shot 可能被當成玩笑或語氣輕鬆而誤判。給更多例子後, 模型比較能把這種語氣歸到 anger。\n",
    "- \"Obama must be fuming.. lol\" true=anger, 0-shot=joy, 1-shot=anger, 5-shot=anger\n",
    "  句子有 \"lol\" 容易把模型帶到 joy, 但 \"fuming\" 是 anger 的關鍵訊號。shot 增加後, 模型更能抓到主要情緒。\n",
    "\n",
    "2) 沒改善案例\n",
    "- \"Me being on my dean ... I don't snap ...\" true=anger, 0/1/5-shot 都判 sadness\n",
    "  這種句子像是在描述疲累, 壓力, 情緒耗損, 本身就可能接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improved: 10\n",
      "worse: 5\n",
      "never: 29\n",
      "\n",
      "--- improved examples ---\n",
      "                                                                                                                                 text true_emotion predicted_emotion_0 predicted_emotion_1 predicted_emotion_5\n",
      "                                           @CozanGaming that's what lisa asked before she started raging at me, 'can I call you?' heh        anger                 joy             sadness               anger\n",
      "                                                                                               @TrussElise Obama must be fuming.. lol        anger                 joy               anger               anger\n",
      "@Jen_ny69 People will always get offended everyone's situation is different! Just because we have kids doesn't mean we have to settle        anger                 joy                 joy               anger\n",
      "\n",
      "--- worse examples ---\n",
      "                                                                                                                                      text true_emotion predicted_emotion_0 predicted_emotion_1 predicted_emotion_5\n",
      "[ @HedgehogDylan ] *she would frown a bit, folding her arms* 'why is it that every time I'm in need of assistance someone expects a lil **        anger               anger             sadness             sadness\n",
      "             Dolores.' A thin lipped smile graced glossed lips as she let blues peer over at the woman. ' A constant delight.. As always.'          joy                 joy                 joy             sadness\n",
      "                                                                @theclobra lol I thought maybe, couldn't decide if there was levity or not          joy                 joy                 joy             sadness\n",
      "\n",
      "--- never correct examples ---\n",
      "                                                                                                                               text true_emotion predicted_emotion_0 predicted_emotion_1 predicted_emotion_5\n",
      "                           Me being on my dean really saving a lot of ppl, bc I don't snap nomore &amp; it take so much out of me..        anger             sadness             sadness             sadness\n",
      "Kik to trade, have fun or a conversation  (kik: youraffair) #kik #kikme #messageme #textme #pics #trade #tradepics #dm #snap #bored        anger                 joy                 joy                 joy\n",
      "                                                                                                 Might just leave and aggravate bae        anger             sadness             sadness             sadness\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "import pandas as pd\n",
    "\n",
    "p0 = \"results/llm_classification_results/results_samples_20_shots_0.csv\"\n",
    "p1 = \"results/llm_classification_results/results_samples_20_shots_1.csv\"\n",
    "p5 = \"results/llm_classification_results/results_samples_20_shots_5.csv\"\n",
    "\n",
    "d0 = pd.read_csv(p0)\n",
    "d1 = pd.read_csv(p1)\n",
    "d5 = pd.read_csv(p5)\n",
    "\n",
    "m = d0.merge(d1, on=[\"text\", \"true_emotion\"], suffixes=(\"_0\", \"_1\")).merge(d5, on=[\"text\", \"true_emotion\"])\n",
    "m = m.rename(columns={\"predicted_emotion\": \"predicted_emotion_5\"})\n",
    "\n",
    "m[\"correct_0\"] = m[\"predicted_emotion_0\"] == m[\"true_emotion\"]\n",
    "m[\"correct_1\"] = m[\"predicted_emotion_1\"] == m[\"true_emotion\"]\n",
    "m[\"correct_5\"] = m[\"predicted_emotion_5\"] == m[\"true_emotion\"]\n",
    "\n",
    "improved = m[(~m[\"correct_0\"]) & (m[\"correct_5\"])]\n",
    "worse = m[(m[\"correct_0\"]) & (~m[\"correct_5\"])]\n",
    "never = m[(~m[\"correct_0\"]) & (~m[\"correct_1\"]) & (~m[\"correct_5\"])]\n",
    "\n",
    "print(\"improved:\", len(improved))\n",
    "print(\"worse:\", len(worse))\n",
    "print(\"never:\", len(never))\n",
    "\n",
    "print(\"\\n--- improved examples ---\")\n",
    "print(improved[[\"text\",\"true_emotion\",\"predicted_emotion_0\",\"predicted_emotion_1\",\"predicted_emotion_5\"]].head(3).to_string(index=False))\n",
    "\n",
    "print(\"\\n--- worse examples ---\")\n",
    "print(worse[[\"text\",\"true_emotion\",\"predicted_emotion_0\",\"predicted_emotion_1\",\"predicted_emotion_5\"]].head(3).to_string(index=False))\n",
    "\n",
    "print(\"\\n--- never correct examples ---\")\n",
    "print(never[[\"text\",\"true_emotion\",\"predicted_emotion_0\",\"predicted_emotion_1\",\"predicted_emotion_5\"]].head(3).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <a id='toc1_5_11_'></a>[**2.7 Extra LLM Related Materials:**](#toc0_)\n",
    "So this will be it for the lab, but here are some extra materials if you would like to explore:\n",
    "\n",
    "- **How to use OpenAI ChatGPT model's API (Not Free API):** [Basics Video](https://www.youtube.com/watch?v=e9P7FLi5Zy8), [Basics GitHub](https://github.com/gkamradt/langchain-tutorials/blob/main/chatapi/ChatAPI%20%2B%20LangChain%20Basics.ipynb), [RAG's Basics Video](https://www.youtube.com/watch?v=9AXP7tCI9PI&t=300s), [RAG's Basics GitHub](https://github.com/techleadhd/chatgpt-retrieval)\n",
    "\n",
    "- **Advanced topic - QLoRA (Quantized Low-Rank Adapter):** QLoRA is a method used to make fine-tuning large language models more efficient. It works by adding a small, trainable part (LoRA) to a pre-trained model, while keeping the rest of the model frozen. At the same time, it reduces the size of the model’s data using a process called quantization, which makes the model require less memory. This allows you to fine-tune large models without needing as much computational power, making it easier to adapt models for specific tasks. Materials: [Paper GitHub](https://github.com/artidoro/qlora?tab=readme-ov-file), [Llama 3 Application Video](https://www.youtube.com/watch?v=YJNbgusTSF0&t=512s),[Llama 3 Application GitHub](https://github.com/adidror005/youtube-videos/blob/main/LLAMA_3_Fine_Tuning_for_Sequence_Classification_Actual_Video.ipynb)\n",
    "\n",
    "- **How to Fine-tune and run local LLMs with the `unsloth` library:** [unsloth tutorials](https://docs.unsloth.ai/models/tutorials-how-to-fine-tune-and-run-llms)\n",
    "\n",
    "- **Google's Agent Development Kit Documentation:** [ADK](https://google.github.io/adk-docs/)\n",
    "\n",
    "- **Build AI agents with LangGraph:** [LangGraph Documentation](https://langchain-ai.github.io/langgraph/concepts/why-langgraph/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_fF1woa8YTp5"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4e5eiVLOYTp5"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "DM2025-Lab2-Exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 594.85,
   "position": {
    "height": "40px",
    "left": "723px",
    "right": "20px",
    "top": "80px",
    "width": "250px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
